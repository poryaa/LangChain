{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "032fcca1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "a08d6189",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VectorStoreRetriever(tags=['InMemoryVectorStore', 'OllamaEmbeddings'], vectorstore=<langchain_core.vectorstores.in_memory.InMemoryVectorStore object at 0x79f6858882c0>, search_kwargs={})"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "insurance_faqs_retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7711d8e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6de9a10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('The number of original documents: 2 and after splitting there are 310 of '\n",
      " 'chunks.')\n",
      "'Here is an example of a splitted text chunk metadata:'\n",
      "{'source': './insurance_faq.txt'}\n"
     ]
    }
   ],
   "source": [
    "medical_records_store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44300b99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': './insurance_faq.txt'}, page_content=\"FAQ ID: 001\\nQuestion: What is health insurance?\\nAnswer: Health insurance is a contract with an insurer that helps pay for medical expenses such as doctor visits, hospital stays, and prescriptions. You typically pay a premium and may also pay deductibles, copayments, and coinsurance for covered services.\\n---\\nFAQ ID: 002\\nQuestion: What is a deductible?\\nAnswer: A deductible is the amount you must pay out of pocket for covered healthcare services before your insurance plan starts to pay. Once you meet the deductible, you usually only pay copayments or coinsurance.\\n---\\nFAQ ID: 003\\nQuestion: What is a copayment (copay)?\\nAnswer: A copayment is a fixed amount you pay for a covered service, such as a clinic visit or prescription, at the time you receive care. The insurance plan pays the remaining cost.\\n---\\nFAQ ID: 004\\nQuestion: What is coinsurance?\\nAnswer: Coinsurance is the percentage of costs of a covered healthcare service that you pay after you have met your deductible. For example, if your plan has 20% coinsurance, you pay 20% and the insurer pays 80% of the allowed amount.\\n---\\nFAQ ID: 005\\nQuestion: What is an out-of-pocket maximum?\\nAnswer: An out-of-pocket maximum is the most you will pay for covered services in a policy period, usually one year. Once you reach this amount through deductibles, copayments, and coinsurance, your plan pays 100% of covered services for the rest of the period.\\n---\\nFAQ ID: 006\\nQuestion: What is a preauthorization or prior authorization?\\nAnswer: Preauthorization (or prior authorization) is approval from your insurance company before you receive a service or medication. Some services require this approval for the plan to cover them.\\n---\\nFAQ ID: 007\\nQuestion: How do I file an insurance claim?\\nAnswer: To file a claim, you or your provider submit a claim form along with any required documentation, such as medical bills or receipts, to the insurance company. Many providers submit claims on your behalf, but for out-of-network or reimbursement claims, you may need to submit them yourself.\\n---\\nFAQ ID: 008\\nQuestion: What is the difference between in-network and out-of-network providers?\\nAnswer: In-network providers have a contract with your insurance company and usually cost you less. Out-of-network providers do not have such a contract, which often means higher out-of-pocket costs or no coverage at all, depending on your plan.\\n---\\nFAQ ID: 009\\nQuestion: Does my insurance cover emergency room visits?\\nAnswer: Many plans cover emergency room visits, but coverage varies. You may have a higher copayment or coinsurance for emergency care. It is important to review your policy to understand emergency coverage, including ambulance services and urgent care alternatives.\\n---\\nFAQ ID: 010\\nQuestion: How can I check if a service is covered by my policy?\\nAnswer: You can review your policy documents, log in to your insurer's member portal, or contact customer service using the number on your insurance card. Ask specifically whether the service, provider, and facility are covered and what your cost share will be.\\n---\\nFAQ ID: 011\\nQuestion: What is a waiting period in insurance?\\nAnswer: A waiting period is a set amount of time you must wait after your policy starts before certain benefits or coverage become available. Some plans apply waiting periods to pre-existing conditions or specific types of services.\\n---\\nFAQ ID: 012\\nQuestion: Can I add family members to my insurance policy?\\nAnswer: Many insurance plans allow you to add eligible dependents such as a spouse, partner, or children. You may be able to add them during initial enrollment, during open enrollment periods, or after a qualifying life event like marriage or birth.\\n---\\nFAQ ID: 013\\nQuestion: What is a qualifying life event?\\nAnswer: A qualifying life event is a major change in your life that allows you to enroll in or change your insurance coverage outside the regular open enrollment period. Examples include marriage, divorce, birth or adoption of a child, and loss of other coverage.\\n---\\nFAQ ID: 014\\nQuestion: Why was my claim denied?\\nAnswer: Claims may be denied for several reasons, including missing information, services not covered by your policy, lack of preauthorization when required, or services considered not medically necessary. Your explanation of benefits (EOB) should describe the reason for denial.\\n---\\nFAQ ID: 015\\nQuestion: How can I appeal a denied claim?\\nAnswer: To appeal a denied claim, review the denial letter or explanation of benefits for instructions. You usually need to submit a written appeal, additional documentation, and sometimes a letter from your healthcare provider explaining why the service should be covered.\\n---\\nFAQ ID: 016\\nQuestion: What is the difference between HMO and PPO plans?\\nAnswer: HMO (Health Maintenance Organization) plans typically require you to choose a primary care provider and get referrals for specialists, and they often only cover care from in-network providers. PPO (Preferred Provider Organization) plans offer more flexibility to see out-of-network providers but may have higher premiums and out-of-pocket costs.\\n---\\nFAQ ID: 017\\nQuestion: Does my plan cover preventive services?\\nAnswer: Many plans cover preventive services such as annual check-ups, vaccinations, and screenings, often at no cost when you use in-network providers. Check your policy to see which preventive services are covered and how often.\\n---\\nFAQ ID: 018\\nQuestion: What is a premium?\\nAnswer: A premium is the amount you pay, usually monthly, to keep your insurance policy active. This is separate from out-of-pocket costs like deductibles, copayments, and coinsurance.\\n---\\nFAQ ID: 019\\nQuestion: What documents do I need when submitting a claim?\\nAnswer: You typically need a completed claim form, itemized bills or invoices, receipts for payments made, and sometimes referral or authorization documents. Your insurerâ€™s website or customer service can provide a checklist for your specific plan.\\n---\\nFAQ ID: 020\\nQuestion: How do I find out what my coverage limits are?\\nAnswer: Coverage limits are described in your policy or benefits summary. You can also log in to your member portal or contact customer service to ask about annual limits, visit caps, or maximum coverage amounts for specific services.\\n---\\n\")]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "859012c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60f94f21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53dba4b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6018fe1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_19328/3709485258.py:37: LangGraphDeprecatedSinceV05: `input` is deprecated and will be removed. Please use `input_schema` instead. Deprecated in LangGraph V0.5 to be removed in V2.0.\n",
      "  builder = StateGraph(State, input=Input, output=Output)\n",
      "/tmp/ipykernel_19328/3709485258.py:37: LangGraphDeprecatedSinceV05: `output` is deprecated and will be removed. Please use `output_schema` instead. Deprecated in LangGraph V0.5 to be removed in V2.0.\n",
      "  builder = StateGraph(State, input=Input, output=Output)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAIsAAAFNCAIAAAC/vQu1AAAQAElEQVR4nOydB1wURxvGZ69Tj15FqqCCiooajR8mYkmMsfeIPWrsPfae2EvUmERjrzGiRhOjscZoglGjInYQpEiVDsfV/d67w/OAO+RwF5Z1/vI792Zn92bn2Zl5p/NIkkQYBsNDGGaDFWI6WCGmgxViOlghpoMVYjrVrVBiTMHjfwtyMmXFhSQikVJZytbn8jlKuUrfhcMlSGWpCgFBqD/KVBLAG9yNJEs5czhqrypVKZ+E5npS86+UOwdcCYN1D76Aw+Ehcyuum68oJMweVS9E9dSHHt3Ku3HmZe5LJcQLPK3InMPlwWMTpLyUN3BRKcpEPVKpVSReOxHqL2VCrfZGqiNeP94JUFdVVgmDlyOtQuCuQuXhiQh4b+QylbRIpVQigRnh7iP6ZKQ7qhZoV+hZVP75n9JlEtLOid+onXWj1raoNqOUKS/8nJ7wUCKVqFx9hL3GeyCaoVehg6vis9IUXkHmXUe4IXaRHFN47kB6caGy42Bn38ZWiDZoVGjrzBgLK87QhT6Ivdy6mHn99xyfRuYfDaHrFaRLoe+/jK3X1CJsgAt6B/hhdsz/ejo0bGWDaIAWhb6bGdOorXXb7k7oneGHObF1/Mw+GUl9SuIgqtk2NzagueU7JQ8wZoVv4lNJ5O8ZiGooVujIhgShGaf9u5G5laHPZLdb53IR1VCpUHpSYXqibOgCb/RO4uBq5uQp3L00DlEKlQqd2p7q5i1E7zB9J3sU5SmfP85H1EGZQi9TJZI8stdE2mtwDMfORXDpcCaiDsoUunAow8KGeruj1hE20LEwT4mog7I4zUqR+Ta2RNXL7Nmzf/nlF2QisbGxXbt2RfTg6G7G5RFXTqQjiqBMIYUchfasbgv7wYMHyHSqdlXlsbLjJT2WIIqgpsZ690r2tVMvx63xQ/Rw7dq1vXv33r9/38HBoUmTJhMnToSDkJAQ7VlLS8vLly8XFBTs37//n3/+gSQCZ9u1a/fFF1+IRCLwEBYWNmrUqIsXL96+fTs8PHzfvn3aC6dOnfrZZ58hqvl9T0rSE8nnX1HT3EVNGspILObxEU08evRo8uTJLVq0OHr06KxZs548ebJ48WKkkQ0+FyxYAPLAweHDh3fv3g0CbNy4EfyfO3du27Zt2jvw+fzjx48HBAR8++2348ePHzJkiIuLy82bN+mQB3CqI1AqVIgiqOnBKyxQ8fh0dQbeuXMHksKIESM4HA7EbMOGDWNiYsp7Gzx4MKQVb++S2tjdu3f//vvvSZMmIU2vnVgsnjFjBqoWrO35KsoEokgh6OGE/BLRQ3BwcHFx8ZQpU1q1ahUaGurh4aHL3/SBhAJZ3KJFiyCRKRQKcLGzs9OdBV1RdcHhchB1kUFNLge9kAopda9NaerXr79p0yZHR8fNmzf37Nlz3LhxkD7Ke4OzkK2BhxMnTkAONnz4cP2zAoEAVRd5WTJEHdQoZO8qUClp7Als06YNlDenTp2CEig3NxfSkzaV6AB7JyIion///qAQ5ITgkp9PZcXeJNKTpVwuogpqFAp8z0ohRzRx69YtKFHgAJIR1GOmT58OsZ+SkqLvRy6XSyQSJ6cSc18mk125cgXVEC8TpCILyqox1NzI3EpIEOj6GSpbO3RAngYm3LFjx7Kzs6Ojo8FmA6lcXV2FQiFIEhkZCXkaGBFeXl4nT55MSkrKyclZunQplF55eXmFhYXlb1i3bt3MzEywAJ8/f45oIDtD4eJjhiiCMqmhmvb4Bi0ZCxhpkHetXbu2Y8eOo0ePtrCwgPKGx1PbOGDg3bhxA1IVJKCvv/4aTL4+ffr06NGjZcuWEyZMgK8dOnR48eJFmRu2bdsW9APT7uzZs4hqlEolqUKdB7siiqCsjzUmKu/MrvQJG+iqtNYWIjYnZSZLx6z0RRRBWRrya2zNExCnd71A7zYpccWtPqJyxBmV1cy2PWz/PJpl7CwU5pBNGTwFBTvUZrSjQcvg4+Ozc+dORA+7NRg8BS1J0Ixk8FSzZs3Wr19v8NRvO5NF5ij4AztEHRSPJNmzLE5ozhkw3dPgWWMWsFQqhWLf4CmQDSIL0QP8LrwcBk+Bu7EqFJfLNTc3N3hqy9SYwXPcbZwoMxMQHWN9ts6I+aCPY8P3xOgd48d5z1y8hV1HUTxamPo+tzGrvC8doX7IC8PZsyzWzIpDuTyIpvFysmLltjlxPca71PGr7j69GmHnomd16pl3GkzLCCe6xpxKpcrts+O8gsy6VtccgRpBUli8/+skCxv+oJmeiB7oHVkPL5dcSr7/qX3Q+7SMmK1ZIrYkpsVJ/UMsOwykcXwg7bNTzh9KfXq7gMMhvIMgH6Cspl2DPL2Te/NcTlaq3MqWO2Q+7YMDq2mG19l9KfH3iyA9Qa2WL+RY2nIsxFy+oFRfpGZuXZm5V+q5XRwO0u8QIwhD87M0jhwClZpwp5kZZsA/oZ6eV74xvswP6bmT8mJVYYFCkqssLlLBba0c+GEDnFy9qLSqjVFNCmmRS+VXT2W9eFpcmC+HiFOpOPoz7rQVVkOz4zRT6XRfkYHuMa0jVJ6UShVBlK77lruA0EzPM6BQGYFfAW8Vh4v4QsLWSeDTyDzwvWqdpFatClUDI0eOnDhxIjSMIrbAtrng0LOnbfZmDVghpoMVYjpsUwha0KGZHLEInIaYDlaI6WCFmA4uh5gOTkNMByvEdLBCTIdVD6PSNE1zOKyaTssqhdhnJiCWKcS+LA5hhZgPVojp4HKI6eA0xHSwQkwHK8R0sEJMByvEdLBCTIdtz+Po6IjYBasUgjbTtLQ0xC7Y1VDP45VZq4QFYIWYDlaI6WCFmA5WiOlghZgOVojpYIWYDlaI6WCFmA5WiOmwavCfdiyjSkXXqsU1Att2O2FfMsIKMR3W9XdhhRgO+xRiyZokwcHBuikP8EQEQYC90Lt37wULFqBaDkvKoYCAAM4ruFwufHp6eoaHh6PaD0sUGjRokJlZqZWqWrRo4eXlhWo/LFGoe/fuPj6v98xydnbu168fYgXssbb1k1Hjxo39/f0RK2CPQp07d65Xrx4cODg4gFqILbzZlkt4Uvj0v3xpsd41mjX1yNJr9mlWQiSIkv80n+WW6uNyCKWqzJJ/hMb00tykZBm/kst0ayuWWWSRo1m8r6yjZvG+rJeZUfeixTbipsFNS9w5iFRpw1I2/GXWg3wV5tdPoX0qVPqg/DKFr5619P1L/GifxwB8LrKw47b55M2j+96g0I6FMdIixBdy5FK9mIWEpyp5EqRTSB0Xuk/1qopEuSggSq9dWUYh/U/tWe0zws/oB5LLI5QKUvtDOtSrYqo0Eaz+3deRAnJCUMusvEio9YRQEqWCVyr8JTfXC4w6mCXXgluZVT1RqZdRHT+k3jtnaOVPHl/9TFBzq9/cImxgRcu/VlRj/WF2jIM7r9MQL4Shh9SEvHP70sUOL0M62hvzYzQNbZ8XU6eeqG3POghDMwdXxQS1Eb/f1XCOZ9hS+OfXdJUSYXmqB69Ai+i/c42dNaxQwtNikRXbmuwYS+D/bJTGd580rJC8SIVY1Q3GaMRiM8ixZBKlwbOGE4pSBcaMYTMRQwdqW8DIDqE4K2M6WCGmgxViCsYKFawQUzDWtGNYIZ6QSypYtR9E7cWwQgqpEttyDAHnckwHK8QUsKXAbIwX+lghZkCYaMtBxxe7tvaqxRhuOYWeUBVWqKr06NVh774fkYkYK4fYNrK+DEuWzj79+y+oNmAsRbBcocePH6BaDmWWQnZ21oqVC+8/iKrr4dW9e9+kpIS/rl7as+so0iwqtmPn1sjrV9PTU4OCgnt27/fee23BPS4udsSo/lu/3XPw4K6r1y47Ojp9+EGn0Z9P5Gra4bOyXm79bn30/bvFxcUtWrQeMniUh4cnuEccO3zw0K6pU+YsWjyrR49+E8fPgPucPHX0v9s3UlNfeHn6dOnSo3u3PuDzw7AQ+Fyzdtl332849ctlOD5z9tTJUxFxcTHe3n7tP+zUu9fA0huDGiAhIX7X7u/v3L1FkmRgYOMB/YY0aqTeqLKoqOirFfP/++9feLrx46ZnZqZf+evi3t0RiGoMpyE+n8PjmdamsHrt0oTE+DWrty5ftv769Wvwpxvqvmnz6qMRB3v26H/wwKl2oWGLlsz688oFza+o1/Vdt355WNhHf5z5Z96c5Ud+3n/p8jlwVCqVU6ePgXiZOmXuzh9/srWxGzd+aPKLJDglEAiKigpPnjw6Z/ZSEBtcvt267saNfyZP+nLlik0gzzebVkVevwbuZ06rP2fOWKCV5/yFM6tWL/GvV//g/pOjRo6HIG3Zuq7ih5LJZFOmjYY3ZtXKzevWfMfj8ubNnwpvDJxav/HrZ7FPN27Y/tOh3+B1PH/hd5qWKTbSxypXKUxpl8vNzYmMvNqvb3jDBkH29g7Tp82H11l7SiqVnv3j10EDh3X7tLfYWtzl4+5h7T/au2+77tp2oR0+aNcBHq9Jk2Zuru5PnjwEx3v37sDLO3fOslYt29jZ2X8xdoq12CYi4iDSbIsLcTRgwNAOYR/VqVMXXBYsWLFmzdZmTVs0DQ6B1BPg3+DfG3+XD+Tp0ycaN246ZfJsW1s78Dx86NgTJ45A0q/guRITn4MHSGqgq69vvUULVy5ZsgYSTUFBwZ9/nu/XLxx+C4I3ftw0nnZ41VtAr6UQ++wpfAYFNdF+tbS0bNaspfYYYhzexBYhrXWeg5s0f/YsJjevZOyEv38D3SlLS6uCgnw4uBd9BzSDeCwJPUHAVXej/tP5rB8Q+PrnSfLYscNDhvWGbA3+Hj1+kFMu3lUqFWSY+sFo2rQFOEbdu42MA2+AjY3tytWL9x/YGR19F3IFeAng6RIS4kCn+vUDdcFr0CDoLRUyrT5kKvn5efBpYWGpc7G2FmsPtDE+cfLIMpdkZ73UrnhpcKsTuEoul2sLEh0QWbpjyOu0BxDLs+dOlstln4+aEBwcYmVpVf63kCa/ghtCcQh/pYJRYRoSCoXfbNj+2+kTkCXChW5udYYNGd2xYxcoI+GsuZm5zqf+cRUgSJpbfYRCEXzKZa9HrGTnlDy5vYN6GNj0afPc3T30L3FycsnKyjR2Q8gqzczMvlq+Qd+RyzHQk//k6aNHj+6vXbO1+atUC+o6OjiV8SYSiczNzTt1/CQ0NEzf3c31DSPO6tb1gjx2+LCxYBT8fubk1ysXenr5iMU2cEoqk+q8FRYVoreANLVNgcfjmFRl1VpZcfGxXl7qKSKQTcPzODurB7vWca8LbyIcQP6g9QyvLWQIEF9Zxl9fX19/iUQCKrq7lcTgi5RkG7GBLdOhCIRPnSTx8c/gz9vL1+A98wvydcGAJJWSkuzk5IyMA2UhWKcff9QNBG7TJrRVq/c/6vI+5NutWr4PZ+HNgPIJadLxg/tRQpEI0YDhckihUJk0GRTi0dPTe8/ebWBugTwbv1nh6uquPQVKDBs6BkwDKPwhqwErbsascRu/WVnx+ov0BQAAEABJREFUDSFBtGzZZu3aZWlpqaDBiV9+HvtF+JkzJ8v7BPMacsufjuzLy8+DCN28ZU2LkPdS01KQJo8CC/7mzcjbd25CsfH5yAnXrl2GCixEKARm6bI502aMlclkFQQjLy939Zql332/MSk5EayGAwd3wX2CApvAbaHQ/XHHt+CemZmxYeOK/II89HbQ3qYwa8ZCKFHCh/ScOm00FP7wGHxeifU5oP+QmTMWHjy8+9PuH4ApDBnL9Onz33jDFV9tbNeuw9Llc6AR5djxwx06fNyr14Dy3pydXebNXf7g4b3uPdrPnT8VzOhu3fo8fBg9dLi6SvTZoBFQT1qwcLqkWAL1mG3fH4iKut2zd0d4SwoLC6BioE3fxgAZpk2dC5Y0PBdYIvfu3V6/7nttPgG2fv2Ahp+PHti3/8dwK7BI0dthLMsyPG57z7J46GPtPcUTVRp408EIhvjSfp0zbwrUHpYtXYveDSBXAFNz144jqErsXhwzZpXfK+unFIbTEMFRz8dApgAtYJB6oB0BpNq3f8etW9e7aSr2mLfEiC2nnv5iWpvCokWr1qxduv3HLRkZaZ51vRctWAnlAaoNfNrtA2Onvvxycdv3P0A1imGFqlD3gvaC5UvXoVrItm0HjZ2C1iZUOaCpAr0duBfcKK4ubogB0NumgHlbSBOtbegFJ/BwueqEMLEHD3rB8TgFhoBzOaaALQWmY1ouxxdyOFg7ZmBYB7lUhUfWMwScUpgOVojpGFZIYMYlFUqEqS44HCTgGjll0NXMAhUXY4WqicQY9VAOZJJCH/ZzkBTgKms1EXUpx9reaHFjWCGxvZmLt+DAihiEoZk7V9Oy06Thc72MeahofbnIMxm3L+a6+pi71zMzMxegCiEqmqVk0D9pvLUQVf6+r88T6NWabm/w/AZP5e5MqofiUFz34HAVmcnS+AeFkjwl9K5W4PMNKwCCSA8jC4qLlEo5ophKxhMD0K5LSC1cLsEVILEjr//UNww1YMmK6DpGjhw5ceLE4OBgxBbYVh9i3+btWCGmgxViOlghpoMVYjpYIaaDFWI6bFNILpfTNJ+0psBpiOlghZgOVojpsOphoI1RpVJxjSxcXUthlULsMxMQyxRiXxaHsELMByvEdHA5xHRwGmI6WCGmgxViOlghpoMtBaaD0xDTYVu7nKenCWsR1QpYpRCHw4mPj0fsgl0N9TyewqR18WoDWCGmgxViOlghpoMVYjpYIaaDFWI6WCGmgxViOlghpoMVYjqs2mWNy+WqVCqWzZ1m2z547EtGWCGmw7r+LqwQw2GfQixZkyQ4OBjMBIIgtJYCdOXBQWho6DfffINqOSwph7y9vbVruIM2WqmcnJxGjRqFaj8sUahLly5ldjwMCAho1KgRqv2wRKGhQ4fWqfN6z0GxWDx48GDECliikEAg6Nu3r272nY+PT8uWLRErYE99aODAga6u6t0rzc3Nw8PDEVuoorWd/KxQkkcSnLIL4+mWM9QtcKjxUbKGnmmLOBIVbVRlcP3Avl0mHD9+ws3Nzd2meWyU8Q1SCVL9r9TdSA4q5WJoCcnXv6l5ljJfjXgt8aDyaWyFqoTJ1vbpPcnx0RJ1AFXorQx1QwoYXA3RhCUSDepW/oeqtDxkmYvKh6qUS2nfXD5SKpCFmDN8kQ8yEdMUunIi7UFkfkhHh4AQG4QxBaVSeflwSlJs8YR1fiZdaIJCx7cmvnwh7T/TtB/A6BMXnX31+Mtxa02IQxMshZQ4aftBjNgyrvbiHWRrbs07uimx8pdUVqF/z2ZwuMjR/a12kMcAzl7CrDRp5f1X1pYryFYRBNu6KmoEKzFfpTDBUKmsQioVUsrwPgMUoFKaFpN4dxumgxViOlghpoMVqn5Ma8+orEIEgXc5pgrTDK5KpyES73JcM1RWIaxOTVHpXK504zymypjaC1P5NETiYogaCNP2m8K2XHVDknTZcgjbchRBmpTNVboxlEQ1a8v16NVh774fK/YTcexwWMdqHUDy7FnMh2Eh9+7dQbTBKluuYYOg8MFsGMWoD6vKoQYNguAPsQt6FTpz9tTJUxFxcTHe3n7tP+zUu9dAaJlIfpE0fETfsaMn9+o1APwUFhZ+Ft69ffvOkybMnLdgGp/H9/T0PvzTXpVK5ePtN3PGQj8//zK3PXb8p8jIvx4+jBYIhU0aNxs5cry7m3o4I+RyW79bf+Hcv0iTKw4fNjY3N2fP3m1mZmYtQlpPGD/D3t6h4gBHXr/20097Hz2+b2fnEBTUZPSoidpL4uOfrVy1KCb2iY2N7cL5K7bv2OLl6TN92jxkOuohRKaU6JUth6pgKZy/cGbV6iX+9eof3H9y1MjxRyMObtm6DtwhNocOGb1j19acnGz4CgeWFpZjPp8Exzwu7/adm3Bw5vS1Pbsj7Owd5i+cplSW2qEcMv3NW9YEBjZZunTt7C+XZGdnffX1/PK/zufzIa45HM6J4xf27Iq4F31n954fKg7wk6eP5syd3LRpi907j06aOCs29smq1YuRZhDIl3Mm2trZHzpwavXKLYeP7E1MfF7lpQYJuiwFZPK2vqdPn2jcuOmUybNtbe2aNW0xfOjYEyeOQITCqQH9hzg5uXz3w8bnz+NOnjw6d+5yoVCovUomk0JZAknNzdUdEkFaWmqZcrhhw0a7dhz5bNDwpsEhLULe69d3MCSm3Lzc8gFwd/cY/NkIK0srSAeQhp48eVhxgKPv3RGJRHCJs7NLq5Zt1q35buDAYeB+89b19PQ0SE+Ojk4+Pn6TJ34JSbPaGsEqbSmod71AlQfyqOj7d4eEf65zgXcTHKPu3W4XGsblcr+ctfiLcUMgcvv2+ayhXuEB+aFuncU67nXh83lCXHBwc50HuPbFi6Rvt657+CgackitY052lthaXCYM/v4NdMdWVtaFhQWoQoIaBRcXF8+ZNyWkeavWrUPruHvASwDukJhAOW9vX6030M/JybnqChGmVf7pGnog17Bj51YwRrV//Qd+Au7aNATUD2gIKQCyizatQ/UvFAlFr49F6uMyMXvt2p9QXAUENNy4fvvF8zdWr9piLAymtsZDhrxyxSYHe8dt2zeHD+k5Y+a46Oi72jCbmZUaQiMSmaGqQpCmZUZ0WQqQa5mbm3fq+EloaJi+u5tryQwFyLsgPbVpE7px08pt3x/QDYrX1wPeaM2tRPp3+PX08UaNgqFg034tKMhH1AGZG/xB7nrr1vWIY4fmzptyLOIcpD/Ie/W9SSRFqKqQCNFSDhEcky0FX1///IJ8yCi0f0GBTeztHCB/gFNSqRQKYShvIK9LT0s9dHiP7qrYZ08hl9cea0sOyPr1b5uXl+vo4KT7+tdfFxFF3Llz6/q/f8OBg4Nj585dx4+bDuFPTUtxdXGD7DQhIV7rDWzRjIx0VFVKRrVXmkorZHqu+/nICdeuXT79+y9Q/ECKWbpszrQZY2UyGZza9uNmDpfbv1+4tZX16NGTwCB+kZKsvcraWrxp8+q8/Dz427tvO2T6jRs11b+tn6//jZuRYPIpFIqfjx7QOkI8orcGCs7FS2ad+vUYGJkPHkYfO34YpHJxdoUySSAQrFm3DNL005jHK1YutLS0RFWFrjSkMr3VB/IiyL6iom737N1xxqxxkH0tX7Yecj/1wx87PHP6Aq1F8GnXXr4+9bR2LQB1IC8v3379P+7eo31q6ovlS9eX2ZNrxIhxkBHNXzCt00etwdIDgxuKtNlzJoFxj94OMAs/6dJzy7drIcBTp402N7fYsH4bBBL0+Gr5hmKJpGu3dmPGDg79X3sHvURMN5Udt33+YNqTWwXhC30RnSxaPAvKlXVrv0PMZvjIflBThooEMp3bFzLv/ZUzfkNlh27j3gem8271PkBxCOaZsbP7950Qi6th1g09/UNktfQ+LFm8GtGJumjcdtDY2crLA40aqOrQNNaHQLWkC+INgOmMahR1VkRLL7haHdzJSgEkaVo7TmUV4nAQB09OoQKSoCeXU6nUf5i3hyBN633A1jbTwQoxncqXQwSHiy0FSiBoseVUKlKlxOOCKQGXQ+wCK8R0Kt0ux0U8AcK8PeqlqUxJF5X1a2PPxfUhSijMVQiFJpgKlW0naN7BgVSRzx9lI8zbkRpfaF/HhLF2JrTkeAWJ/j7xEmHeglsXUqQSssfYupW/xLTVy+5cyYr8NSughXVIp+rrBmYHKc/zbv6Rk5su+2I1bauXablyPO3hv/kKmWYFQEQN6kBQ1T9IUtYET1A375DHIVQEaW3HC5/rhUyk6iuiZyTJDOaR5ZdEJF7FG2k0ECWrWuqtvUkYqtcRul4Q0shvrVq5slevHvX86+v/XPm7lQTp1eUGfk69urq6HZooUaqUh1I3f7XgJlk+oK/gcpGdcxVN4arXhxzrMNH6zsx7ZmVPOLqxp2bAthqrQqHQDftmB1ghpoMVYjpYIabDQoWqPDuOmeA0xHSwQkwHK8R02KaQXC7HCjEanIaYjlKpxAoxF/YlIMQyhdhXCCGchpgPVojpYIWYDtvKIZY1yiGchpgPVojpYIWYDi6HmA5OQ0yHVc9DkqS3tzdiF2x74+Lj4xG7YFczMI8HGR1iF1ghpoMVYjpYIaaDFWI6WCGmgxViOlghpoMVYjpYIaaDFWI6bFOozHZSLIBta5dyuVyWJSO2KcS+jI5tCkEfK/S0IhbBuh5J1qUhgqzZrYoponPnztoSKCsrSygUgr0gk8kCAwP37duHajksSUMEQaSnl+yrJZWqd0SztbUdM2YMqv2wpBxq165dmcygbt26bdu2RbUflig0YsQIV1dX3VcLC4tBgwYhVsAShZydnTt27Kj7CglI/2uthj3W9rBhwzw8POBAIBD069cPsQX2KCQWiz/++GOw6CABffrpp4gt1IC1HXkmPfaupDBXqZCTpIp84+5gJav1VW7FRM1qj5XxV6mlHAnNRrRcHiGy4Ni7Ct7rYufoXvXdjKtGtSp0YOXz7HQ5RCBPwDUTi8xsBWYWAi6Pp4ssdeyS5dc6JDQxr9swQW8lR+3upmWvQqV8GUSnUMULSKpIsN2L82SF2TKZRK6Sq/hComELq7Y9mbfb51vy88bEtOdSvhnPxd9W7Fz17WZrnMSo9PzMIi4XdQ538gq0QvRDu0JQvf9hdjyHx/Fr48aaYe/JDzJyXhS4+Ql7fuGBaIZehXJfyvZ9lWDnYeVW3wGxjsdXE0RCNHQhvWP5aVQoO116YEViUCe2TUbQ5+HlOBcPYc8JNKYkuhSS5Mp2LE5gtzxanv79nM8nh9G2Hzdd9aFdyxJc/Kthf+Cap14bz8I88vddLxA90KLQ/hVxAnOeg5ctejcIDPOOjSqSFcoQDVCvUPyDgtwMpV9r2o0cRmFmK9q3MgnRAPUKXTySYSYWoncM3xaukkJV0tNCRDUUK1SULy3KVfq0rOG9tytgzeaBEado2R9eaMG/dCQDUQ3FCl08lMkXcdE7iaOvOPcl9YC80bAAAATZSURBVEMkKFYoOa5YaPmO7pdn42wFjXvR13IQpVDcDKOQkk716Gr9VSoVv5///uGTazk5qd6eTdq06tsw4H1wT0mLXbdl0KQxOy9e2RP98E+xtVNwo45dOo6Hngg4m5r+7HDE0rSMOD+f5h3ajUB0wuGhZ1H5Qe9TWc2gMg1J8hVQ/bV1FSN6OP7r2r/+OdS2Vd+50080Cmy/9/DsqOiL4M7jqtch+fmXFU0bd1656OqgPkv+vHbg7v3zSL0GhvzHvVNsxE6zJv30SacJl6/uz8/PRLTBE/KyMynO6KhUKCm2CNGGXC69eee39v8b2rplLwtzcavm3UCPc5d36Dw0CWzfJCiMx+P7ejezt3VPSn4EjvceXMrJTev28VRbGxcXJ5+eXWdIivMRbfD4XEkBxVtuUqmQtJDG/UATXzxUKGT+fq10Lr5ezVLSYgqLcrVf67g10J0Siay0SmS+TBTwRXa2JYNMrK0cbMTOiDY4PMhZKS7aqSyHeEKCoGo7u3IUSwrg89sfR5dxzy94yeWon4IgDERNkSRPIDTXd+HzRIhGSA6X4nZOKhWydebT11Juba3uv+jTfY6DXanWCluxS57xosXczFoqLZX3Fkupr1TqUMqUPAHF7yiVCjl7mEN3siRHYmZDvTnnaF+Xz1c3VYBJpnXJL8iCF0IIScR4yWJr4yqXF0Nm6OrsB1+TU57k5VNfqdShkCvFdhQvn0Zxpgnd+FkptLykoESnDz8/d2nHs+d35AoZWHHbdk889usbWgcCG4TyeIKfT6yQyYpz8zL2H5lvbk6XqYk0acjNl+JclOL6kNiBl/eSLovuw/+Fu7n6X/pr79PYGyKRpZdHo77d51Z8iZnIcuTg9b/9sWX+V+3BZACD+7+oszQVlTKZTKVCbbpS3JtMcQ/eo5u5Fw5lBHZgf8ddeeL+S1YWy0cto7grj+Jcrn6ImMcnkh/QmNczFkmOrOF71ohqqB98ExBi+fBGgXtDR2Me5n8VZtBdpVKCxWzMXp89JcLSgrLWlB37psUl3DV4Csw/sNENnlo+7wIyQsqTTA4HtfnE6FNXGVrGKWybG2NmY+7RyHDdMCu7Kh3GdrZU9mjk5WUqlIa7RKVSiVBoZmoYHlyIb97BptVH9ohqaFEoL0e2d8k7MYxES0xkkkBADpnnhWiAlnEK1jaChq0tH16KR+8AaTFZcomcJnkQfWN92vdzcfUSRZ+LQ6wm6WFaZnzuF6v9EG3QO+b033NZt85nN/jAC7GRhLtp+RlF49fRKA+qhnHbZ/elPv2vQOxq1HCopTz5K4EkVWNW0DWQUUd1zH3IfCE5siFZpUT2da1dA6i3dqqZmMjE4nyFq4+o94Q6iH6qb/7QHwdSYm4XkirENeOInS0cvW1q0VSIvPTCrOTcohyZSk5a23F7T3W3qK7hGNU9B+/25ayoa7n5L5XaeVXQp6OenqW3nhW4kJqOQFIzc6v89KvX7iUXaJ3Uk/RKzf3STeLSdyEJ3f3L/0T5X1SpXdT/wVUCEcfZU9BtdHWkG31qck0SaMTLyYQKIkHo982q4+h1pBqYG6eeL8kBLwRRPuQVT7yrwAuhNy3v9WkejzC34br4iFw8qntypA6WrBrDYti28hL7wAoxHawQ08EKMR2sENPBCjGd/wMAAP//4n0nQQAAAAZJREFUAwA9lVZlnsJeDAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from langgraph.graph import StateGraph,START,END\n",
    "from langgraph.graph.message import add_messages\n",
    "from typing import Annotated, TypedDict\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "    #input\n",
    "    user_query: str\n",
    "    #output\n",
    "    sql_query: str\n",
    "    sql_explanation: str\n",
    "class Input(TypedDict):\n",
    "    user_query: str\n",
    "class Output(TypedDict):\n",
    "    sql_query: str\n",
    "    sql_explanation: str\n",
    "\n",
    "chat_model_1 = ChatOllama(model=\"llama3.1:latest\",temperature=0.1)\n",
    "chat_model_2 = ChatOllama(model=\"llama3.1:latest\",temperature=0.7)\n",
    "\n",
    "generate_prompt = SystemMessage(\"\"\"You are a helpful data analyst who generates SQL queries for users based on their questions.\"\"\")\n",
    "explain_prompt = SystemMessage(\"\"\"You are a helpful data analyst who explain SQL queries to users.\"\"\")\n",
    "\n",
    "def generate_sql(state:State) -> State:\n",
    "    user_message = HumanMessage(state[\"user_query\"])\n",
    "    messages = [generate_prompt, *state[\"messages\"], user_message]\n",
    "    res = chat_model_1.invoke(messages)\n",
    "    return {\"sql_query\": res.content, \"messages\": [user_message, res]}\n",
    "\n",
    "def explain_sql(state:State) -> State:\n",
    "    messages = [explain_prompt, *state[\"messages\"]]\n",
    "    res = chat_model_2.invoke(messages)\n",
    "    return {\"sql_explanation\": res.content, \"messages\": [*state[\"messages\"], res]}\n",
    "\n",
    "builder = StateGraph(State, input=Input, output=Output)\n",
    "builder.add_node(\"generate_sql\",generate_sql)\n",
    "builder.add_node(\"explain_sql\",explain_sql)\n",
    "builder.add_edge(START, \"generate_sql\")\n",
    "builder.add_edge(\"generate_sql\",\"explain_sql\")\n",
    "builder.add_edge(\"explain_sql\", END)\n",
    "graph = builder.compile()\n",
    "\n",
    "from IPython.display import Image, display\n",
    "\n",
    "png_bytes = graph.get_graph().draw_mermaid_png()\n",
    "display(Image(png_bytes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "3f8180fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's an example SQL query that calculates the total sales of each product:\n",
      "\n",
      "```sql\n",
      "SELECT \n",
      "  product_name,\n",
      "  SUM(sale_amount) AS total_sales\n",
      "FROM \n",
      "  orders\n",
      "GROUP BY \n",
      "  product_name;\n",
      "```\n",
      "\n",
      "This query works as follows:\n",
      "\n",
      "- `SELECT` selects the columns we want to see in our results. In this case, we're selecting the `product_name` and calculating the sum of sales for each product.\n",
      "- `SUM(sale_amount)` calculates the total amount sold for each product.\n",
      "- `FROM orders` specifies that we're working with the `orders` table.\n",
      "- `GROUP BY product_name` groups our results by product name, so we can see the total sales for each product.\n",
      "\n",
      "For example, if your database has a table called `orders` with columns like this:\n",
      "\n",
      "| order_id | product_name | sale_amount |\n",
      "| --- | --- | --- |\n",
      "| 1      | Product A    | 10.00     |\n",
      "| 2      | Product B    | 20.00     |\n",
      "| 3      | Product A    | 15.00     |\n",
      "\n",
      "The query would return:\n",
      "\n",
      "| product_name | total_sales |\n",
      "| --- | --- |\n",
      "| Product A    | 25.00     |\n",
      "| Product B    | 20.00     |\n",
      "\n",
      "Let me know if you have any questions or need further assistance!\n"
     ]
    }
   ],
   "source": [
    "user_input = {\"user_query\": \"total sale of each product\"}\n",
    "result = graph.invoke(user_input)\n",
    "print(result[\"sql_query\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e8d67f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b005fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9213be59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='I said that the capital of France is Paris.', additional_kwargs={}, response_metadata={'model': 'llama3.1:latest', 'created_at': '2026-02-14T17:19:34.459274199Z', 'done': True, 'done_reason': 'stop', 'total_duration': 284490183, 'load_duration': 73147643, 'prompt_eval_count': 50, 'prompt_eval_duration': 35648202, 'eval_count': 11, 'eval_duration': 166846873, 'model_name': 'llama3.1:latest'}, id='lc_run--019c5d2a-391e-70f2-9dc2-030355039ae6-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 50, 'output_tokens': 11, 'total_tokens': 61})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_ollama.chat_models import ChatOllama\n",
    "\n",
    "promt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a helpful assistant.\"),\n",
    "    (\"placeholder\", \"{messages}\"),\n",
    "])\n",
    "\n",
    "chat_model = ChatOllama(model=\"llama3.1:latest\")\n",
    "\n",
    "chain = promt | chat_model\n",
    "\n",
    "chain.invoke(\n",
    "    {\"messages\": [(\"human\", \"What is the capital of France?\"),\n",
    "                  ('ai', \"The capital of France is Paris.\"),\n",
    "                  (\"human\", \"What did you say?\")]\n",
    "     }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "900dd556",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'chatbot': {'messages': [AIMessage(content='Hello Porya! Nice to meet you. Is there something I can help you with or would you like to chat?', additional_kwargs={}, response_metadata={'model': 'llama3.1:latest', 'created_at': '2026-02-14T18:04:15.622264047Z', 'done': True, 'done_reason': 'stop', 'total_duration': 1796498871, 'load_duration': 1378463442, 'prompt_eval_count': 18, 'prompt_eval_duration': 22355648, 'eval_count': 26, 'eval_duration': 379145321, 'model_name': 'llama3.1:latest'}, id='lc_run--019c5d53-1c81-7b90-9697-2b5f50c18ba3-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 18, 'output_tokens': 26, 'total_tokens': 44})]}}\n"
     ]
    }
   ],
   "source": [
    "from typing import Annotated, TypedDict\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "builder = StateGraph(State)\n",
    "\n",
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "chat_mdoel = ChatOllama(model=\"llama3.1:latest\")\n",
    "def chatbot(state: State):\n",
    "    answer = chat_mdoel.invoke(state[\"messages\"])\n",
    "    return {\"messages\": [answer]}\n",
    "builder.add_node(\"chatbot\", chatbot)\n",
    "\n",
    "builder.add_edge(START, \"chatbot\")\n",
    "builder.add_edge(\"chatbot\", END)\n",
    "\n",
    "graph = builder.compile(checkpointer=MemorySaver())\n",
    "\n",
    "from IPython.display import Image, display\n",
    "\n",
    "png_bytes = graph.get_graph().draw_mermaid_png()\n",
    "display(Image(png_bytes))\n",
    "\n",
    "from langchain_core.messages import AIMessage, HumanMessage, SystemMessage\n",
    "\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "inp = {\"messages\": [HumanMessage(content=\"hi! I am Porya.\")]}\n",
    "for chunk in graph.stream(inp):\n",
    "    print(chunk)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7a43fd70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result 1 (current response): {'messages': [HumanMessage(content='hi, my name is Jack!', additional_kwargs={}, response_metadata={}, id='9c7c359e-39ea-48a0-9d82-b647b599c811'), AIMessage(content=\"Hi Jack! It's nice to meet you. Is there something I can help you with or would you like to chat for a bit?\", additional_kwargs={}, response_metadata={'model': 'llama3.1:latest', 'created_at': '2026-02-14T18:08:02.955557342Z', 'done': True, 'done_reason': 'stop', 'total_duration': 561377682, 'load_duration': 73197889, 'prompt_eval_count': 17, 'prompt_eval_duration': 38728223, 'eval_count': 29, 'eval_duration': 431604721, 'model_name': 'llama3.1:latest'}, id='lc_run--019c5d56-9959-7f10-980e-e4cf85d74712-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 17, 'output_tokens': 29, 'total_tokens': 46})]}\n",
      "Result 2 (current response): {'messages': [HumanMessage(content='what is my name?', additional_kwargs={}, response_metadata={}, id='24c88078-3083-49b8-bdb7-c8336c70542a'), AIMessage(content=\"I'm happy to chat with you, but I don't actually know your name. This conversation just started, and I don't have any prior information about you. Would you like to tell me what your name is?\", additional_kwargs={}, response_metadata={'model': 'llama3.1:latest', 'created_at': '2026-02-14T18:08:03.689003447Z', 'done': True, 'done_reason': 'stop', 'total_duration': 731575046, 'load_duration': 64960715, 'prompt_eval_count': 15, 'prompt_eval_duration': 19131056, 'eval_count': 45, 'eval_duration': 621712301, 'model_name': 'llama3.1:latest'}, id='lc_run--019c5d56-9b8c-7403-bc1d-83f131de3968-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 15, 'output_tokens': 45, 'total_tokens': 60})]}\n"
     ]
    }
   ],
   "source": [
    "thread1 = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "# Run first interaction\n",
    "result_1 = graph.invoke({\"messages\": [HumanMessage(\"hi, my name is Jack!\")]}, config=thread1)\n",
    "print(\"Result 1 (current response):\", result_1)\n",
    "\n",
    "# Run follow-up interaction\n",
    "result_2 = graph.invoke({\"messages\": [HumanMessage(\"what is my name?\")]}, config=thread1)\n",
    "print(\"Result 2 (current response):\", result_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c4bcb637",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Invalid input type <class 'dict'>. Must be a PromptValue, str, or list of BaseMessages.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_core\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmessages\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AIMessage, HumanMessage, SystemMessage\n\u001b[32m      3\u001b[39m \u001b[38;5;28minput\u001b[39m = {\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m: [HumanMessage(\u001b[33m'\u001b[39m\u001b[33mhi! I am Porya.\u001b[39m\u001b[33m'\u001b[39m)]}\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mgraph\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mprint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/LangChain/.langchain_venv/lib/python3.12/site-packages/langgraph/pregel/main.py:2647\u001b[39m, in \u001b[36mPregel.stream\u001b[39m\u001b[34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability, subgraphs, debug, **kwargs)\u001b[39m\n\u001b[32m   2645\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m task \u001b[38;5;129;01min\u001b[39;00m loop.match_cached_writes():\n\u001b[32m   2646\u001b[39m     loop.output_writes(task.id, task.writes, cached=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m-> \u001b[39m\u001b[32m2647\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrunner\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtick\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2648\u001b[39m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwrites\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2649\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstep_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2650\u001b[39m \u001b[43m    \u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m=\u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2651\u001b[39m \u001b[43m    \u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m=\u001b[49m\u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43maccept_push\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2652\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   2653\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# emit output\u001b[39;49;00m\n\u001b[32m   2654\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01myield from\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_output\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2655\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubgraphs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mqueue\u001b[49m\u001b[43m.\u001b[49m\u001b[43mEmpty\u001b[49m\n\u001b[32m   2656\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2657\u001b[39m loop.after_tick()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/LangChain/.langchain_venv/lib/python3.12/site-packages/langgraph/pregel/_runner.py:162\u001b[39m, in \u001b[36mPregelRunner.tick\u001b[39m\u001b[34m(self, tasks, reraise, timeout, retry_policy, get_waiter, schedule_task)\u001b[39m\n\u001b[32m    160\u001b[39m t = tasks[\u001b[32m0\u001b[39m]\n\u001b[32m    161\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m162\u001b[39m     \u001b[43mrun_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    163\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    164\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    165\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconfigurable\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    166\u001b[39m \u001b[43m            \u001b[49m\u001b[43mCONFIG_KEY_CALL\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    167\u001b[39m \u001b[43m                \u001b[49m\u001b[43m_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    168\u001b[39m \u001b[43m                \u001b[49m\u001b[43mweakref\u001b[49m\u001b[43m.\u001b[49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    169\u001b[39m \u001b[43m                \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    170\u001b[39m \u001b[43m                \u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m=\u001b[49m\u001b[43mweakref\u001b[49m\u001b[43m.\u001b[49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    171\u001b[39m \u001b[43m                \u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m=\u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    172\u001b[39m \u001b[43m                \u001b[49m\u001b[43msubmit\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msubmit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    173\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    174\u001b[39m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    175\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    176\u001b[39m     \u001b[38;5;28mself\u001b[39m.commit(t, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    177\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/LangChain/.langchain_venv/lib/python3.12/site-packages/langgraph/pregel/_retry.py:42\u001b[39m, in \u001b[36mrun_with_retry\u001b[39m\u001b[34m(task, retry_policy, configurable)\u001b[39m\n\u001b[32m     40\u001b[39m     task.writes.clear()\n\u001b[32m     41\u001b[39m     \u001b[38;5;66;03m# run the task\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m42\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43mproc\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43minput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     43\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ParentCommand \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m     44\u001b[39m     ns: \u001b[38;5;28mstr\u001b[39m = config[CONF][CONFIG_KEY_CHECKPOINT_NS]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/LangChain/.langchain_venv/lib/python3.12/site-packages/langgraph/_internal/_runnable.py:657\u001b[39m, in \u001b[36mRunnableSeq.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    655\u001b[39m     \u001b[38;5;66;03m# run in context\u001b[39;00m\n\u001b[32m    656\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(config, run) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[32m--> \u001b[39m\u001b[32m657\u001b[39m         \u001b[38;5;28minput\u001b[39m = \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    658\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    659\u001b[39m     \u001b[38;5;28minput\u001b[39m = step.invoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/LangChain/.langchain_venv/lib/python3.12/site-packages/langgraph/_internal/_runnable.py:401\u001b[39m, in \u001b[36mRunnableCallable.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    399\u001b[39m         run_manager.on_chain_end(ret)\n\u001b[32m    400\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m401\u001b[39m     ret = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    402\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.recurse \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, Runnable):\n\u001b[32m    403\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m ret.invoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 14\u001b[39m, in \u001b[36mchatbot\u001b[39m\u001b[34m(state)\u001b[39m\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mchatbot\u001b[39m(state: State) -> State:\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m     answer = \u001b[43mchat_mdoel\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     15\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m: [answer]}\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/LangChain/.langchain_venv/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py:403\u001b[39m, in \u001b[36mBaseChatModel.invoke\u001b[39m\u001b[34m(self, input, config, stop, **kwargs)\u001b[39m\n\u001b[32m    388\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    389\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m    390\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    395\u001b[39m     **kwargs: Any,\n\u001b[32m    396\u001b[39m ) -> AIMessage:\n\u001b[32m    397\u001b[39m     config = ensure_config(config)\n\u001b[32m    398\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[32m    399\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mAIMessage\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    400\u001b[39m         cast(\n\u001b[32m    401\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mChatGeneration\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    402\u001b[39m             \u001b[38;5;28mself\u001b[39m.generate_prompt(\n\u001b[32m--> \u001b[39m\u001b[32m403\u001b[39m                 [\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_convert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m],\n\u001b[32m    404\u001b[39m                 stop=stop,\n\u001b[32m    405\u001b[39m                 callbacks=config.get(\u001b[33m\"\u001b[39m\u001b[33mcallbacks\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m    406\u001b[39m                 tags=config.get(\u001b[33m\"\u001b[39m\u001b[33mtags\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m    407\u001b[39m                 metadata=config.get(\u001b[33m\"\u001b[39m\u001b[33mmetadata\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m    408\u001b[39m                 run_name=config.get(\u001b[33m\"\u001b[39m\u001b[33mrun_name\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m    409\u001b[39m                 run_id=config.pop(\u001b[33m\"\u001b[39m\u001b[33mrun_id\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[32m    410\u001b[39m                 **kwargs,\n\u001b[32m    411\u001b[39m             ).generations[\u001b[32m0\u001b[39m][\u001b[32m0\u001b[39m],\n\u001b[32m    412\u001b[39m         ).message,\n\u001b[32m    413\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/LangChain/.langchain_venv/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py:386\u001b[39m, in \u001b[36mBaseChatModel._convert_input\u001b[39m\u001b[34m(self, model_input)\u001b[39m\n\u001b[32m    381\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m ChatPromptValue(messages=convert_to_messages(model_input))\n\u001b[32m    382\u001b[39m msg = (\n\u001b[32m    383\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mInvalid input type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(model_input)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    384\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mMust be a PromptValue, str, or list of BaseMessages.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    385\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m386\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n",
      "\u001b[31mValueError\u001b[39m: Invalid input type <class 'dict'>. Must be a PromptValue, str, or list of BaseMessages.",
      "During task with name 'chatbot' and id '66cfa8f3-96d1-6db5-37c4-3766fb02d3eb'"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import AIMessage, HumanMessage, SystemMessage\n",
    "\n",
    "input = {\"messages\": [HumanMessage('hi! I am Porya.')]}\n",
    "for chunk in graph.stream(input):\n",
    "    print(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "577ce475",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "from langchain_postgres.vectorstores import PGVector\n",
    "\n",
    "# Load the document\n",
    "loader = TextLoader('test.txt')\n",
    "raw_text = loader.load()\n",
    "\n",
    "# Split the document into smaller chunks\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
    "chunks = text_splitter.split_documents(raw_text)\n",
    "\n",
    "# Initialize the Ollama Embeddings model\n",
    "embeddings_model = OllamaEmbeddings(model='llama3.1:latest')\n",
    "# Connect to the PostgreSQL database with pgvector extension\n",
    "connection_string = 'postgresql+psycopg://langchain:langchain@localhost:6024/langchain'\n",
    "db = PGVector.from_documents(chunks, embeddings_model, connection=connection_string)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c778b19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'In response to the report, the city council was split. Some members accepted the findings and pushed for a â€œconvenienceâ€‘firstâ€ strategy that would restore some direct routes, extend evening and night services on key corridors, and introduce an integrated ticket that allowed unlimited transfers within 60 minutes at no extra cost. Others argued that the cityâ€™s budget could not support such measures without either significant tax increases or cuts to other services. A particularly contentious debate erupted around the idea of reinstating the direct tram line between Hohenfeld and the central station. Critics pointed out that the tram infrastructure had been partially dismantled and that rebuilding it would require a large upfront investment, while supporters claimed that the corridorâ€™s high population density and strong latent demand justified a longâ€‘term commitment.'"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# retriever = db.as_retriever()\n",
    "# results = retriever.invoke(\"In which year did Langenfurt face a mounting crisis in its public transportation system?\",k=1)\n",
    "# results[0].page_content  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b352c46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content=\"I don't know.\" additional_kwargs={} response_metadata={'model': 'llama3.1:latest', 'created_at': '2026-02-04T12:19:43.921133472Z', 'done': True, 'done_reason': 'stop', 'total_duration': 179140801, 'load_duration': 63796348, 'prompt_eval_count': 82, 'prompt_eval_duration': 38471296, 'eval_count': 6, 'eval_duration': 71998737, 'model_name': 'llama3.1:latest'} id='run--e808113d-81e2-4749-bea9-0b6b3ea4ad61-0' usage_metadata={'input_tokens': 82, 'output_tokens': 6, 'total_tokens': 88}\n"
     ]
    }
   ],
   "source": [
    "from langchain_ollama.chat_models import ChatOllama\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "chat_model = ChatOllama(model='llama3.1:latest',temperature=0)\n",
    "\n",
    "prompt =ChatPromptTemplate.from_template(\"\"\"Answer the question based on the context below./\n",
    "                                        If the question cannot be answered using the information provided, answer with \"I don't know\".\n",
    "Context: {context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Answer: \"\"\")\n",
    "\n",
    "chain = prompt | chat_model\n",
    "retriever = db.as_retriever()\n",
    "\n",
    "question=\"Who was the policy analyst in the Department of Urban Mobility?\"\n",
    "docs =  retriever.invoke(question,k=4)\n",
    "#run the chain\n",
    "response = chain.invoke({\"context\": docs[0].page_content, \"question\": question})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "4239334b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== DOC 0 ===\n",
      "\n",
      "gains but may also produce a sense of inequality if not accompanied by a broader, clearly communicated longâ€‘term vision.\n",
      "\n",
      "=== DOC 1 ===\n",
      "\n",
      "gains but may also produce a sense of inequality if not accompanied by a broader, clearly communicated longâ€‘term vision.\n",
      "\n",
      "=== DOC 2 ===\n",
      "\n",
      "Dr. Kraussâ€™s report argued that the city had fallen into what she called the â€œefficiency trapâ€: a pattern in which shortâ€‘term costâ€‘cutting measures, justified by the language of optimization, led to longâ€‘term losses in ridership and public trust. By focusing narrowly on metrics like cost per vehicleâ€‘kilometer and average occupancy per vehicle, Langenfurtâ€™s decisionâ€‘makers had overlooked less easily quantifiable factors such as perceived reliability, simplicity of routes, and the emotional comfort of not having to worry about missed connections late at night. She emphasized that once riders abandon public transport and adapt their lives around car use or alternative arrangements, it becomes far harderâ€”and more expensiveâ€”to win them back.\n",
      "\n",
      "=== DOC 3 ===\n",
      "\n",
      "Dr. Kraussâ€™s report argued that the city had fallen into what she called the â€œefficiency trapâ€: a pattern in which shortâ€‘term costâ€‘cutting measures, justified by the language of optimization, led to longâ€‘term losses in ridership and public trust. By focusing narrowly on metrics like cost per vehicleâ€‘kilometer and average occupancy per vehicle, Langenfurtâ€™s decisionâ€‘makers had overlooked less easily quantifiable factors such as perceived reliability, simplicity of routes, and the emotional comfort of not having to worry about missed connections late at night. She emphasized that once riders abandon public transport and adapt their lives around car use or alternative arrangements, it becomes far harderâ€”and more expensiveâ€”to win them back.\n"
     ]
    }
   ],
   "source": [
    "for i, d in enumerate(docs):\n",
    "    print(f\"\\n=== DOC {i} ===\\n\")\n",
    "    print(d.page_content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10794f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q1 (causal reasoning)\n",
    "# Q: According to the text, what deeper cause did Dr. Krauss identify behind the longâ€‘term decline in public transport ridership in Langenfurt?\n",
    "\n",
    "# A: She concluded that the main cause was a series of policy decisions that prioritized shortâ€‘term costâ€‘cutting and â€œefficiencyâ€ over convenience, reliability, and simplicity for riders, which gradually pushed people away from the system.\n",
    "\n",
    "# Q2 (specific detail)\n",
    "# Q: What change in 2008 led to a 37 percent drop in daily ridership on the Hohenfeld corridor within a year?\n",
    "\n",
    "# A: The city replaced the direct tram line between Hohenfeld and the central train station with a bus route that required a transfer downtown.\n",
    "\n",
    "# Q3 (interpretation)\n",
    "# Q: What does the â€œefficiency trapâ€ mean in the context of Langenfurtâ€™s transit policy?\n",
    "\n",
    "# A: It refers to the pattern where measures intended to cut costs and optimize operations, like reducing direct routes or simplifying the network on paper, ended up undermining rider experience, causing ridership losses and making the system less sustainable in the long run."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".langchain_venv (3.12.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
