{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e8b8e4b0",
   "metadata": {},
   "source": [
    "# Review and rerun\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f43acd53",
   "metadata": {},
   "source": [
    "## Chapter1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a59874a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GenerateResponse(model='gemma3:1b', created_at='2025-10-07T10:28:33.231767408Z', done=True, done_reason='stop', total_duration=5177111377, load_duration=819260284, prompt_eval_count=15, prompt_eval_duration=958843756, eval_count=759, eval_duration=3398153914, response='This is a fantastic and surprisingly complex question that has captivated people for decades! The \"Sly Blue\" isn\\'t a real, specific, or documented creature. It\\'s a fascinating, persistent myth and a result of a few intertwined historical and cultural elements. Here\\'s the breakdown of why it\\'s so popular and the story behind it:\\n\\n**1. The Origin – The Story of Silas Gray:**\\n\\n* **Silas Gray, a 19th-century American storyteller:** The myth began with a story told by Silas Gray, a travelling salesman and storyteller from the mid-1800s. He recounted a tale of a man named Silas Gray who lived in a remote area of the Appalachian Mountains.\\n* **The Legend:** Gray’s story involved a man who could move silently and disappear into the shadows. He would often appear as a shadowy figure, often described as wearing a blue coat.  He was said to be incredibly elusive and rarely interfered with people.\\n\\n**2. The Evolution of the Myth:**\\n\\n* **Early Folklore & Local Legends:**  The story quickly spread through Appalachian communities, evolving into various local legends. These legends often involved a \"blue man\" who could vanish and reappear at will.\\n* **The \"Blue Man\" as a Protector:** Over time, the \"blue man\" transformed into a more complex figure. He was often portrayed as a guardian of the forest, a protector of the land, and a being of immense power and wisdom.  He\\'s often depicted as benevolent and able to help those in need.\\n* **The \"Blue Coat\" Detail:**  A particularly compelling detail added to the myth was the legend that the blue coat wasn\\'t just a color, but a *coat of invisibility*.  It seemed to ripple and shift, making the man incredibly difficult to track.\\n\\n**3. Why the Blue Color is Important:**\\n\\n* **Color Symbolism:** The color blue has long been associated with mystery, sadness, and the unknown. It\\'s a color that evokes a sense of the ethereal and the hidden.\\n* **Connection to the Appalachian Mountains:** The Appalachian Mountains have a rich folklore tradition that connects to the land itself, adding to the sense of a mystical, untouched wilderness.\\n\\n**4.  The Modern Appeal & Popularity:**\\n\\n* **Sense of Mystery & Adventure:** The \"Sly Blue\" is deeply appealing because it embodies a sense of adventure, mystery, and the possibility of encountering something truly extraordinary.\\n* **Internet Popularity:**  The myth exploded in the 1990s, especially on internet forums and communities like 4chan. It became a massive phenomenon, captivating thousands.  The \"Sly Blue\" became a meme, referenced in countless memes and jokes.\\n\\n**In short, the \"Sly Blue\" isn\\'t a real creature. It\\'s a captivating legend that has evolved over centuries, fueled by folklore, the Appalachian landscape, and a potent combination of mystery and the desire to believe in something beyond the ordinary.**\\n\\n**Resources for Further Exploration:**\\n\\n* **Wikipedia - The Sly Blue:** [https://en.wikipedia.org/wiki/Sly_Blue](https://en.wikipedia.org/wiki/Sly_Blue)\\n* **The Story of the Sly Blue:** [https://www.the-story-of-the-sly-blue.com/](https://www.the-story-of-the-sly-blue.com/)\\n\\n\\nDo you want to delve deeper into a specific aspect of the \"Sly Blue\" myth, like its connection to specific folklore traditions, or perhaps its role in internet culture?', thinking=None, context=[105, 2364, 107, 36425, 563, 506, 130246, 3730, 236881, 106, 107, 105, 4368, 107, 2094, 563, 496, 14853, 532, 33887, 3996, 2934, 600, 815, 160456, 1331, 573, 13013, 236888, 669, 623, 236773, 586, 9595, 236775, 5889, 236789, 236745, 496, 1759, 236764, 3530, 236764, 653, 31037, 33070, 236761, 1030, 236789, 236751, 496, 27858, 236764, 33086, 27642, 532, 496, 1354, 529, 496, 2321, 106166, 11858, 532, 9226, 4820, 236761, 5715, 236789, 236751, 506, 25890, 529, 3217, 625, 236789, 236751, 834, 4913, 532, 506, 3925, 4977, 625, 236787, 108, 1018, 236770, 236761, 669, 45769, 1271, 669, 16976, 529, 205520, 25393, 53121, 108, 236829, 5213, 21576, 527, 25393, 236764, 496, 236743, 236770, 236819, 594, 236772, 33201, 3668, 146456, 53121, 669, 27642, 6074, 607, 496, 3925, 4173, 684, 205520, 25393, 236764, 496, 26326, 86946, 532, 146456, 699, 506, 5453, 236772, 236770, 236828, 236771, 236771, 236751, 236761, 1293, 130615, 496, 22720, 529, 496, 880, 7489, 205520, 25393, 1015, 11742, 528, 496, 10883, 2433, 529, 506, 122116, 31093, 236761, 107, 236829, 5213, 818, 38947, 53121, 25393, 236858, 236751, 3925, 5418, 496, 880, 1015, 1451, 2827, 75538, 532, 36422, 1131, 506, 37676, 236761, 1293, 1093, 3187, 3196, 618, 496, 184923, 5811, 236764, 3187, 4970, 618, 9922, 496, 3730, 15674, 236761, 138, 2209, 691, 1176, 531, 577, 20068, 84322, 532, 20390, 128092, 607, 1331, 236761, 108, 1018, 236778, 236761, 669, 36630, 529, 506, 67970, 53121, 108, 236829, 5213, 39403, 224014, 833, 12263, 54710, 53121, 138, 818, 3925, 6077, 7028, 1343, 122116, 8904, 236764, 36757, 1131, 3572, 2263, 48840, 236761, 3143, 48840, 3187, 5418, 496, 623, 9503, 880, 236775, 1015, 1451, 62911, 532, 205988, 657, 795, 236761, 107, 236829, 5213, 818, 623, 16520, 2599, 236775, 618, 496, 103275, 53121, 7178, 990, 236764, 506, 623, 9503, 880, 236775, 22094, 1131, 496, 919, 3996, 5811, 236761, 1293, 691, 3187, 54056, 618, 496, 43445, 529, 506, 6426, 236764, 496, 56948, 529, 506, 2601, 236764, 532, 496, 1646, 529, 36628, 2066, 532, 23069, 236761, 138, 2209, 236789, 236751, 3187, 35718, 618, 131210, 532, 2735, 531, 1601, 1724, 528, 1202, 236761, 107, 236829, 5213, 818, 623, 16520, 85119, 236775, 52586, 53121, 138, 236776, 6412, 33348, 8052, 3742, 531, 506, 27642, 691, 506, 15287, 600, 506, 3730, 15674, 7289, 236789, 236745, 1164, 496, 2258, 236764, 840, 496, 808, 41525, 529, 226744, 22429, 138, 1509, 10012, 531, 81640, 532, 8633, 236764, 3043, 506, 880, 20068, 3909, 531, 4087, 236761, 108, 1018, 236800, 236761, 8922, 506, 9595, 8040, 563, 46780, 53121, 108, 236829, 5213, 3484, 27277, 1929, 53121, 669, 2258, 3730, 815, 1440, 1010, 5143, 607, 26460, 236764, 55882, 236764, 532, 506, 11908, 236761, 1030, 236789, 236751, 496, 2258, 600, 131680, 496, 5113, 529, 506, 144377, 532, 506, 11497, 236761, 107, 236829, 5213, 10745, 531, 506, 122116, 31093, 53121, 669, 122116, 31093, 735, 496, 8326, 99724, 14385, 600, 32407, 531, 506, 2601, 4850, 236764, 8009, 531, 506, 5113, 529, 496, 73581, 236764, 91354, 49582, 236761, 108, 1018, 236812, 236761, 138, 818, 13806, 47137, 833, 35626, 665, 53121, 108, 236829, 5213, 66498, 529, 72289, 833, 47880, 53121, 669, 623, 236773, 586, 9595, 236775, 563, 19297, 35745, 1547, 625, 97216, 496, 5113, 529, 19063, 236764, 26460, 236764, 532, 506, 11160, 529, 125180, 2613, 9995, 23205, 236761, 107, 236829, 5213, 40519, 35626, 665, 53121, 138, 818, 27642, 66543, 528, 506, 236743, 236770, 236819, 236819, 236771, 236751, 236764, 4285, 580, 8379, 46318, 532, 8904, 1133, 236743, 236812, 3655, 236761, 1030, 5452, 496, 12566, 20284, 236764, 81865, 11252, 236761, 138, 818, 623, 236773, 586, 9595, 236775, 5452, 496, 40741, 236764, 44112, 528, 33703, 55537, 532, 38295, 236761, 108, 1018, 902, 2822, 236764, 506, 623, 236773, 586, 9595, 236775, 5889, 236789, 236745, 496, 1759, 33070, 236761, 1030, 236789, 236751, 496, 81865, 15287, 600, 815, 28404, 1024, 24744, 236764, 85132, 684, 99724, 236764, 506, 122116, 10092, 236764, 532, 496, 30199, 8376, 529, 26460, 532, 506, 12614, 531, 4646, 528, 2613, 6998, 506, 12822, 99382, 108, 1018, 19213, 573, 9077, 77985, 53121, 108, 236829, 5213, 137875, 753, 669, 159665, 9595, 53121, 870, 2574, 1411, 501, 236761, 47180, 236761, 2187, 236786, 24466, 236786, 236773, 586, 236779, 16520, 5457, 2574, 1411, 501, 236761, 47180, 236761, 2187, 236786, 24466, 236786, 236773, 586, 236779, 16520, 236768, 107, 236829, 5213, 818, 16976, 529, 506, 159665, 9595, 53121, 870, 2574, 1411, 2769, 236761, 1437, 236772, 24251, 236772, 1340, 236772, 1437, 236772, 236751, 586, 236772, 9503, 236761, 854, 236786, 5457, 2574, 1411, 2769, 236761, 1437, 236772, 24251, 236772, 1340, 236772, 1437, 236772, 236751, 586, 236772, 9503, 236761, 854, 31004, 109, 6294, 611, 1461, 531, 92541, 19276, 1131, 496, 3530, 6084, 529, 506, 623, 236773, 586, 9595, 236775, 27642, 236764, 1133, 1061, 5603, 531, 3530, 99724, 28968, 236764, 653, 8229, 1061, 3853, 528, 8379, 6540, 236881])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# call ollama without langchain\n",
    "import ollama\n",
    "result = ollama.generate(model=\"gemma3:1b\", prompt=\"why is the sly blue?\")\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7e2d0c98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The sky is a fascinating and complex place! Here's a breakdown of what it is, depending on your perspective:\\n\\n**1. Physically – The Atmosphere:**\\n\\n* **A Layer of Gases:** The sky is primarily composed of gases, mainly nitrogen and oxygen, that make up about 78% of the atmosphere.\\n* **Clouds:** Clouds are formed by water vapor condensing into tiny droplets or ice crystals. Different types of clouds have different shapes and sizes.\\n* **Sunlight:** Sunlight is the source of light and warmth in the sky.\\n* **Particles:** Tiny particles like dust, pollen, and pollution can affect the color and clarity of the sky.\\n\\n**2. Emotionally & Figuratively – Our Perception:**\\n\\n* **Blue:** This is the most common color we associate with the sky, due to Rayleigh scattering, where sunlight is scattered by air molecules.\\n* **Peaceful:**  Many people find the sky calming and beautiful.\\n* **A Vastness:** The sky can evoke a sense of limitless space and possibility.\\n* **A Reminder of Something Bigger:** It can make us feel small in the grand scheme of things.\\n\\n**3.  Symbolically – Different Meanings:**\\n\\n* **Hope:**  The vastness of the sky can symbolize hope and dreams.\\n* **Freedom:**  The sky is often associated with freedom and escape.\\n* **Mystery:**  The sky holds many secrets and mysteries.\\n\\n\\n**In short, the sky is a combination of physical elements and our subjective experience of it.**\\n\\n---\\n\\n**To help me give you a more tailored answer, could you tell me:**\\n\\n*   **What are you interested in knowing about the sky?** (e.g., weather, clouds, constellations, etc.)\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# call ollama inside the langchain\n",
    "from langchain_ollama.llms import OllamaLLM\n",
    "\n",
    "llm = OllamaLLM(model=\"gemma3:1b\", temperature=0)\n",
    "\n",
    "llm.invoke(\"the sky is?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fbbca4af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"The most natural and common translation would be:\\n\\n**Ich liebe es, Französisch zu lernen.**\\n\\nHere's a breakdown:\\n\\n*   **Ich:** I\\n*   **liebe:** love\\n*   **es:** it (referring to learning French)\\n*   **Französisch:** French\\n\\nYou could also say:\\n\\n*   **Ich mag es, Französisch zu lernen.** (I like it to learn French.) - This is slightly less enthusiastic.\\n\\nDo you want me to translate it in a slightly different way?\", additional_kwargs={}, response_metadata={'model': 'gemma3:1b', 'created_at': '2025-10-07T10:54:27.666132477Z', 'done': True, 'done_reason': 'stop', 'total_duration': 675304105, 'load_duration': 95548930, 'prompt_eval_count': 33, 'prompt_eval_duration': 15358832, 'eval_count': 116, 'eval_duration': 563908382, 'model_name': 'gemma3:1b'}, id='run--0799735b-8912-43cd-8f07-7c2820231cad-0', usage_metadata={'input_tokens': 33, 'output_tokens': 116, 'total_tokens': 149})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# call ollama as chatbot\n",
    "from langchain_ollama.chat_models import ChatOllama\n",
    "\n",
    "llm = ChatOllama(model=\"gemma3:1b\", temperature=0)\n",
    "\n",
    "message = [{\"role\": \"system\", \"content\":\"You are a helpful translator. Translate the user sentence to german.\"},\n",
    "           {\"role\": \"user\", \"content\":\"I love learing french.\"}]\n",
    "\n",
    "llm.invoke(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d4f63aff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='\"Programmieren ist meine Leidenschaft.\"\\n\\n(I translated \"programming\" to the German word \"Programmieren\", and added \"ist meine Leidenschaft\" which means \"is my passion\")', additional_kwargs={}, response_metadata={'model': 'llama3.1', 'created_at': '2025-10-07T11:30:44.67586593Z', 'done': True, 'done_reason': 'stop', 'total_duration': 686444066, 'load_duration': 41729888, 'prompt_eval_count': 30, 'prompt_eval_duration': 4032757, 'eval_count': 41, 'eval_duration': 639951252, 'model_name': 'llama3.1'}, id='run--a321f7b0-58e7-40ad-a437-e4c454854ef5-0', usage_metadata={'input_tokens': 30, 'output_tokens': 41, 'total_tokens': 71})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chat with promt template\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_ollama.chat_models import ChatOllama\n",
    "\n",
    "\n",
    "llm = ChatOllama(model=\"llama3.1\", temperature=0)\n",
    "\n",
    "template = ChatPromptTemplate.from_messages([(\"system\", \"You are a helpful assistant that translates {input_language} to {output_language}.\"),\n",
    "                                             (\"human\", \"{input}\")])\n",
    "\n",
    "chain = template | llm\n",
    "chain.invoke({\"input_language\":\"English\",\n",
    "              \"output_language\": \"German\",\n",
    "              \"input\": \"I love programming.\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bf6951cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='The translation of \"I love programming\" from English to German is:\\n\\n\"Ich liebe Programmieren\"\\n\\nBreakdown:\\n\\n* \"Ich liebe\" means \"I love\"\\n* \"Programmieren\" means \"programming\" (note that in German, the verb \"programmieren\" is used as a noun, but in this context it\\'s clear that it\\'s being used as a verb)' additional_kwargs={} response_metadata={'model': 'llama3.1', 'created_at': '2025-10-07T11:42:32.269258095Z', 'done': True, 'done_reason': 'stop', 'total_duration': 1297797022, 'load_duration': 53746424, 'prompt_eval_count': 34, 'prompt_eval_duration': 15133903, 'eval_count': 79, 'eval_duration': 1228306791, 'model_name': 'llama3.1'} id='run--a4a7de54-1edb-4701-8382-b24b1c6c9513-0' usage_metadata={'input_tokens': 34, 'output_tokens': 79, 'total_tokens': 113}\n"
     ]
    }
   ],
   "source": [
    "# chat with promt template(book example p8)\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "template =ChatPromptTemplate.from_template(\"\"\"You are a translator. translate the below Context:\".\n",
    "Context: {context}\n",
    "Language: {language}\n",
    "\n",
    "Answer: \"\"\")\n",
    "\n",
    "model = ChatOllama(model= \"llama3.1\")\n",
    "\n",
    "prompt = ({\n",
    "        \"context\": \"I love programming.\",\n",
    "        \"language\": \"german\"})\n",
    "chain = template | llm\n",
    "response =chain.invoke(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d03b0ac3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='The translation of \"I love programming\" to German is:\\n\\n\"Ich liebe Programmieren\"\\n\\nHere\\'s a breakdown of the translation:\\n\\n* \"Ich liebe\" means \"I love\"\\n* \"Programmieren\" means \"programming\" (note that in German, the verb ending changes depending on the subject, so \"programmieren\" is the correct form for the first person singular \"ich\")' additional_kwargs={} response_metadata={'model': 'llama3.1', 'created_at': '2025-10-07T11:48:42.362552964Z', 'done': True, 'done_reason': 'stop', 'total_duration': 2789469354, 'load_duration': 1473672524, 'prompt_eval_count': 36, 'prompt_eval_duration': 99576682, 'eval_count': 80, 'eval_duration': 1215107512, 'model_name': 'llama3.1'} id='run--7d038baf-1802-4950-b47d-ad971af6aacd-0' usage_metadata={'input_tokens': 36, 'output_tokens': 80, 'total_tokens': 116}\n"
     ]
    }
   ],
   "source": [
    "# chat with promt template(book example p11)\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "template =ChatPromptTemplate.from_messages([(\"system\", \"You are a translator. translate the below Context:\"),\n",
    "                                            (\"human\", \"text context: {context}\"),\n",
    "                                            (\"human\", \"desired language: {language}\")])\n",
    "\n",
    "model = ChatOllama(model= \"llama3.1\")\n",
    "\n",
    "prompt = ({\n",
    "        \"context\": \"I love programming.\",\n",
    "        \"language\": \"german\"})\n",
    "chain = template | llm\n",
    "response =chain.invoke(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "005c4ffd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnswerWithJustification(answer='They weigh the same!', justification='In both cases, the weight is one (1) pound. The difference lies in density and volume.')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pydantic import BaseModel\n",
    "\n",
    "class AnswerWithJustification(BaseModel):\n",
    "    '''An answer to the user question along with justification for the answer.'''\n",
    "    answer:str\n",
    "    '''the answer to the user question'''\n",
    "    justification: str\n",
    "    '''justification for the answer'''\n",
    "    \n",
    "llm = ChatOllama(model='llama3.1')\n",
    "structured_llm = llm.with_structured_output(AnswerWithJustification)\n",
    "\n",
    "structured_llm.invoke(\"\"\"What weighs more, a pound of bricks or a pound of feathers\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e540cb4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Answer(answer='Ich liebe Programmieren und Lehren.', num_of_words=4)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "template =ChatPromptTemplate.from_messages([(\"system\", \"You are a translator. translate the below Context:\"),\n",
    "                                            (\"human\", \"text context: {context}\"),\n",
    "                                            (\"human\", \"desired language: {language}\")])\n",
    "from pydantic import BaseModel\n",
    "\n",
    "class Answer(BaseModel):\n",
    "    '''An answer to the user question along with number of words for the answer.'''\n",
    "    answer:str\n",
    "    '''the answer to the user question'''\n",
    "    num_of_words: int\n",
    "    '''number of words for the answer'''\n",
    "\n",
    "model = ChatOllama(model= \"llama3.1\").with_structured_output(Answer)\n",
    "\n",
    "prompt = ({\n",
    "        \"context\": \"I love programming and teaching.\",\n",
    "        \"language\": \"german\"})\n",
    "\n",
    "chain = template | model\n",
    "response =chain.invoke(prompt)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6b219475",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using runnable interface(invoke(), bathc(), stream())\n",
    "\n",
    "from langchain_ollama.chat_models import ChatOllama\n",
    "\n",
    "llm = ChatOllama(model=\"llama3.1\")\n",
    "\n",
    "#1 invoke()\n",
    "#llm.invoke(\"hello there!\")\n",
    "\n",
    "#2 batch()\n",
    "#llm.batch([\"hi there!\", \"what is your name?\"])\n",
    "\n",
    "#3 stream()\n",
    "# for i in llm.stream('Bye!'):\n",
    "#     print(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa4aba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imperative Composition\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf7f7380",
   "metadata": {},
   "source": [
    "## Chapter2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e2ab411b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': './test.txt'}, page_content='Silent speech interfaces allow speech communication to take place in the absence of the acoustic speech signal.\\nRadar-based sensing with radio antennas on the speakers’ face can be used as a non-invasive modality to measure speech articulation in such applications.\\nOne of the major challenges with this approach is the variability between different sessions,\\nmainly due to the repositioning of the antennas on the face of the speaker. In order to reduce the impact of this influencing factor,\\nwe developed a wearable headset that can be 3D-printed with flexible materials and weighs only about 69 g. For evaluation,\\na radar-based word recognition experiment was performed, where five speakers recorded a speech corpus in multiple sessions,\\nalternatively with the headset and with double-sided tape to place the antennas on the face.\\nBy using a bidirectional long short-term memory network for classification,\\nan average intersession word accuracy of 76.50% and 68.18% was obtained using the headset and the tape,respectively.\\nThis indicates that the antenna (re-) positioning accuracy with the headset is not worse than that with the double-sided tape while providing other benefits.')]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load a text file\n",
    "from langchain.document_loaders import TextLoader\n",
    "\n",
    "loader = TextLoader(file_path=\"./test.txt\")\n",
    "loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d322b262",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now splitting it to a number of chunks\n",
    "\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "\n",
    "loader = PyPDFLoader(file_path=\"./test_article.pdf\")\n",
    "docs = loader.load()\n",
    "\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=10)\n",
    "splitted_docs = splitter.split_documents(docs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "ebd66f03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length:  171\n",
      "\n",
      "Page content:  methods presented in Table 6. As can been seen in\n",
      "Table 8, the proposed technique is the fourth rank for\n",
      "Case 2 and is the second rank for Case 3. However, the\n",
      "ﬁnal ranking results in the test phase show that the\n",
      "proposed method and Method 4 are in the ﬁrst rank and\n",
      "Method 5 is in the second rank.\n",
      "• The results of the ﬁrst case indicate that the proposed\n",
      "technique in this work, Method 5, and Method 6 are\n",
      "superior to other methods in identifying defects with\n",
      "\n",
      "All metadata:  {'producer': 'Acrobat Distiller 10.1.8 (Windows)', 'creator': 'Springer', 'creationdate': '2021-09-30T14:13:46+05:30', 'author': 'Saeed Nezamivand Chegini', 'crossmarkdomains[1]': 'springer.com', 'crossmarkdomains[2]': 'springerlink.com', 'crossmarkdomainexclusive': 'true', 'crossmarkmajorversiondate': '2010-04-23', 'keywords': 'Bearing fault diagnosis,Swarm decomposition,Optimized compensation distance evaluation,Hybrid particle swarm optimization algorithm,Support vector machine', 'moddate': '2022-01-17T23:41:10+05:30', 'subject': 'Soft Computing, https://doi.org/10.1007/s00500-021-06307-x', 'title': 'Intelligent bearing fault diagnosis using swarm decomposition method and new hybrid particle swarm optimization algorithm', 'doi': '10.1007/s00500-021-06307-x', 'robots': 'noindex', 'rgid': 'PB:354981974_AS:1141442265260032@1649152451047', 'source': './article.pdf', 'total_pages': 24, 'page': 0, 'page_label': '1475'}\n",
      "\n",
      "An example of metadata:  1475\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"length: \", len(splitted_docs), end='\\n\\n'),\n",
    "print(\"Page content: \", splitted_docs[100].page_content, end='\\n\\n')\n",
    "print(\"All metadata: \", splitted_docs[0].metadata, end='\\n\\n')\n",
    "print(\"An example of metadata: \", splitted_docs[0].metadata[\"page_label\"], end='\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dc60357",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={}, page_content='def hello_world():\\n    print(\"Hello, World!\")'),\n",
       " Document(metadata={}, page_content='# Call the function\\nhello_world()')]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chunking when we have only raw data not a doc\n",
    "\n",
    "from langchain_text_splitters import (\n",
    "    Language,\n",
    "    RecursiveCharacterTextSplitter,\n",
    ")\n",
    "PYTHON_CODE = \"\"\"\n",
    "def hello_world():\n",
    "    print(\"Hello, World!\")\n",
    "\n",
    "# Call the function\n",
    "hello_world()\n",
    "\"\"\"\n",
    "python_splitter = RecursiveCharacterTextSplitter.from_language(\n",
    "    language=Language.PYTHON, chunk_size=50, chunk_overlap=0\n",
    ")\n",
    "python_docs = python_splitter.create_documents([PYTHON_CODE])\n",
    "python_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "e06c8b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embeddings\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "\n",
    "text = (\"horse is for king\")\n",
    "\n",
    "embedding_model = OllamaEmbeddings(model=\"llama3.1\")\n",
    "horse = embedding_model.embed_documents(text)\n",
    "# len(vector[0])\n",
    "# vector[0][0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "9e143fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now use document loade, splitting text and embedding all combined\n",
    "#1- load the file\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "\n",
    "document_loader = PyPDFLoader(file_path=\"./test_article.pdf\")\n",
    "document = document_loader.load()\n",
    "\n",
    "#2- splitt the documnet\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
    "splitted_docs = splitter.split_documents(document)\n",
    "\n",
    "#3- embedding the documnet\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "\n",
    "embedding_model = OllamaEmbeddings(model=\"llama3.1\")\n",
    "embeddings = embedding_model.embed_documents([chunk.page_content for chunk in splitted_docs]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "36f4f021",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(92, 92)"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(splitted_docs), len(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec1decb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pgvector installation\n",
    "#docker run --name pgvector-container \n",
    "# -e POSTGRES_USER=langchain \n",
    "# -e POSTGRES_PASSWORD=langchain \n",
    "# -e POSTGRES_DB=langchain \n",
    "# -p 6024:5432 \n",
    "# -d pgvector/pgvector:pg16 -v pgvector-data: /var/lib/postgresql/data\n",
    "\n",
    "#for work labtop\n",
    "# docker run --name pgvector-container \\\n",
    "# -e POSTGRES_USER=langchain \\\n",
    "# -e POSTGRES_PASSWORD=langchain \\\n",
    "# -e POSTGRES_DB=langchain \\\n",
    "# -e POSTGRES_HOST_AUTH_METHOD=md5 \\\n",
    "# -p 6024:5432 \\\n",
    "# -v pgvector-data:/var/lib/postgresql/data \\\n",
    "# -d pgvector/pgvector:pg16\n",
    "\n",
    "# connection_string:\"b6b4c28ed83b53c1970c3e476fa8332ea5d14cb0caee3eb92b81795016ba4919\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "f0eb6ac8",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[213]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdocument_loaders\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m PyPDFLoader\n\u001b[32m      4\u001b[39m document_loader = PyPDFLoader(file_path=\u001b[33m\"\u001b[39m\u001b[33m./test_article.pdf\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m document = \u001b[43mdocument_loader\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m#splitt the documnet\u001b[39;00m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_text_splitters\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m RecursiveCharacterTextSplitter\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/LangChain/lib/python3.12/site-packages/langchain_core/document_loaders/base.py:32\u001b[39m, in \u001b[36mBaseLoader.load\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     30\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mload\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> \u001b[38;5;28mlist\u001b[39m[Document]:\n\u001b[32m     31\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Load data into Document objects.\"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m32\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlazy_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/LangChain/lib/python3.12/site-packages/langchain_community/document_loaders/pdf.py:305\u001b[39m, in \u001b[36mPyPDFLoader.lazy_load\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    303\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    304\u001b[39m     blob = Blob.from_path(\u001b[38;5;28mself\u001b[39m.file_path)\n\u001b[32m--> \u001b[39m\u001b[32m305\u001b[39m \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m.parser.lazy_parse(blob)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/LangChain/lib/python3.12/site-packages/langchain_community/document_loaders/parsers/pdf.py:396\u001b[39m, in \u001b[36mPyPDFParser.lazy_parse\u001b[39m\u001b[34m(self, blob)\u001b[39m\n\u001b[32m    394\u001b[39m single_texts = []\n\u001b[32m    395\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m page_number, page \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(pdf_reader.pages):\n\u001b[32m--> \u001b[39m\u001b[32m396\u001b[39m     text_from_page = \u001b[43m_extract_text_from_page\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpage\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    397\u001b[39m     images_from_page = \u001b[38;5;28mself\u001b[39m.extract_images_from_page(page)\n\u001b[32m    398\u001b[39m     all_text = _merge_text_and_extras(\n\u001b[32m    399\u001b[39m         [images_from_page], text_from_page\n\u001b[32m    400\u001b[39m     ).strip()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/LangChain/lib/python3.12/site-packages/langchain_community/document_loaders/parsers/pdf.py:378\u001b[39m, in \u001b[36mPyPDFParser.lazy_parse.<locals>._extract_text_from_page\u001b[39m\u001b[34m(page)\u001b[39m\n\u001b[32m    376\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m page.extract_text()\n\u001b[32m    377\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m378\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpage\u001b[49m\u001b[43m.\u001b[49m\u001b[43mextract_text\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    379\u001b[39m \u001b[43m        \u001b[49m\u001b[43mextraction_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mextraction_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    380\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mextraction_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    381\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/LangChain/lib/python3.12/site-packages/pypdf/_page.py:2038\u001b[39m, in \u001b[36mPageObject.extract_text\u001b[39m\u001b[34m(self, orientations, space_width, visitor_operand_before, visitor_operand_after, visitor_text, extraction_mode, *args, **kwargs)\u001b[39m\n\u001b[32m   2035\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(orientations, \u001b[38;5;28mint\u001b[39m):\n\u001b[32m   2036\u001b[39m     orientations = (orientations,)\n\u001b[32m-> \u001b[39m\u001b[32m2038\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_extract_text\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2039\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   2040\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpdf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2041\u001b[39m \u001b[43m    \u001b[49m\u001b[43morientations\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2042\u001b[39m \u001b[43m    \u001b[49m\u001b[43mspace_width\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2043\u001b[39m \u001b[43m    \u001b[49m\u001b[43mPG\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCONTENTS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2044\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvisitor_operand_before\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2045\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvisitor_operand_after\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2046\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvisitor_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2047\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/LangChain/lib/python3.12/site-packages/pypdf/_page.py:1702\u001b[39m, in \u001b[36mPageObject._extract_text\u001b[39m\u001b[34m(self, obj, pdf, orientations, space_width, content_key, visitor_operand_before, visitor_operand_after, visitor_text)\u001b[39m\n\u001b[32m   1700\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m cast(DictionaryObject, font):\n\u001b[32m   1701\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1702\u001b[39m         cmaps[f] = \u001b[43mbuild_char_map\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mspace_width\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1703\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m   1704\u001b[39m         \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/LangChain/lib/python3.12/site-packages/pypdf/_cmap.py:37\u001b[39m, in \u001b[36mbuild_char_map\u001b[39m\u001b[34m(font_name, space_width, obj)\u001b[39m\n\u001b[32m     23\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     24\u001b[39m \u001b[33;03mDetermine information about a font.\u001b[39;00m\n\u001b[32m     25\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m     34\u001b[39m \n\u001b[32m     35\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     36\u001b[39m ft: DictionaryObject = obj[\u001b[33m\"\u001b[39m\u001b[33m/Resources\u001b[39m\u001b[33m\"\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33m/Font\u001b[39m\u001b[33m\"\u001b[39m][font_name]  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m37\u001b[39m font_subtype, font_halfspace, font_encoding, font_map = \u001b[43mbuild_char_map_from_dict\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     38\u001b[39m \u001b[43m    \u001b[49m\u001b[43mspace_width\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mft\u001b[49m\n\u001b[32m     39\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     40\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m font_subtype, font_halfspace, font_encoding, font_map, ft\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/LangChain/lib/python3.12/site-packages/pypdf/_cmap.py:63\u001b[39m, in \u001b[36mbuild_char_map_from_dict\u001b[39m\u001b[34m(space_width, ft)\u001b[39m\n\u001b[32m     60\u001b[39m encoding, map_dict = get_encoding(ft)\n\u001b[32m     62\u001b[39m space_key_char = get_actual_str_key(\u001b[33m\"\u001b[39m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m, encoding, map_dict)\n\u001b[32m---> \u001b[39m\u001b[32m63\u001b[39m font_width_map = \u001b[43mbuild_font_width_map\u001b[49m\u001b[43m(\u001b[49m\u001b[43mft\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mspace_width\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m2.0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     64\u001b[39m half_space_width = compute_space_width(font_width_map, space_key_char) / \u001b[32m2.0\u001b[39m\n\u001b[32m     66\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[32m     67\u001b[39m     font_type,\n\u001b[32m     68\u001b[39m     half_space_width,\n\u001b[32m   (...)\u001b[39m\u001b[32m     71\u001b[39m     map_dict\n\u001b[32m     72\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/LangChain/lib/python3.12/site-packages/pypdf/_cmap.py:473\u001b[39m, in \u001b[36mbuild_font_width_map\u001b[39m\u001b[34m(ft, default_font_width)\u001b[39m\n\u001b[32m    471\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m c_code \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(st, en + \u001b[32m1\u001b[39m):\n\u001b[32m    472\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m473\u001b[39m         width = \u001b[43mw\u001b[49m\u001b[43m[\u001b[49m\u001b[43mc_code\u001b[49m\u001b[43m \u001b[49m\u001b[43m-\u001b[49m\u001b[43m \u001b[49m\u001b[43mst\u001b[49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_object\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    474\u001b[39m         font_width_map[\u001b[38;5;28mchr\u001b[39m(c_code)] = width\n\u001b[32m    475\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mIndexError\u001b[39;00m, \u001b[38;5;167;01mKeyError\u001b[39;00m):\n\u001b[32m    476\u001b[39m         \u001b[38;5;66;03m# The PDF structure is invalid. The array is too small\u001b[39;00m\n\u001b[32m    477\u001b[39m         \u001b[38;5;66;03m# for the specified font width.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/LangChain/lib/python3.12/site-packages/pypdf/generic/_base.py:192\u001b[39m, in \u001b[36mPdfObject.get_object\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    189\u001b[39m     clone.indirect_reference = IndirectObject(i, \u001b[32m0\u001b[39m, pdf_dest)\n\u001b[32m    190\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m clone\n\u001b[32m--> \u001b[39m\u001b[32m192\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_object\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> Optional[\u001b[33m\"\u001b[39m\u001b[33mPdfObject\u001b[39m\u001b[33m\"\u001b[39m]:\n\u001b[32m    193\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Resolve indirect references.\"\"\"\u001b[39;00m\n\u001b[32m    194\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "#PGVector\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "\n",
    "document_loader = PyPDFLoader(file_path=\"./test_article.pdf\")\n",
    "document = document_loader.load()\n",
    "\n",
    "#splitt the documnet\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
    "splitted_docs = splitter.split_documents(document)\n",
    "\n",
    "#embedding the documnet\n",
    "from langchain_postgres.vectorstores import PGVector\n",
    "\n",
    "connection = \"postgresql+psycopg://langchain:langchain@localhost:6024/langchain\"\n",
    "embedding_model = OllamaEmbeddings(model=\"SmolLM2:135M \")\n",
    "db =PGVector.from_documents(splitted_docs, embedding_model, connection=connection)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LangChain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
