{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e8b8e4b0",
   "metadata": {},
   "source": [
    "# Review and rerun\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f43acd53",
   "metadata": {},
   "source": [
    "## Chapter1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a59874a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# call ollama without langchain\n",
    "import ollama\n",
    "result = ollama.generate(model=\"gemma3:1b\", prompt=\"why is the sly blue?\")\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e2d0c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# call ollama inside the langchain\n",
    "from langchain_ollama.llms import OllamaLLM\n",
    "\n",
    "llm = OllamaLLM(model=\"gemma3:1b\", temperature=0)\n",
    "\n",
    "llm.invoke(\"the sky is?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbbca4af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# call ollama as chatbot\n",
    "from langchain_ollama.chat_models import ChatOllama\n",
    "\n",
    "llm = ChatOllama(model=\"gemma3:1b\", temperature=0)\n",
    "\n",
    "message = [{\"role\": \"system\", \"content\":\"You are a helpful translator. Translate the user sentence to german.\"},\n",
    "           {\"role\": \"user\", \"content\":\"I love learing french.\"}]\n",
    "\n",
    "llm.invoke(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f63aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# chat with promt template\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_ollama.chat_models import ChatOllama\n",
    "\n",
    "\n",
    "llm = ChatOllama(model=\"llama3.1\", temperature=0)\n",
    "\n",
    "template = ChatPromptTemplate.from_messages([(\"system\", \"You are a helpful assistant that translates {input_language} to {output_language}.\"),\n",
    "                                             (\"human\", \"{input}\")])\n",
    "\n",
    "chain = template | llm\n",
    "chain.invoke({\"input_language\":\"English\",\n",
    "              \"output_language\": \"German\",\n",
    "              \"input\": \"I love programming.\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf6951cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# chat with promt template(book example p8)\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "template =ChatPromptTemplate.from_template(\"\"\"You are a translator. translate the below Context:\".\n",
    "Context: {context}\n",
    "Language: {language}\n",
    "\n",
    "Answer: \"\"\")\n",
    "\n",
    "model = ChatOllama(model= \"llama3.1\")\n",
    "\n",
    "prompt = ({\n",
    "        \"context\": \"I love programming.\",\n",
    "        \"language\": \"german\"})\n",
    "chain = template | llm\n",
    "response =chain.invoke(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d03b0ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# chat with promt template(book example p11)\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "template =ChatPromptTemplate.from_messages([(\"system\", \"You are a translator. translate the below Context:\"),\n",
    "                                            (\"human\", \"text context: {context}\"),\n",
    "                                            (\"human\", \"desired language: {language}\")])\n",
    "\n",
    "model = ChatOllama(model= \"llama3.1\")\n",
    "\n",
    "prompt = ({\n",
    "        \"context\": \"I love programming.\",\n",
    "        \"language\": \"german\"})\n",
    "chain = template | llm\n",
    "response =chain.invoke(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "005c4ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "\n",
    "class AnswerWithJustification(BaseModel):\n",
    "    '''An answer to the user question along with justification for the answer.'''\n",
    "    answer:str\n",
    "    '''the answer to the user question'''\n",
    "    justification: str\n",
    "    '''justification for the answer'''\n",
    "    \n",
    "llm = ChatOllama(model='llama3.1')\n",
    "structured_llm = llm.with_structured_output(AnswerWithJustification)\n",
    "\n",
    "structured_llm.invoke(\"\"\"What weighs more, a pound of bricks or a pound of feathers\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e540cb4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "template =ChatPromptTemplate.from_messages([(\"system\", \"You are a translator. translate the below Context:\"),\n",
    "                                            (\"human\", \"text context: {context}\"),\n",
    "                                            (\"human\", \"desired language: {language}\")])\n",
    "from pydantic import BaseModel\n",
    "\n",
    "class Answer(BaseModel):\n",
    "    '''An answer to the user question along with number of words for the answer.'''\n",
    "    answer:str\n",
    "    '''the answer to the user question'''\n",
    "    num_of_words: int\n",
    "    '''number of words for the answer'''\n",
    "\n",
    "model = ChatOllama(model= \"llama3.1\").with_structured_output(Answer)\n",
    "\n",
    "prompt = ({\n",
    "        \"context\": \"I love programming and teaching.\",\n",
    "        \"language\": \"german\"})\n",
    "\n",
    "chain = template | model\n",
    "response =chain.invoke(prompt)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b219475",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using runnable interface(invoke(), bathc(), stream())\n",
    "\n",
    "from langchain_ollama.chat_models import ChatOllama\n",
    "\n",
    "llm = ChatOllama(model=\"llama3.1\")\n",
    "\n",
    "#1 invoke()\n",
    "#llm.invoke(\"hello there!\")\n",
    "\n",
    "#2 batch()\n",
    "#llm.batch([\"hi there!\", \"what is your name?\"])\n",
    "\n",
    "#3 stream()\n",
    "# for i in llm.stream('Bye!'):\n",
    "#     print(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa4aba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imperative Composition\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf7f7380",
   "metadata": {},
   "source": [
    "## Chapter2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ab411b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load a text file\n",
    "from langchain.document_loaders import TextLoader\n",
    "\n",
    "loader = TextLoader(file_path=\"./test.txt\")\n",
    "loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d322b262",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now splitting it to a number of chunks\n",
    "\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "\n",
    "loader = PyPDFLoader(file_path=\"./test_article.pdf\")\n",
    "docs = loader.load()\n",
    "\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=10)\n",
    "splitted_docs = splitter.split_documents(docs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd66f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"length: \", len(splitted_docs), end='\\n\\n'),\n",
    "print(\"Page content: \", splitted_docs[100].page_content, end='\\n\\n')\n",
    "print(\"All metadata: \", splitted_docs[0].metadata, end='\\n\\n')\n",
    "print(\"An example of metadata: \", splitted_docs[0].metadata[\"page_label\"], end='\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dc60357",
   "metadata": {},
   "outputs": [],
   "source": [
    "# chunking when we have only raw data not a doc\n",
    "\n",
    "from langchain_text_splitters import (\n",
    "    Language,\n",
    "    RecursiveCharacterTextSplitter,\n",
    ")\n",
    "PYTHON_CODE = \"\"\"\n",
    "def hello_world():\n",
    "    print(\"Hello, World!\")\n",
    "\n",
    "# Call the function\n",
    "hello_world()\n",
    "\"\"\"\n",
    "python_splitter = RecursiveCharacterTextSplitter.from_language(\n",
    "    language=Language.PYTHON, chunk_size=50, chunk_overlap=0\n",
    ")\n",
    "python_docs = python_splitter.create_documents([PYTHON_CODE])\n",
    "python_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e06c8b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embeddings\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "\n",
    "text = (\"horse is for king\")\n",
    "\n",
    "embedding_model = OllamaEmbeddings(model=\"llama3.1\")\n",
    "horse = embedding_model.embed_documents(text)\n",
    "# len(vector[0])\n",
    "# vector[0][0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e143fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now use document loade, splitting text and embedding all combined\n",
    "#1- load the file\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "\n",
    "document_loader = PyPDFLoader(file_path=\"./test_article.pdf\")\n",
    "document = document_loader.load()\n",
    "\n",
    "#2- splitt the documnet\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
    "splitted_docs = splitter.split_documents(document)\n",
    "\n",
    "#3- embedding the documnet\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "\n",
    "embedding_model = OllamaEmbeddings(model=\"llama3.1\")\n",
    "embeddings = embedding_model.embed_documents([chunk.page_content for chunk in splitted_docs]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f4f021",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(splitted_docs), len(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec1decb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for work labtop\n",
    "# docker run --name pgvector-container \\\n",
    "# -e POSTGRES_USER=langchain \\\n",
    "# -e POSTGRES_PASSWORD=langchain \\\n",
    "# -e POSTGRES_DB=langchain \\\n",
    "# -e POSTGRES_HOST_AUTH_METHOD=md5 \\\n",
    "# -p 6024:5432 \\\n",
    "# -v pgvector-data:/var/lib/postgresql/data \\\n",
    "# -d pgvector/pgvector:pg16\n",
    "\n",
    "# connection_string:\"d539c9988113e8335cb996537db3cbcaf12438bece7430b9e11da4a311b37bc0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dd38a36b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PGVector\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_postgres.vectorstores import PGVector\n",
    "\n",
    "document_loader = PyPDFLoader(file_path=\"./test_article.pdf\")\n",
    "document = document_loader.load()\n",
    "\n",
    "#split the documnet\n",
    "\n",
    "splitter = RecursiveCharacterTextSplitter()             #chunk_size=1000, chunk_overlap=100\n",
    "splitted_docs = splitter.split_documents(document)\n",
    "\n",
    "#embedding the documnet\n",
    "connection = \"postgresql+psycopg://langchain:langchain@127.0.0.1:6024/langchain\"\n",
    "embedding_model = OllamaEmbeddings(model=\"tinyllama:latest\")\n",
    "\n",
    "db = PGVector.from_documents(splitted_docs, embedding_model, connection=connection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e9e43fa4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='95255c4c-6f31-4317-94f9-b2b36b9e1c3a', metadata={'doi': '10.1007/s00500-021-06307-x', 'page': 1, 'rgid': 'PB:354981974_AS:1141442265260032@1649152451047', 'title': 'Intelligent bearing fault diagnosis using swarm decomposition method and new hybrid particle swarm optimization algorithm', 'author': 'Saeed Nezamivand Chegini', 'robots': 'noindex', 'source': './test_article.pdf', 'creator': 'Springer', 'moddate': '2022-01-17T23:41:10+05:30', 'subject': 'Soft Computing, https://doi.org/10.1007/s00500-021-06307-x', 'keywords': 'Bearing fault diagnosis,Swarm decomposition,Optimized compensation distance evaluation,Hybrid particle swarm optimization algorithm,Support vector machine', 'producer': 'Acrobat Distiller 10.1.8 (Windows)', 'page_label': '1476', 'total_pages': 24, 'creationdate': '2021-09-30T14:13:46+05:30', 'crossmarkdomains[1]': 'springer.com', 'crossmarkdomains[2]': 'springerlink.com', 'crossmarkdomainexclusive': 'true', 'crossmarkmajorversiondate': '2010-04-23'}, page_content='APPLICATION OF SOFT COMPUTING\\nIntelligent bearing fault diagnosis using swarm decomposition\\nmethod and new hybrid particle swarm optimization algorithm\\nSaeed Nezamivand Chegini1 • Pouriya Amini2 • Bahman Ahmadi3 • Ahmad Bagheri1 • Illia Amirmostoﬁan1\\nAccepted: 17 September 2021 / Published online: 30 September 2021\\n/C211 The Author(s), under exclusive licence to Springer-Verlag GmbH Germany, part of Springer Nature 2021\\nAbstract\\nThe quality of information extracted from the vibration signals, and the accuracy of the bearing status detection depend on\\nthe methods used to process the signal and select the informative features. In this paper, a new hybrid approach is\\nintroduced in which the relatively new swarm decomposition (SWD) method and the optimized compensation distance\\nevaluation technique (OCDET) are used to enhance the signal processing stage and to improve the optimal features\\nselection process, respectively. Firstly, the vibration signals are decomposed into their Oscillatory Components (OCs)\\nusing the SWD. The feature matrix is constructed by computing the time-domain features for the OCs. The CDET method\\nis consequently utilized to select the most sensitive features corresponding to the bearing status. On the other hand, The\\nCDET approach contains a parameter called threshold which affects the number of the selected features. In this way, the\\nhybrid optimization algorithm, which is a combination of the Particle Swarm Optimization (PSO) algorithm with the Sine–\\nCosine Algorithm (SCA) and the Levy ﬂight distribution, has been used to select the optimal CDET threshold and improve\\nthe support vector machine (SVM) classiﬁer. The proposed technique ability is evaluated by vibration signals corre-\\nsponding to different bearing defects and various speeds. The results indicate the capability of the proposed fault diagnosis\\nmethod in identifying the very small-size defects under various bearing conditions. Finally, the presented method shows\\nbetter performance in comparison with other well-known methods in the most of the case studies.\\nKeywords Bearing fault diagnosis /C1 Swarm decomposition /C1 Optimized compensation distance evaluation /C1\\nHybrid particle swarm optimization algorithm /C1 Support vector machine\\n1 Introduction\\nMechanical equipment holds are the basics in modern\\nindustry with the rapid improvements in science and\\ntechnology. Among these, rotating machinery is considered\\nas one of the most complex and functional equipment in\\nindustrial applications. Thus, it seems essential to diagnosis\\nthe faults of rotary machines as one of the most important\\nparts of design and maintenance in a system (Liu et al.\\n2018). The technique of fault diagnosis (FD) of rotating\\nmachinery consists of four functions, namely, fault iden-\\ntiﬁcation, fault isolation, fault detection, and fault estima-\\ntion. In other words, the FD means the determination of\\nkind, size, location, and time of occurrence of a fault.\\nBesides, with a similar point of view, one can divide the\\nFD process into three distinguished parts: (1) inspecting the\\nfunction of equipment, (2) determining the existence and\\nthe reason for failure, and (3) predicting the fault devel-\\nopment (Jardine et al. 2006).\\nIntelligent fault diagnosis (IFD) methods include four\\nmain parts: signal processing, feature extraction (FE),\\nfeature selection (FS), and pattern recognition. The signal\\nprocessing technique plays a crucial role in extracting\\nuseful information from the vibration data. In recent dec-\\nades, various methods have been introduced for the anal-\\nysis of vibration signals, including the Wavelet Transforms\\n(WT) (Daubechies 1990), Empirical Mode Decomposition\\n& Saeed Nezamivand Chegini\\nsaeed.nezamivand@gmail.com\\n1 Department of Dynamics, Control, and Vibrations, Faculty of\\nMechanical Engineering, University of Guilan, Rasht, Iran\\n2 Institute of Acoustics and Speech Communication, Dresden,\\nTU, Germany\\n3 Department of Mechanical Engineering, Faculty of'),\n",
       " Document(id='ea45a383-8533-4208-b5a2-3a55cdf44e99', metadata={'doi': '10.1007/s00500-021-06307-x', 'page': 3, 'rgid': 'PB:354981974_AS:1141442265260032@1649152451047', 'title': 'Intelligent bearing fault diagnosis using swarm decomposition method and new hybrid particle swarm optimization algorithm', 'author': 'Saeed Nezamivand Chegini', 'robots': 'noindex', 'source': './test_article.pdf', 'creator': 'Springer', 'moddate': '2022-01-17T23:41:10+05:30', 'subject': 'Soft Computing, https://doi.org/10.1007/s00500-021-06307-x', 'keywords': 'Bearing fault diagnosis,Swarm decomposition,Optimized compensation distance evaluation,Hybrid particle swarm optimization algorithm,Support vector machine', 'producer': 'Acrobat Distiller 10.1.8 (Windows)', 'page_label': '1478', 'total_pages': 24, 'creationdate': '2021-09-30T14:13:46+05:30', 'crossmarkdomains[1]': 'springer.com', 'crossmarkdomains[2]': 'springerlink.com', 'crossmarkdomainexclusive': 'true', 'crossmarkmajorversiondate': '2010-04-23'}, page_content='between the i-th and j-th members can be applied as\\nrepulsive or attraction force, and its type is determined by\\nfunctionfdðÞ . The parameter d\\ncr is a key parameter for\\ncontrolling the distribution of members in the population.\\nThis parameter corresponds to the crucial distance from\\nwhich the force between two members of the swarm is\\nzero, that is,fd\\ncrðÞ ¼ 0. In (Rao and Kumaresan 2000), the\\nvalue of dcr is considered as the root mean square (RMS) of\\nthe input multi-component signal. The updating equations\\nof the position of each member in the hunting process are\\nas follows:\\nvi n½/C138 ¼ vi n /C0 1½/C138 þ d Fn\\nDr;i þ Fn\\nCoh;i\\n/C16/C17\\nð4Þ\\npi n½/C138 ¼ pi n /C0 1½/C138 þ dvi n½/C138 ð 5Þ\\nd is one of the most important parameters in the SWD\\nprocess. The parameter d controls the ﬂexibility of the\\nswarm members. The output of SWD is considered as\\nfollows:\\nyn½/C138 ¼ b\\nX\\nM\\ni¼1\\npi n½/C138 ð 6Þ\\nIn fact, in each repetition, the output signal of SwF is\\nequal to the weighted summation of the paths of all\\nmembers. Adopted from (Rao and Kumaresan 2000), the\\nIntelligent bearing fault diagnosis using swarm decomposition method and new hybrid particle swarm… 1477\\n123'),\n",
       " Document(id='242d398a-61ce-4b41-89f8-99de6b1c278d', metadata={'doi': '10.1007/s00500-021-06307-x', 'page': 21, 'rgid': 'PB:354981974_AS:1141442265260032@1649152451047', 'title': 'Intelligent bearing fault diagnosis using swarm decomposition method and new hybrid particle swarm optimization algorithm', 'author': 'Saeed Nezamivand Chegini', 'robots': 'noindex', 'source': './test_article.pdf', 'creator': 'Springer', 'moddate': '2022-01-17T23:41:10+05:30', 'subject': 'Soft Computing, https://doi.org/10.1007/s00500-021-06307-x', 'keywords': 'Bearing fault diagnosis,Swarm decomposition,Optimized compensation distance evaluation,Hybrid particle swarm optimization algorithm,Support vector machine', 'producer': 'Acrobat Distiller 10.1.8 (Windows)', 'page_label': '1496', 'total_pages': 24, 'creationdate': '2021-09-30T14:13:46+05:30', 'crossmarkdomains[1]': 'springer.com', 'crossmarkdomains[2]': 'springerlink.com', 'crossmarkdomainexclusive': 'true', 'crossmarkmajorversiondate': '2010-04-23'}, page_content='vibration signals. Appl Acoust 1(89):16–27. https://doi.org/10.\\n1016/j.apacoust.2014.08.016\\nAmini Digehsara P, Bagheri A, Moshfegh S (2019) Interval search\\nwith quadratic interpolation and stable deviation quantum-\\nbehaved particle swarm optimization (IQS-QPSO). Int J Multi-\\nphys 13(2):113–130. https://doi.org/10.21152/1750-9548.13.2.\\n113\\nAmini Digehsara P, Nezamivand Chegini S, Bagheri A, Pourabd\\nRoknsaraei M (2020) An improved particle swarm optimization\\nbased on the reinforcement of the population initialization phase\\nby scrambled Halton sequence. Cogent Eng 7(1):1737383.\\nhttps://doi.org/10.1080/23311916.2020.1737383\\nIntelligent bearing fault diagnosis using swarm decomposition method and new hybrid particle swarm… 1495\\n123')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check the similarity (by using model embedding only)\n",
    "db.similarity_search(\"Ahrar Institute of Technology and Higher\", k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8e3a2871",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['e169933e-9421-474e-895a-4f4ee052640e',\n",
       " '0505232b-16b7-48b9-b95b-b66d76f3002a']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How to add new data to the db\n",
    "import uuid\n",
    "from langchain.docstore.document import Document\n",
    "\n",
    "ids = [str(uuid.uuid4()), str(uuid.uuid4())]\n",
    "\n",
    "db.add_documents([\n",
    "                    Document(page_content=\"there are cats in the pond\",\n",
    "                            metadata={\"location\":\"pond\" ,\"topic\":\"animals\"}),\n",
    "                    Document(page_content=\"Ducks are also found in the pond\",\n",
    "                    metadata={\"location\":\"pond\" ,\"topic\":\"animals\"})],\n",
    "    ids=ids,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "52708b8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='e169933e-9421-474e-895a-4f4ee052640e', metadata={'topic': 'animals', 'location': 'pond'}, page_content='there are cats in the pond'),\n",
       " Document(id='0505232b-16b7-48b9-b95b-b66d76f3002a', metadata={'topic': 'animals', 'location': 'pond'}, page_content='Ducks are also found in the pond'),\n",
       " Document(id='2e865b51-29c1-4414-96fd-facef7c87198', metadata={'doi': '10.1007/s00500-021-06307-x', 'page': 4, 'rgid': 'PB:354981974_AS:1141442265260032@1649152451047', 'title': 'Intelligent bearing fault diagnosis using swarm decomposition method and new hybrid particle swarm optimization algorithm', 'author': 'Saeed Nezamivand Chegini', 'robots': 'noindex', 'source': './test_article.pdf', 'creator': 'Springer', 'moddate': '2022-01-17T23:41:10+05:30', 'subject': 'Soft Computing, https://doi.org/10.1007/s00500-021-06307-x', 'keywords': 'Bearing fault diagnosis,Swarm decomposition,Optimized compensation distance evaluation,Hybrid particle swarm optimization algorithm,Support vector machine', 'producer': 'Acrobat Distiller 10.1.8 (Windows)', 'page_label': '1479', 'total_pages': 24, 'creationdate': '2021-09-30T14:13:46+05:30', 'crossmarkdomains[1]': 'springer.com', 'crossmarkdomains[2]': 'springerlink.com', 'crossmarkdomainexclusive': 'true', 'crossmarkmajorversiondate': '2010-04-23'}, page_content='value of parameter b is considered as 0.005. Moreover, it is\\nassumed that the initial value of the velocity of all mem-\\nbers is zero and their initial positions are calculated as\\nfollows:\\npi 0½/C138 ¼ pprey n½/C138 þ dcr i /C0 1 /C0 M\\n2\\n/C18/C19\\n; 8i ¼ 1; 2; ... ; M ð7Þ\\nLet Smulti½n/C138be a non-stationary multi-component signal\\ncomposed of the mono-component signals Smono;l½n/C138, and\\nyM;d½n/C138is the SwF output for the SWD key parameters, i.e.,\\nM and d. On the other hand, the swarm parameters M and d\\naffect the outputs of the SwF method. Therefore, by solv-\\ning the minimization problem in Eq. ( 8) using the GA\\noptimization algorithm, Eqs. ( 9) and ( 10) are obtained to\\ncalculate the parameters M and d:\\nargmin\\nd; M\\nX\\nk\\nYd;M kðÞ\\n/C12/C12 /C12/C12 /C0 Smulti kðÞ\\n/C8/C9 2\\nð8Þ\\nM xðÞ ¼ 33:46x/C0 0:735 /C0 29:1\\n/C2/C3\\nð9Þ\\nd xðÞ ¼ /C0 1:5x2 þ 3:454x /C0 0:01 ð10Þ\\nwhere Yd;M kðÞ and SmultiðkÞ are the discrete Fourier trans-\\nform of the signals yM;d½n/C138and Smulti½n/C138, respectively. Also,\\nx denotes the normalized frequency. The repetitive method\\nin the SWD approach is similar to the sifting process so\\nthat each OC is obtained by applying the SwF in each\\nrepetition. Then, the obtained OC is subtracted from the\\ninput signal. If the input signal includes no other OCs, the\\nSWD approach is stopped. In the other words, the repeti-\\ntive SWD process is terminated whenever the standard\\ndeviation of the results of the two successive iterations, i.e.,\\ny\\ni n /C0 1½/C138 and yi n½/C138 , is less than the predetermined threshold\\nof StDth.\\nAt the beginning of the sifting process ( i.e., it = 0), it is\\nassumed that x0 n½/C138 ¼ y0½n/C138¼ x½n/C138. Then, the energy spec-\\ntral density of y0½n/C138, i.e., Sxit ðxÞ, is calculated and the fre-\\nquency with the highest amplitude in the energy spectrum\\nsmoothed by the Savitzky-Golay ﬁlter (SGﬁlter) is con-\\nsidered as the optimal mode frequency. Hence, the optimal\\nfrequency is estimated as follows:\\nxopt ¼ argmax\\nx S\\n0\\nxit xðÞ [ Pth\\n/C16/C17\\nð11aÞ\\nS\\n0\\nxit xðÞ ¼ SGfilter S xit xðÞðÞ ð 11bÞ\\nwhere xopt is the optimal frequency. The parameter Pth\\nlimits the search range to ﬁnd the optimal frequency and\\nconsiderably affects the computational time. In the next\\nstage, the parameters M and d are determined using\\nEqs. ( 9) and ( 10). Also, y\\ni½n/C138is obtained from Eq. ( 4)b y\\nsetting i = 1. If the standard deviation of two successive\\nsequences, i.e., P yi n½/C138 /C0 yi/C0 1½n/C138jj 2\\nðyi/C0 1½n/C138Þ2 , is less than the\\npredetermined threshold value of StDth, the ﬁltered signal\\nx\\n0\\nit½n/C138is considered equal to the signal yi½n/C138. Otherwise, in\\nan iterative procedure, the index i is increased by one unit\\nand the signal xit½n/C138 is replaced with the signal yi½n/C138.\\nFinally, if S\\n0\\nxit xðÞ \\\\Pth, the residue signal xitþ1 n½/C138 is\\nobtained by xitþ1 n½/C138 ¼ xit n½/C138 /C0 x\\n0\\nit½n/C138; otherwise,\\nxitþ1 n½/C138 ¼ xit n½/C138 . The above iterative procedure continues\\nuntil no more OCs are extracted. The ﬂowchart of SWD is\\nillustrated in Fig. 1.\\nIn the SWD technique, the number of the extracted\\nmodes and their quality depend on the parameters StDth\\nand Pth. In Apostolidis and Hadjileontiadis ( 2017), the\\nvalue of these parameters is set to 0.1.\\n2.2 The FE procedure\\nThe vibration signals of bearings have non-stationary,\\ncomplex, and nonlinear dynamics behavior. To provide\\nusable information about the characteristics of faulty\\nbearings, different FE methods are introduced. Moreover,\\nto construct the feature vector corresponding to each signal,\\nthe following procedure is proposed:\\n1. Each vibration signal is decomposed into different OCs\\nusing the SWD method. There are two parameters\\n(PS\\nth and TthÞ which have a signiﬁcant role in the SWD\\nmethod, and these parameters are considered as 0.1,\\nadopted from Apostolidis and Hadjileontiadis ( 2017).\\n2. The two OCs with the highest kurtosis value are\\nselected to extract the features in the time domain.\\n3. For each OC, the statistical features listed in Table 1')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.similarity_search(\"are cats in the pond\", k=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed736c65",
   "metadata": {},
   "source": [
    "## Chapter3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3895e1f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#p62 retrieve data\n",
    "\n",
    "retriever = db.as_retriever()\n",
    "\n",
    "#fetch relevant documents\n",
    "docs = retriever.invoke(\"\"\"What are the main components and specifications of the experimental fault simulator setup\n",
    "                         at Ahrar Institute of Technology and Higher Education (AITHE),\n",
    "                         and how were vibration signals collected and measured for different fault conditions?\"\"\", k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7e7d289e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='The Experimental Recordings for the Setup Obtained by Saeed Nezamivand Chegini Are Not Provided in the Documentary.', additional_kwargs={}, response_metadata={'model': 'tinyllama:latest', 'created_at': '2025-10-12T17:55:12.015361561Z', 'done': True, 'done_reason': 'stop', 'total_duration': 56886870749, 'load_duration': 33526931, 'prompt_eval_count': 2048, 'prompt_eval_duration': 54683028701, 'eval_count': 33, 'eval_duration': 2157772747, 'model_name': 'tinyllama:latest'}, id='run--61bd702c-320f-4e30-a2d6-ad8a0810c160-0', usage_metadata={'input_tokens': 2048, 'output_tokens': 33, 'total_tokens': 2081})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#p64 retrieve data from db and run llm\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "retriever = db.as_retriever()\n",
    "prompt = ChatPromptTemplate.from_template(\"Answer the question only based on the following context: {context}, Question:{question}.\")\n",
    "llm = ChatOllama(model=\"tinyllama:latest\")\n",
    "\n",
    "chain = prompt | llm\n",
    "#fetch relevant documents\n",
    "question= \"\"\" which institute were the experimental recordings in this setup obtained?\"\"\"\n",
    "docs = retriever.invoke(question, k=5)\n",
    "\n",
    "#run\n",
    "chain.invoke({\"context\": docs, \"question\": question})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e69e3519",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='To answer the question, the authors argue that the frequency of intermittent impulse (i.e., sudden jolts) in a virabtion signal plays a crucial role in detecting bearing faults and identifying the location of defects within bearing components. The authors provide evidence from their experiments demonstrating that an imbalance in the frequency of these jolts can be used to detect specific types of bearings, including those exhibiting irregular or abnormal behavior. They also show how this imbalance can be used to generate virabion signals with more accurate and reliable fault detection capabilities than existing methods based solely on static properties or temperature fluctuations. Overall, the authors propose a novel approach for predicting bearing faults that combines dynamic and static information using particle swarm optimization (PSO) with virabion-based approaches to identify locations of defects within bearings.', additional_kwargs={}, response_metadata={'model': 'tinyllama:latest', 'created_at': '2025-10-12T17:56:36.100509544Z', 'done': True, 'done_reason': 'stop', 'total_duration': 62229371634, 'load_duration': 29875598, 'prompt_eval_count': 2048, 'prompt_eval_duration': 49823146907, 'eval_count': 189, 'eval_duration': 12368501620, 'model_name': 'tinyllama:latest'}, id='run--ef70241d-2714-411b-9b15-6f85e10f0722-0', usage_metadata={'input_tokens': 2048, 'output_tokens': 189, 'total_tokens': 2237})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#p65 encapsulate the retrieval logic\n",
    "from langchain_ollama import ChatOllama \n",
    "from langchain_core.runnables import chain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "retriever = db.as_retriever()\n",
    "prompt = ChatPromptTemplate.from_template(\"\"\"Answer the question only based on th following context:\n",
    "                                          context: {context},\n",
    "                                          question: {question}.\"\"\")\n",
    "llm = ChatOllama(model=\"tinyllama:latest\")\n",
    "\n",
    "@chain\n",
    "def qa(input):\n",
    "    #fetch relevant documents\n",
    "    docs = retriever.invoke(input)\n",
    "    #format prompt\n",
    "    formatted_prompt = prompt.invoke({\"context\": docs, \"question\": input})\n",
    "    #generate answer\n",
    "    answer = llm.invoke(formatted_prompt)\n",
    "    return answer\n",
    "\n",
    "#run\n",
    "qa.invoke(\"\"\"What role does the frequency of intermittent impulses in a vibration signal play\n",
    "           in detecting bearing faults and identifying the location of defects within bearing components?\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c0b6b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# p74: RAG fusion for query transformation\n",
    "#part1\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "prompt_rag_fusion = ChatPromptTemplate.from_template(\"\"\"You are a helpful assistant that generates multiple search queries\n",
    "                                                      based on a single input query. \\n\n",
    "                                                     generate multiple search queries related to: {question} \\n\n",
    "                                                     Output (4 queries): \"\"\")\n",
    "def parse_queries_output(message):\n",
    "    return message.content.split('\\n')\n",
    "\n",
    "llm = ChatOllama(model=\"tinyllama:latest\")\n",
    "\n",
    "query_gen = prompt_rag_fusion | llm | parse_queries_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "75ef4115",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Sure! Here are four search queries based on a single input query, \"which institutes were the experimental recording(s) in this setup obtained?\" generated by our AI assistant:',\n",
       " '',\n",
       " '1. Which institutions had their experimental recording(s) in this setup?',\n",
       " '',\n",
       " '2. What institutes have recorded in this setup?',\n",
       " '',\n",
       " '3. Which institute was involved in experimental recording(s) in this setup? ',\n",
       " '',\n",
       " '4. What are the names of institutes that participated in experimental recording(s) in this setup?']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_gen.invoke(\"which institute were the experimental recordings in this setup obtained?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bf4fdda9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#part2\n",
    "def reciprocal_rank_fusion(results: list[list], k=60):\n",
    "    \"\"\"reciprocal rank fusion on multiple lists of ranked documents and an optional parameter k used in the RRF formula\"\"\"\n",
    "    # Initialize a dictionary to hold fused scores for each document\n",
    "    # Documents will be keyed by their contents to ensure uniqueness\n",
    "    fused_scores = {}\n",
    "    documents = {}\n",
    "    for docs in results:\n",
    "        # Iterate through each document in the list, with its rank (position in the list)\n",
    "        for rank, doc in enumerate(docs):\n",
    "            doc_str = doc.page_content\n",
    "            if doc_str not in fused_scores:\n",
    "                fused_scores[doc_str] = 0\n",
    "                documents[doc_str] = doc\n",
    "            fused_scores[doc_str] += 1 / (rank + k)\n",
    "    # sort the documents based on their fused scores in descending order to get the final reranked results\n",
    "    reranked_doc_strs = sorted(\n",
    "        fused_scores, key=lambda d: fused_scores[d], reverse=True)\n",
    "    return [documents[doc_str] for doc_str in reranked_doc_strs]\n",
    "\n",
    "retrieval_chain = query_gen | retriever.batch | reciprocal_rank_fusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "47d32509",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='The dataset was recorded at the University of California, Irvine.', additional_kwargs={}, response_metadata={'model': 'tinyllama:latest', 'created_at': '2025-10-12T18:25:29.590373008Z', 'done': True, 'done_reason': 'stop', 'total_duration': 52129277893, 'load_duration': 30851875, 'prompt_eval_count': 2048, 'prompt_eval_duration': 51146260896, 'eval_count': 15, 'eval_duration': 940389644, 'model_name': 'tinyllama:latest'}, id='run--deeb1e57-1026-41f2-b6a3-1f58f3b4c658-0', usage_metadata={'input_tokens': 2048, 'output_tokens': 15, 'total_tokens': 2063})"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#part 3 \n",
    "prompt = ChatPromptTemplate.from_template(\n",
    "    \"\"\"Answer the question based only on the following context: {context} Question: {question} \"\"\"\n",
    ")\n",
    "\n",
    "llm = ChatOllama(model=\"tinyllama:latest\")\n",
    "\n",
    "@chain\n",
    "def rag_fusion(input):\n",
    "    # fetch relevant documents\n",
    "    docs = retrieval_chain.invoke(input)  # format prompt\n",
    "    formatted = prompt.invoke(\n",
    "        {\"context\": docs, \"question\": input})  # generate answer\n",
    "    answer = llm.invoke(formatted)\n",
    "    return answer\n",
    "\n",
    "\n",
    "rag_fusion.invoke(\"In which institute were the dataset recorded?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "67dff245",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running hyde\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The experimental set of the faults simulator in the rotating machines were recorded by the authors. Specifically, the authors used the experimental set provided by the Rotor Fault Simulator (RFS) developed by the University of California, Berkeley. The RFS is a software tool that simulates the behavior of rotating machinery under fault conditions.\n"
     ]
    }
   ],
   "source": [
    "#p78: Hypothetical Document embedding\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "prompt_hyde = ChatPromptTemplate.from_template(\"\"\"Please write a passage to answer the question.\\n\n",
    "                                                Question: {question}\\n\n",
    "                                                Passage:\"\"\")\n",
    "\n",
    "generate_doc = (prompt_hyde | llm | StrOutputParser())\n",
    "\n",
    "retrieval_chain = generate_doc | retriever\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\n",
    "    \"\"\"Answer the question based only on the following context: {context} Question: {question} \"\"\"\n",
    ")\n",
    "\n",
    "llm = ChatOllama(model=\"tinyllama:latest\", temperature=0)\n",
    "\n",
    "@chain\n",
    "def qa(input):\n",
    "    # fetch relevant documents from the hyde retrieval chain defined earlier\n",
    "    docs = retrieval_chain.invoke(input)\n",
    "    # format prompt\n",
    "    formatted = prompt.invoke({\"context\": docs, \"question\": input})\n",
    "    # generate answer\n",
    "    answer = llm.invoke(formatted)\n",
    "    return answer\n",
    "\n",
    "query = \"where the experimental set of the faults simulator in the rotating machines were recorded?\"\n",
    "\n",
    "print(\"Running hyde\\n\")\n",
    "result = qa.invoke(query)\n",
    "print(\"\\n\\n\")\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d78bd117",
   "metadata": {},
   "source": [
    "# Chapter04"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1fc2f6ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='I said \"Ich liebe Programmieren.\"', additional_kwargs={}, response_metadata={'model': 'llama3.1:latest', 'created_at': '2025-10-13T07:12:44.921775671Z', 'done': True, 'done_reason': 'stop', 'total_duration': 6175321544, 'load_duration': 4875669602, 'prompt_eval_count': 57, 'prompt_eval_duration': 1054473948, 'eval_count': 9, 'eval_duration': 243756148, 'model_name': 'llama3.1:latest'}, id='run--6aad168f-87c2-46cb-ad91-73fc0554a643-0', usage_metadata={'input_tokens': 57, 'output_tokens': 9, 'total_tokens': 66})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#p96: store and use all previous messages for chat\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([(\"system\", \"You are a helpful assistant. Answer all questions to the best of your ability\"),\n",
    "                                           (\"placeholder\",\"{messages}\")])\n",
    "model = ChatOllama(model=\"llama3.1:latest\")\n",
    "\n",
    "chain = prompt | model\n",
    "chain.invoke({\"messages\":[\"human\",\"Translate this from English to German: I love programming.\",\n",
    "                          \"ai\",\"Ich liebe programmieren.\",\n",
    "                          \"human\",\"what did you say?\"]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "982de3e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#p101: Simple LangGraph for chatbot\n",
    "\n",
    "#part1: the langgraph itself\n",
    "from typing import Annotated, TypedDict\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.graph import START,END,StateGraph\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "builder = StateGraph(State)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "79aad33e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x7207c21ca5a0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#part2: the chatbot node\n",
    "\n",
    "from langchain_ollama import ChatOllama\n",
    "model = ChatOllama(model=\"llama3.1:latest\")\n",
    "\n",
    "def chatbot(state: State):\n",
    "    answer = model.invoke(state[\"messages\"])\n",
    "    return {\"messages\": [answer]}\n",
    "\n",
    "builder.add_node(\"chatbot\", chatbot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f2362b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# part3: add edges\n",
    "builder.add_edge(START, 'chatbot')\n",
    "builder.add_edge('chatbot', END)\n",
    "\n",
    "graph = builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5998f746",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "86c5a543",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'chatbot': {'messages': [AIMessage(content=\"Hello! How's your day going so far? Is there something I can help you with or would you like to chat?\", additional_kwargs={}, response_metadata={'model': 'llama3.1:latest', 'created_at': '2025-10-13T11:09:39.277638154Z', 'done': True, 'done_reason': 'stop', 'total_duration': 3333747705, 'load_duration': 837826964, 'prompt_eval_count': 12, 'prompt_eval_duration': 384534906, 'eval_count': 26, 'eval_duration': 2110435045, 'model_name': 'llama3.1:latest'}, id='run--0de1c9fa-a82c-4f3d-8ed7-2b5a6041d62f-0', usage_metadata={'input_tokens': 12, 'output_tokens': 26, 'total_tokens': 38})]}}\n"
     ]
    }
   ],
   "source": [
    "#part4: run the graph\n",
    "from langchain_core.messages import HumanMessage\n",
    "input = {\"messages\": [HumanMessage(\"hi!\")]}\n",
    "for chunk in graph.stream(input):\n",
    "    print(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7d0b52a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#p105: adding memory\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "graph = builder.compile(checkpointer = MemorySaver())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1d030996",
   "metadata": {},
   "outputs": [],
   "source": [
    "thread1 = {\"configurable\": {\"thread_id\":\"1\"}}\n",
    "result_1 = graph.invoke({\"messages\": [HumanMessage(\"hi my name is XXX.\")]},\n",
    "                        thread1)\n",
    "result_2 = graph.invoke({\"messages\": [HumanMessage(\"what is my name?\")]},\n",
    "                        thread1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2d2e327b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'messages': [HumanMessage(content='hi my name is XXX.', additional_kwargs={}, response_metadata={}, id='41aece37-78fe-4015-b4da-a67ce652fe37'),\n",
       "   AIMessage(content=\"It looks like you forgot to tell me your name! No worries, I'm happy to chat with you regardless. Would you like to share what's on your mind or is there something specific you'd like to talk about?\", additional_kwargs={}, response_metadata={'model': 'llama3.1:latest', 'created_at': '2025-10-13T11:19:28.589756195Z', 'done': True, 'done_reason': 'stop', 'total_duration': 5035488917, 'load_duration': 842498204, 'prompt_eval_count': 16, 'prompt_eval_duration': 501882709, 'eval_count': 46, 'eval_duration': 3690373313, 'model_name': 'llama3.1:latest'}, id='run--5e897c37-1a16-43be-b4c3-d846deae1008-0', usage_metadata={'input_tokens': 16, 'output_tokens': 46, 'total_tokens': 62})]},\n",
       " {'messages': [HumanMessage(content='hi my name is XXX.', additional_kwargs={}, response_metadata={}, id='41aece37-78fe-4015-b4da-a67ce652fe37'),\n",
       "   AIMessage(content=\"It looks like you forgot to tell me your name! No worries, I'm happy to chat with you regardless. Would you like to share what's on your mind or is there something specific you'd like to talk about?\", additional_kwargs={}, response_metadata={'model': 'llama3.1:latest', 'created_at': '2025-10-13T11:19:28.589756195Z', 'done': True, 'done_reason': 'stop', 'total_duration': 5035488917, 'load_duration': 842498204, 'prompt_eval_count': 16, 'prompt_eval_duration': 501882709, 'eval_count': 46, 'eval_duration': 3690373313, 'model_name': 'llama3.1:latest'}, id='run--5e897c37-1a16-43be-b4c3-d846deae1008-0', usage_metadata={'input_tokens': 16, 'output_tokens': 46, 'total_tokens': 62}),\n",
       "   HumanMessage(content='what is my name?', additional_kwargs={}, response_metadata={}, id='34580407-fa83-4cef-865d-651585b4ff5b'),\n",
       "   AIMessage(content='You mentioned earlier that your name was XXX, but it looks like you left the \"X\"s blank! Don\\'t worry if you forgot to fill in your name - I can just call you \"friend\" for now. Would you like to tell me what your real name is?', additional_kwargs={}, response_metadata={'model': 'llama3.1:latest', 'created_at': '2025-10-13T11:19:33.842227972Z', 'done': True, 'done_reason': 'stop', 'total_duration': 5248495361, 'load_duration': 55717025, 'prompt_eval_count': 76, 'prompt_eval_duration': 475075615, 'eval_count': 57, 'eval_duration': 4716818085, 'model_name': 'llama3.1:latest'}, id='run--5b9505be-1716-458e-bc71-97d4f63ddd62-0', usage_metadata={'input_tokens': 76, 'output_tokens': 57, 'total_tokens': 133})]})"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_1, result_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "871f6df2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StateSnapshot(values={'messages': [HumanMessage(content='hi my name is XXX.', additional_kwargs={}, response_metadata={}, id='41aece37-78fe-4015-b4da-a67ce652fe37'), AIMessage(content=\"It looks like you forgot to tell me your name! No worries, I'm happy to chat with you regardless. Would you like to share what's on your mind or is there something specific you'd like to talk about?\", additional_kwargs={}, response_metadata={'model': 'llama3.1:latest', 'created_at': '2025-10-13T11:19:28.589756195Z', 'done': True, 'done_reason': 'stop', 'total_duration': 5035488917, 'load_duration': 842498204, 'prompt_eval_count': 16, 'prompt_eval_duration': 501882709, 'eval_count': 46, 'eval_duration': 3690373313, 'model_name': 'llama3.1:latest'}, id='run--5e897c37-1a16-43be-b4c3-d846deae1008-0', usage_metadata={'input_tokens': 16, 'output_tokens': 46, 'total_tokens': 62}), HumanMessage(content='what is my name?', additional_kwargs={}, response_metadata={}, id='34580407-fa83-4cef-865d-651585b4ff5b'), AIMessage(content='You mentioned earlier that your name was XXX, but it looks like you left the \"X\"s blank! Don\\'t worry if you forgot to fill in your name - I can just call you \"friend\" for now. Would you like to tell me what your real name is?', additional_kwargs={}, response_metadata={'model': 'llama3.1:latest', 'created_at': '2025-10-13T11:19:33.842227972Z', 'done': True, 'done_reason': 'stop', 'total_duration': 5248495361, 'load_duration': 55717025, 'prompt_eval_count': 76, 'prompt_eval_duration': 475075615, 'eval_count': 57, 'eval_duration': 4716818085, 'model_name': 'llama3.1:latest'}, id='run--5b9505be-1716-458e-bc71-97d4f63ddd62-0', usage_metadata={'input_tokens': 76, 'output_tokens': 57, 'total_tokens': 133})]}, next=(), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0a8267-ed27-6710-8004-c9bb3ce67a30'}}, metadata={'source': 'loop', 'step': 4, 'parents': {}}, created_at='2025-10-13T11:19:33.843110+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0a8267-bb14-6bf3-8003-e0a43a4ef3b4'}}, tasks=(), interrupts=())"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.get_state(thread1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d3f787e",
   "metadata": {},
   "source": [
    "# Chapter05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c18ed48b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'chatbot': {'messages': [AIMessage(content=\"How's it going? Is there something I can help you with or would you like to chat?\", additional_kwargs={}, response_metadata={'model': 'llama3.1:latest', 'created_at': '2025-10-13T13:24:09.298345343Z', 'done': True, 'done_reason': 'stop', 'total_duration': 2896139403, 'load_duration': 852175299, 'prompt_eval_count': 12, 'prompt_eval_duration': 388221274, 'eval_count': 21, 'eval_duration': 1654961583, 'model_name': 'llama3.1:latest'}, id='run--3e9b2d27-6082-41c2-b93f-03b1bb6e01b3-0', usage_metadata={'input_tokens': 12, 'output_tokens': 21, 'total_tokens': 33})]}}\n"
     ]
    }
   ],
   "source": [
    "#P118: Arcitecture#1: LLM Call\n",
    "from typing import Annotated, TypedDict\n",
    "from langchain_ollama import ChatOllama\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "\n",
    "model = ChatOllama(model=\"llama3.1:latest\")\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "def chatbot(state: State):\n",
    "    answer = model.invoke(state[\"messages\"])\n",
    "    return {\"messages\": [answer]}\n",
    "\n",
    "builder = StateGraph(State)\n",
    "builder.add_node(\"chatbot\", chatbot)\n",
    "builder.add_edge(START, 'chatbot')\n",
    "builder.add_edge('chatbot', END)\n",
    "\n",
    "graph=builder.compile()\n",
    "\n",
    "from IPython.display import Image, display\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))\n",
    "\n",
    "from langchain_core.messages import HumanMessage\n",
    "input={\"messages\": [HumanMessage('hi!')]}\n",
    "for chunk in graph.stream(input):\n",
    "    print(chunk)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c381e664",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LangChain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
