{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e8b8e4b0",
   "metadata": {},
   "source": [
    "# Review and rerun\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f43acd53",
   "metadata": {},
   "source": [
    "## Chapter1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a59874a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# call ollama without langchain\n",
    "import ollama\n",
    "result = ollama.generate(model=\"gemma3:1b\", prompt=\"why is the sly blue?\")\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e2d0c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# call ollama inside the langchain\n",
    "from langchain_ollama.llms import OllamaLLM\n",
    "\n",
    "llm = OllamaLLM(model=\"gemma3:1b\", temperature=0)\n",
    "\n",
    "llm.invoke(\"the sky is?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbbca4af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# call ollama as chatbot\n",
    "from langchain_ollama.chat_models import ChatOllama\n",
    "\n",
    "llm = ChatOllama(model=\"gemma3:1b\", temperature=0)\n",
    "\n",
    "message = [{\"role\": \"system\", \"content\":\"You are a helpful translator. Translate the user sentence to german.\"},\n",
    "           {\"role\": \"user\", \"content\":\"I love learing french.\"}]\n",
    "\n",
    "llm.invoke(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f63aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# chat with promt template\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_ollama.chat_models import ChatOllama\n",
    "\n",
    "\n",
    "llm = ChatOllama(model=\"llama3.1\", temperature=0)\n",
    "\n",
    "template = ChatPromptTemplate.from_messages([(\"system\", \"You are a helpful assistant that translates {input_language} to {output_language}.\"),\n",
    "                                             (\"human\", \"{input}\")])\n",
    "\n",
    "chain = template | llm\n",
    "chain.invoke({\"input_language\":\"English\",\n",
    "              \"output_language\": \"German\",\n",
    "              \"input\": \"I love programming.\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf6951cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# chat with promt template(book example p8)\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "template =ChatPromptTemplate.from_template(\"\"\"You are a translator. translate the below Context:\".\n",
    "Context: {context}\n",
    "Language: {language}\n",
    "\n",
    "Answer: \"\"\")\n",
    "\n",
    "model = ChatOllama(model= \"llama3.1\")\n",
    "\n",
    "prompt = ({\n",
    "        \"context\": \"I love programming.\",\n",
    "        \"language\": \"german\"})\n",
    "chain = template | llm\n",
    "response =chain.invoke(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d03b0ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# chat with promt template(book example p11)\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "template =ChatPromptTemplate.from_messages([(\"system\", \"You are a translator. translate the below Context:\"),\n",
    "                                            (\"human\", \"text context: {context}\"),\n",
    "                                            (\"human\", \"desired language: {language}\")])\n",
    "\n",
    "model = ChatOllama(model= \"llama3.1\")\n",
    "\n",
    "prompt = ({\n",
    "        \"context\": \"I love programming.\",\n",
    "        \"language\": \"german\"})\n",
    "chain = template | llm\n",
    "response =chain.invoke(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "005c4ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "\n",
    "class AnswerWithJustification(BaseModel):\n",
    "    '''An answer to the user question along with justification for the answer.'''\n",
    "    answer:str\n",
    "    '''the answer to the user question'''\n",
    "    justification: str\n",
    "    '''justification for the answer'''\n",
    "    \n",
    "llm = ChatOllama(model='llama3.1')\n",
    "structured_llm = llm.with_structured_output(AnswerWithJustification)\n",
    "\n",
    "structured_llm.invoke(\"\"\"What weighs more, a pound of bricks or a pound of feathers\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e540cb4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "template =ChatPromptTemplate.from_messages([(\"system\", \"You are a translator. translate the below Context:\"),\n",
    "                                            (\"human\", \"text context: {context}\"),\n",
    "                                            (\"human\", \"desired language: {language}\")])\n",
    "from pydantic import BaseModel\n",
    "\n",
    "class Answer(BaseModel):\n",
    "    '''An answer to the user question along with number of words for the answer.'''\n",
    "    answer:str\n",
    "    '''the answer to the user question'''\n",
    "    num_of_words: int\n",
    "    '''number of words for the answer'''\n",
    "\n",
    "model = ChatOllama(model= \"llama3.1\").with_structured_output(Answer)\n",
    "\n",
    "prompt = ({\n",
    "        \"context\": \"I love programming and teaching.\",\n",
    "        \"language\": \"german\"})\n",
    "\n",
    "chain = template | model\n",
    "response =chain.invoke(prompt)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b219475",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using runnable interface(invoke(), bathc(), stream())\n",
    "\n",
    "from langchain_ollama.chat_models import ChatOllama\n",
    "\n",
    "llm = ChatOllama(model=\"llama3.1\")\n",
    "\n",
    "#1 invoke()\n",
    "#llm.invoke(\"hello there!\")\n",
    "\n",
    "#2 batch()\n",
    "#llm.batch([\"hi there!\", \"what is your name?\"])\n",
    "\n",
    "#3 stream()\n",
    "# for i in llm.stream('Bye!'):\n",
    "#     print(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa4aba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imperative Composition\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf7f7380",
   "metadata": {},
   "source": [
    "## Chapter2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ab411b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load a text file\n",
    "from langchain.document_loaders import TextLoader\n",
    "\n",
    "loader = TextLoader(file_path=\"./test.txt\")\n",
    "loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d322b262",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now splitting it to a number of chunks\n",
    "\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "\n",
    "loader = PyPDFLoader(file_path=\"./test_article.pdf\")\n",
    "docs = loader.load()\n",
    "\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=10)\n",
    "splitted_docs = splitter.split_documents(docs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd66f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"length: \", len(splitted_docs), end='\\n\\n'),\n",
    "print(\"Page content: \", splitted_docs[100].page_content, end='\\n\\n')\n",
    "print(\"All metadata: \", splitted_docs[0].metadata, end='\\n\\n')\n",
    "print(\"An example of metadata: \", splitted_docs[0].metadata[\"page_label\"], end='\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dc60357",
   "metadata": {},
   "outputs": [],
   "source": [
    "# chunking when we have only raw data not a doc\n",
    "\n",
    "from langchain_text_splitters import (\n",
    "    Language,\n",
    "    RecursiveCharacterTextSplitter,\n",
    ")\n",
    "PYTHON_CODE = \"\"\"\n",
    "def hello_world():\n",
    "    print(\"Hello, World!\")\n",
    "\n",
    "# Call the function\n",
    "hello_world()\n",
    "\"\"\"\n",
    "python_splitter = RecursiveCharacterTextSplitter.from_language(\n",
    "    language=Language.PYTHON, chunk_size=50, chunk_overlap=0\n",
    ")\n",
    "python_docs = python_splitter.create_documents([PYTHON_CODE])\n",
    "python_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e06c8b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embeddings\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "\n",
    "text = (\"horse is for king\")\n",
    "\n",
    "embedding_model = OllamaEmbeddings(model=\"llama3.1\")\n",
    "horse = embedding_model.embed_documents(text)\n",
    "# len(vector[0])\n",
    "# vector[0][0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e143fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now use document loade, splitting text and embedding all combined\n",
    "#1- load the file\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "\n",
    "document_loader = PyPDFLoader(file_path=\"./test_article.pdf\")\n",
    "document = document_loader.load()\n",
    "\n",
    "#2- splitt the documnet\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
    "splitted_docs = splitter.split_documents(document)\n",
    "\n",
    "#3- embedding the documnet\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "\n",
    "embedding_model = OllamaEmbeddings(model=\"llama3.1\")\n",
    "embeddings = embedding_model.embed_documents([chunk.page_content for chunk in splitted_docs]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f4f021",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(splitted_docs), len(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec1decb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for work labtop\n",
    "# docker run --name pgvector-container \\\n",
    "# -e POSTGRES_USER=langchain \\\n",
    "# -e POSTGRES_PASSWORD=langchain \\\n",
    "# -e POSTGRES_DB=langchain \\\n",
    "# -e POSTGRES_HOST_AUTH_METHOD=md5 \\\n",
    "# -p 6024:5432 \\\n",
    "# -v pgvector-data:/var/lib/postgresql/data \\\n",
    "# -d pgvector/pgvector:pg16\n",
    "\n",
    "# connection_string:\"d539c9988113e8335cb996537db3cbcaf12438bece7430b9e11da4a311b37bc0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd38a36b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PGVector\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_postgres.vectorstores import PGVector\n",
    "\n",
    "document_loader = PyPDFLoader(file_path=\"./test_article.pdf\")\n",
    "document = document_loader.load()\n",
    "\n",
    "#split the documnet\n",
    "\n",
    "splitter = RecursiveCharacterTextSplitter()             #chunk_size=1000, chunk_overlap=100\n",
    "splitted_docs = splitter.split_documents(document)\n",
    "\n",
    "#embedding the documnet\n",
    "connection = \"postgresql+psycopg://langchain:langchain@127.0.0.1:6024/langchain\"\n",
    "embedding_model = OllamaEmbeddings(model=\"tinyllama:latest\")\n",
    "\n",
    "db = PGVector.from_documents(splitted_docs, embedding_model, connection=connection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e43fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check the similarity (by using model embedding only)\n",
    "db.similarity_search(\"Ahrar Institute of Technology and Higher\", k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e3a2871",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How to add new data to the db\n",
    "import uuid\n",
    "from langchain.docstore.document import Document\n",
    "\n",
    "ids = [str(uuid.uuid4()), str(uuid.uuid4())]\n",
    "\n",
    "db.add_documents([\n",
    "                    Document(page_content=\"there are cats in the pond\",\n",
    "                            metadata={\"location\":\"pond\" ,\"topic\":\"animals\"}),\n",
    "                    Document(page_content=\"Ducks are also found in the pond\",\n",
    "                    metadata={\"location\":\"pond\" ,\"topic\":\"animals\"})],\n",
    "    ids=ids,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52708b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "db.similarity_search(\"are cats in the pond\", k=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed736c65",
   "metadata": {},
   "source": [
    "## Chapter3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3895e1f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#p62 retrieve data\n",
    "\n",
    "retriever = db.as_retriever()\n",
    "\n",
    "#fetch relevant documents\n",
    "docs = retriever.invoke(\"\"\"What are the main components and specifications of the experimental fault simulator setup\n",
    "                         at Ahrar Institute of Technology and Higher Education (AITHE),\n",
    "                         and how were vibration signals collected and measured for different fault conditions?\"\"\", k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e7d289e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#p64 retrieve data from db and run llm\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "retriever = db.as_retriever()\n",
    "prompt = ChatPromptTemplate.from_template(\"Answer the question only based on the following context: {context}, Question:{question}.\")\n",
    "llm = ChatOllama(model=\"tinyllama:latest\")\n",
    "\n",
    "chain = prompt | llm\n",
    "#fetch relevant documents\n",
    "question= \"\"\" which institute were the experimental recordings in this setup obtained?\"\"\"\n",
    "docs = retriever.invoke(question, k=5)\n",
    "\n",
    "#run\n",
    "chain.invoke({\"context\": docs, \"question\": question})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e69e3519",
   "metadata": {},
   "outputs": [],
   "source": [
    "#p65 encapsulate the retrieval logic\n",
    "from langchain_ollama import ChatOllama \n",
    "from langchain_core.runnables import chain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "retriever = db.as_retriever()\n",
    "prompt = ChatPromptTemplate.from_template(\"\"\"Answer the question only based on th following context:\n",
    "                                          context: {context},\n",
    "                                          question: {question}.\"\"\")\n",
    "llm = ChatOllama(model=\"tinyllama:latest\")\n",
    "\n",
    "@chain\n",
    "def qa(input):\n",
    "    #fetch relevant documents\n",
    "    docs = retriever.invoke(input)\n",
    "    #format prompt\n",
    "    formatted_prompt = prompt.invoke({\"context\": docs, \"question\": input})\n",
    "    #generate answer\n",
    "    answer = llm.invoke(formatted_prompt)\n",
    "    return answer\n",
    "\n",
    "#run\n",
    "qa.invoke(\"\"\"What role does the frequency of intermittent impulses in a vibration signal play\n",
    "           in detecting bearing faults and identifying the location of defects within bearing components?\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c0b6b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# p74: RAG fusion for query transformation\n",
    "#part1\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "prompt_rag_fusion = ChatPromptTemplate.from_template(\"\"\"You are a helpful assistant that generates multiple search queries\n",
    "                                                      based on a single input query. \\n\n",
    "                                                     generate multiple search queries related to: {question} \\n\n",
    "                                                     Output (4 queries): \"\"\")\n",
    "def parse_queries_output(message):\n",
    "    return message.content.split('\\n')\n",
    "\n",
    "llm = ChatOllama(model=\"tinyllama:latest\")\n",
    "\n",
    "query_gen = prompt_rag_fusion | llm | parse_queries_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ef4115",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_gen.invoke(\"which institute were the experimental recordings in this setup obtained?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf4fdda9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#part2\n",
    "def reciprocal_rank_fusion(results: list[list], k=60):\n",
    "    \"\"\"reciprocal rank fusion on multiple lists of ranked documents and an optional parameter k used in the RRF formula\"\"\"\n",
    "    # Initialize a dictionary to hold fused scores for each document\n",
    "    # Documents will be keyed by their contents to ensure uniqueness\n",
    "    fused_scores = {}\n",
    "    documents = {}\n",
    "    for docs in results:\n",
    "        # Iterate through each document in the list, with its rank (position in the list)\n",
    "        for rank, doc in enumerate(docs):\n",
    "            doc_str = doc.page_content\n",
    "            if doc_str not in fused_scores:\n",
    "                fused_scores[doc_str] = 0\n",
    "                documents[doc_str] = doc\n",
    "            fused_scores[doc_str] += 1 / (rank + k)\n",
    "    # sort the documents based on their fused scores in descending order to get the final reranked results\n",
    "    reranked_doc_strs = sorted(\n",
    "        fused_scores, key=lambda d: fused_scores[d], reverse=True)\n",
    "    return [documents[doc_str] for doc_str in reranked_doc_strs]\n",
    "\n",
    "retrieval_chain = query_gen | retriever.batch | reciprocal_rank_fusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47d32509",
   "metadata": {},
   "outputs": [],
   "source": [
    "#part 3 \n",
    "prompt = ChatPromptTemplate.from_template(\n",
    "    \"\"\"Answer the question based only on the following context: {context} Question: {question} \"\"\"\n",
    ")\n",
    "\n",
    "llm = ChatOllama(model=\"tinyllama:latest\")\n",
    "\n",
    "@chain\n",
    "def rag_fusion(input):\n",
    "    # fetch relevant documents\n",
    "    docs = retrieval_chain.invoke(input)  # format prompt\n",
    "    formatted = prompt.invoke(\n",
    "        {\"context\": docs, \"question\": input})  # generate answer\n",
    "    answer = llm.invoke(formatted)\n",
    "    return answer\n",
    "\n",
    "\n",
    "rag_fusion.invoke(\"In which institute were the dataset recorded?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67dff245",
   "metadata": {},
   "outputs": [],
   "source": [
    "#p78: Hypothetical Document embedding\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "prompt_hyde = ChatPromptTemplate.from_template(\"\"\"Please write a passage to answer the question.\\n\n",
    "                                                Question: {question}\\n\n",
    "                                                Passage:\"\"\")\n",
    "\n",
    "generate_doc = (prompt_hyde | llm | StrOutputParser())\n",
    "\n",
    "retrieval_chain = generate_doc | retriever\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\n",
    "    \"\"\"Answer the question based only on the following context: {context} Question: {question} \"\"\"\n",
    ")\n",
    "\n",
    "llm = ChatOllama(model=\"tinyllama:latest\", temperature=0)\n",
    "\n",
    "@chain\n",
    "def qa(input):\n",
    "    # fetch relevant documents from the hyde retrieval chain defined earlier\n",
    "    docs = retrieval_chain.invoke(input)\n",
    "    # format prompt\n",
    "    formatted = prompt.invoke({\"context\": docs, \"question\": input})\n",
    "    # generate answer\n",
    "    answer = llm.invoke(formatted)\n",
    "    return answer\n",
    "\n",
    "query = \"where the experimental set of the faults simulator in the rotating machines were recorded?\"\n",
    "\n",
    "print(\"Running hyde\\n\")\n",
    "result = qa.invoke(query)\n",
    "print(\"\\n\\n\")\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d78bd117",
   "metadata": {},
   "source": [
    "# Chapter04"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc2f6ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#p96: store and use all previous messages for chat\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([(\"system\", \"You are a helpful assistant. Answer all questions to the best of your ability\"),\n",
    "                                           (\"placeholder\",\"{messages}\")])\n",
    "model = ChatOllama(model=\"llama3.1:latest\")\n",
    "\n",
    "chain = prompt | model\n",
    "chain.invoke({\"messages\":[\"human\",\"Translate this from English to German: I love programming.\",\n",
    "                          \"ai\",\"Ich liebe programmieren.\",\n",
    "                          \"human\",\"what did you say?\"]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "982de3e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#p101: Simple LangGraph for chatbot\n",
    "\n",
    "#part1: the langgraph itself\n",
    "from typing import Annotated, TypedDict\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.graph import START,END,StateGraph\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "builder = StateGraph(State)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79aad33e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#part2: the chatbot node\n",
    "\n",
    "from langchain_ollama import ChatOllama\n",
    "model = ChatOllama(model=\"llama3.1:latest\")\n",
    "\n",
    "def chatbot(state: State):\n",
    "    answer = model.invoke(state[\"messages\"])\n",
    "    return {\"messages\": [answer]}\n",
    "\n",
    "builder.add_node(\"chatbot\", chatbot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2362b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# part3: add edges\n",
    "builder.add_edge(START, 'chatbot')\n",
    "builder.add_edge('chatbot', END)\n",
    "\n",
    "graph = builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5998f746",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c5a543",
   "metadata": {},
   "outputs": [],
   "source": [
    "#part4: run the graph\n",
    "from langchain_core.messages import HumanMessage\n",
    "input = {\"messages\": [HumanMessage(\"hi!\")]}\n",
    "for chunk in graph.stream(input):\n",
    "    print(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d0b52a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#p105: adding memory\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "graph = builder.compile(checkpointer = MemorySaver())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d030996",
   "metadata": {},
   "outputs": [],
   "source": [
    "thread1 = {\"configurable\": {\"thread_id\":\"1\"}}\n",
    "result_1 = graph.invoke({\"messages\": [HumanMessage(\"hi my name is XXX.\")]},\n",
    "                        thread1)\n",
    "result_2 = graph.invoke({\"messages\": [HumanMessage(\"what is my name?\")]},\n",
    "                        thread1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d2e327b",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_1, result_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "871f6df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.get_state(thread1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d3f787e",
   "metadata": {},
   "source": [
    "# Chapter05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c18ed48b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#P118: Arcitecture#1: LLM Call\n",
    "\n",
    "from typing import Annotated, TypedDict\n",
    "from langchain_ollama import ChatOllama\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "\n",
    "model = ChatOllama(model=\"llama3.1:latest\")\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "def chatbot(state: State):\n",
    "    answer = model.invoke(state[\"messages\"])\n",
    "    return {\"messages\": [answer]}\n",
    "\n",
    "builder = StateGraph(State)\n",
    "builder.add_node(\"chatbot\", chatbot)\n",
    "builder.add_edge(START, 'chatbot')\n",
    "builder.add_edge('chatbot', END)\n",
    "\n",
    "graph=builder.compile()\n",
    "\n",
    "from IPython.display import Image, display\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))\n",
    "\n",
    "from langchain_core.messages import HumanMessage\n",
    "input={\"messages\": [HumanMessage('hi!')]}\n",
    "for chunk in graph.stream(input):\n",
    "    print(chunk)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c381e664",
   "metadata": {},
   "outputs": [],
   "source": [
    "#p121: Arcitecture#2: Chain\n",
    "from langchain_ollama import ChatOllama\n",
    "from typing import Annotated, TypedDict\n",
    "from langgraph.graph.message import add_messages\n",
    "from langchain_core.messages import SystemMessage,HumanMessage\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "\n",
    "model_1 = ChatOllama(model=\"llama3.1:latest\", temperature=0.1)#low temp to generate SQL query\n",
    "model_2 = ChatOllama(model=\"llama3.1:latest\", temperature=0.7)#high temp to generate natural language outputs\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]# to track the state and conversations\n",
    "    user_query: str #input\n",
    "    sql_query: str #output\n",
    "    sql_explanation: str #output\n",
    "\n",
    "class Input(TypedDict):\n",
    "    user_query: str\n",
    "class Output(TypedDict):\n",
    "    sql_query: str\n",
    "    sql_explanation: str\n",
    "############generation part################\n",
    "generate_prompt = SystemMessage('''You are a helpful data analyst who generates SQL queries for users based on their questions.''' )\n",
    "def generate_sql(state: State):\n",
    "    user_msg = HumanMessage(state[\"user_query\"])\n",
    "    messages = [generate_prompt, *state[\"messages\"], user_msg]\n",
    "    res = model_1.invoke(messages)\n",
    "    return{\n",
    "        \"sql_query\": res.content,\n",
    "        \"messages\": [user_msg, res]# update converstion history\n",
    "    }\n",
    "############explanantion part################\n",
    "explain_prompt = SystemMessage('''You are a helpful data analyst who explains SQL queries to users''')\n",
    "def explain_sql(state: State):\n",
    "    messages = [explain_prompt, *state[\"messages\"]]\n",
    "    res = model_2.invoke(messages)\n",
    "    return{\n",
    "        \"sql_explanation\": res.content,\n",
    "        \"messages\": [*state[\"messages\"], res] # update converstion history\n",
    "    }\n",
    "############build LangGraph################\n",
    "builder = StateGraph(State, input=Input, output=Output)\n",
    "builder.add_node(\"generate_sql\", generate_sql)\n",
    "builder.add_node(\"explain_sql\", explain_sql)\n",
    "builder.add_edge(START,\"generate_sql\")\n",
    "builder.add_edge(\"generate_sql\", \"explain_sql\")\n",
    "builder.add_edge(\"explain_sql\", END)\n",
    "graph = builder.compile()\n",
    "\n",
    "from IPython.display import Image,display\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))\n",
    "\n",
    "graph.invoke({\"user_query\": \"What is the total sales for each product?\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8b3b7b43",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_54932/2482297966.py:97: LangGraphDeprecatedSinceV05: `input` is deprecated and will be removed. Please use `input_schema` instead. Deprecated in LangGraph V0.5 to be removed in V2.0.\n",
      "  builder = StateGraph(State, input=Input, output=Output)\n",
      "/tmp/ipykernel_54932/2482297966.py:97: LangGraphDeprecatedSinceV05: `output` is deprecated and will be removed. Please use `output_schema` instead. Deprecated in LangGraph V0.5 to be removed in V2.0.\n",
      "  builder = StateGraph(State, input=Input, output=Output)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'router': {'domain': 'insurance', 'messages': [HumanMessage(content='Am I covered for COVID-19 treatment?', additional_kwargs={}, response_metadata={}, id='62f0b42c-f5cf-4b5d-890e-cc29bfd167d8'), AIMessage(content='insurance', additional_kwargs={}, response_metadata={'model': 'llama3.1:latest', 'created_at': '2025-10-14T09:49:42.307128391Z', 'done': True, 'done_reason': 'stop', 'total_duration': 111410809, 'load_duration': 45526632, 'prompt_eval_count': 86, 'prompt_eval_duration': 16566037, 'eval_count': 2, 'eval_duration': 48403781, 'model_name': 'llama3.1:latest'}, id='run--daa5402d-8904-4da1-96dc-712bd1b6247f-0', usage_metadata={'input_tokens': 86, 'output_tokens': 2, 'total_tokens': 88})]}}\n",
      "{'retrieve_insurance_faqs': {'documents': []}}\n",
      "{'generate_answer': {'answer': \"It seems like you haven't provided me with any documents or details about your specific policy. To confirm if you're covered for COVID-19 treatment, could you please provide me with the following information:\\n\\n* Your insurance policy number\\n* A copy of your policy document (if possible)\\n* The name and contact information of your insurance provider\\n\\nWith this information, I can review your policy and let you know if you have coverage for COVID-19 treatment.\\n\\nAlternatively, most health insurance policies, including many employer-sponsored plans, now cover COVID-19 testing and treatment. However, it's always best to confirm with your insurance provider directly to ensure you understand the specifics of your coverage.\", 'messages': AIMessage(content=\"It seems like you haven't provided me with any documents or details about your specific policy. To confirm if you're covered for COVID-19 treatment, could you please provide me with the following information:\\n\\n* Your insurance policy number\\n* A copy of your policy document (if possible)\\n* The name and contact information of your insurance provider\\n\\nWith this information, I can review your policy and let you know if you have coverage for COVID-19 treatment.\\n\\nAlternatively, most health insurance policies, including many employer-sponsored plans, now cover COVID-19 testing and treatment. However, it's always best to confirm with your insurance provider directly to ensure you understand the specifics of your coverage.\", additional_kwargs={}, response_metadata={'model': 'llama3.1:latest', 'created_at': '2025-10-14T09:49:44.682391944Z', 'done': True, 'done_reason': 'stop', 'total_duration': 2289836051, 'load_duration': 46264568, 'prompt_eval_count': 61, 'prompt_eval_duration': 6797031, 'eval_count': 137, 'eval_duration': 2235628087, 'model_name': 'llama3.1:latest'}, id='run--7fd630b5-6676-4705-aebf-99e06491ca61-0', usage_metadata={'input_tokens': 61, 'output_tokens': 137, 'total_tokens': 198})}}\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAdwAAAGwCAIAAACM90ODAAAQAElEQVR4nOzdB3wTZR8H8OeS7j0o0F2g7A1lI7MMQfYUkKHIFJmKgIgyBBF8EQQRERd7gyBbZe+9oZRRRgsUuuhO8v6TKyFtk9A2l5K7/L7yqZdbuVye+91zz13ubFQqFQMAAMtgwwAAwGIglAEALAhCGQDAgiCUAQAsCEIZAMCCIJQBACwIQhnM7urxuMhLyUlxGRnpKkWmug8n41RKFf+XXsplMoVSKZNxSs1LvoOGckylVGabFfViKvqPaUdWjy/nlAqVeiBNkP0ST00fpp0n/aWXNI7u5OoFkMsUimzvZGsns7Hn3DzlwRWdyod5MIDCwuE6ZTCT/Rsf3zqflJxIacts7DQxZyNTKSlWKZQpbrP+qsk5plBpX76MbE3xVHDZZqp+RbHKcXKmUrzsx0/Ij5i9OKs49X/qcTTja8bUxLf2rTVkcqZUZJtQbs9lpCky01XpqerxnFzlpau7NGjvwwDMDKEMwtu7JibiTBJlcbFgh9pve/kGOzIxux+RfGrP85i7qdRdrrZr485FGYDZIJRBYD9PjqDqbVi4Z41mXkxaju14cv5Agq0d9/5XJRmAeSCUQTB3Lyf99Ut0iUoObd8PYNK1dcmDqOspPcf6e/uJ+wgALBNCGYSRkqT4ZfLtd8f7exeXflTdv5m0eVH0oK9L2DnKGYCgEMoggJtnE/esjBn2bSizJgvHRXQa6utXypkBCEfGAEy264+YgVODmJXpPtp/06JHDEBQCGUw1ZIJt8rVdrZztGNWxsffsUQlp6WTIxmAcBDKYJK/fn5AbWDh7/oyq9RmgJ8yk+1ZHs0ABIJQBpPcvZbSpIdVX7dbp61nxPkkBiAQhDIU3N+/PbSzY2WqujErVrWhp40t9886VJZBGAhlKLj715NLVnNhVs8/1DHizAsGIASEMhRQcmJ6eioL71GcFa4WLVo8ePCA5dPatWunTJnCzKP5uz7pabi0FISBUIYCOrr9ma09K2SPHj16/vw5y78rV64ws7F3tLWx4Q5ve8IATIZbd0IBPXmQ5uhqrvKjUqlWrVq1bdu2u3fvlihRom7dukOHDj179uyQIUNoaIcOHRo3bjx37tyDBw/u2rWL+sfHx1eqVGngwIFhYWE0QkRERM+ePefNmzd9+nRPT09XV9czZ85Q/+3bty9fvrxcuXJMaA7OsujbaQzAZAhlKKDUF0o3T3OVn9WrVy9btmzUqFENGjT477//Fi5c6OzsPGDAAMpZ6rllyxZ/f//U1NTPP/+8du3aX331FU2yd+/e0aNHb9682dvb29bWlvosXbr0vffeq1atWsWKFfv37x8cHMyPaQ6OLrLkxEwGYDKEMhSQIlNlb7Y7P1DFtkKFCu+88w51d+rUqVatWsnJyTnGcXBwoOx2dHT08FDfhJ5qyuvXrz937lzz5s3Vt7tnjOrXvXv3ZoXC3kGekoRQBgEglKGAZIxjZju5VbVq1QULFkydOrV69eqNGjUKCNB/27kXL1788MMPp0+ffvr0Kd9Ht8W5fPnyrLAoWNZTVABMhFCGgpKxtDQFM49evXpRe8X+/fupwcHGxqZFixYff/yxj0+2B39ER0dTIzI1X3z99deVK1em2jFVjXVHsLcvvBORmWkKmS3HAEyGUIYCsneQvYgzVyjLZLJOGpGRkSdOnFiyZElSUtL//vc/3XH27NmTnp5OqU0tGCx7HbnwpSRmOrnZMgCTIZShgLz97e5cTmbmsW3bNmp8KFWqVEmNxMTETZs25RgnPj7ezc2NT2Syb98+9uakvFAGV7K6WzKBOeA6ZSigak3dM9LN1Yq6c+fOTz755MCBA5S8hw4d+ueff6iVmfqHhIQwTR350qVLpUuXpqbkDRs2ZGZmHjlyhCrUdMaP2jT0zjAwMJAmOXny5LNnz5gZKDJYvbbeDMBk8i+//JIB5J+Lm+3J3c8yMjKDygh/l/caNWpcvXr1p59++uOPPyhJW7du/dFHH9nZ2VHV+NGjR6tXr7579+6oUaMUCsXKlSvnz59PbReTJk1KTk7+888/KamrVKmyZs2aNm3aaM8Qenp6Hjx4cNWqVXXq1DF02rDA/lkT8/Rhev22RRiAyfDkESi49fOjnsdkfDjD2p8iuvjTW74lHToM8WcAJkPzBRRc148D05KV8U/TmRW7fzM5M0OFRAah4EQfmMTbz3b99/c/mKa/shwRETFw4EC9gzjO4FFax44dqWmCmQfN+dy5c3oHubu7UxO23kETJ05s2bKl3kHblz0sFoxTfCAYNF+AqRaNi2jQzqtqY6/cg6jNN/cv8XgpKSnaCydysLW1dXBwYOZBy0NLpXdQRkYG//vs3Gh59A46su3J2X/jh8+1rifGglmhpgymentAsb+XxegNZblc7urqqncqQ/3NzcnJiQnnzD/x3Uah4QKEhDZlMFWJiq5lazn/PPEWszI/fRZRrYlrsSBHBiAcNF+AMG5fTvp7WbT1HMj/MCai/RC/oDJC1rsBGEIZBPTv2pirJxIbdvKu0sCTSdepvbHHdzyv3ty9fhsfBiA0hDII6daFhN1/Pnb2sOkx0s/eRWrXJMTHpm9e+CA5SdFpqG/xEsL/ZAaAIZTBHNZ8d+/Jg3RXT5uKtV3CWkrhd27Hdzy5ejIxKU5ZLNi+28hABmA2CGUwlw3fRz15mK5SquwcZA7Ocmc3uZ2jnHHZ7m9Jr6gAymRMqdT2eVUmZXJOqaBu+vdqKrmcqS9py9aPxmRKBT85Tc1ln1zTX91b3601VUxuw/RcI5epTElRpCYpXiQoMtJVNE7RAIfOIwT+fTZAbghlMK+oGwmXjyU9fZCRlqLIpIjOHn98BHOyV3eI59irW+frpioz3FOpVNrYyvme+jJdI3uIv5qWqWxsZMrMnO/C2TAbG+bgJPfxt6vc0NOvJC6xgEKCUAZxS05ObtWq1cGDBxmAJODHIyBumZmZNjYoxiAdKM0gbghlkBiUZhA3hDJIDEoziJuRuwgBiBFCGcQNNWWQGJRmEDeEMkgMSjOIG0IZJAalGcQNbcogMQhlEDfUlEFiUJpB3BQKBUIZpASlGcSNaspyuZwBSAVCGcQNzRcgMSjNIG440QcSg1AGcUNNGSQGpRnEDaEMEoPSDOKGUAaJQWkGcUObMkgMQhnEDTVlkBiUZhA3hDJIDEoziBtCGSQGpRnEDaEMEoPSDOKGE30gMTIGIGaoKYPEoDSDuDloMACpQCiDuKWnpysUCgYgFWi+AHGjBmVqVmYAUoFQBnGjBmVqVmYAUoHmCxA3hDJIDEIZxA2hDBKDUAZxQyiDxCCUQdwQyiAxCGUQN4QySAxCGcQNoQwSg1AGcUMog8QglEHcEMogMQhlEDeEMkgMQhnEDaEMEoNQBnGjUMYNiUBKEMogbnK5HDVlkBKEMogbmi9AYhDKIG4IZZAYTqVSMQCxGTp06PHjxzlOXYCJTCbjO86ePcsAxAz3UwZRGjFihJ+fH4UyxTE1K/PpXKVKFQYgcghlEKUKFSpUq1ZNt4+bm1uvXr0YgMghlEGsBgwYUKxYMe1Lqji3atWKAYgcQhnEqlSpUnXr1uW77e3tu3XrxgDED6EMIta/f3+qIDNNNblz584MQPxw9QWY16M7SVdOJKUnqVQyTrc/p3mlLn3UoXrVU92ZvUiqeypVWRNkn5aGXL95M+peVGjp0OCgYHrN8fNkTP97Mf79Xs5WlWPoq548GVPaOXGVG7j6+LswgEKBUAYz+n3a7aR4hZ29LCNdyVTZQ1mmvmCCD1ttGaSe6gDOMSaNkb2fTMbRFDQiJ6O/NLmK0ySr3vDNmoNmxjr5rxvK6ms3lMpsPbPeiFPJbbn0NJWrJ9f381IMwPwQymAuy6ZE2rvI2w8KZuK3YUEEp7Tp90UIAzAzhDKYxbIvbrn7yFv2DWFS8feyeykJmf2nlGQA5oQTfSC866eepaWqpJTIpM37QS8SlPduJDAAc0Iog/Cun062d5IzyXFwkl0+ksQAzAk3JALhpaYyZaYEm8WUCi4tGc19YF4IZTCDzKyLGSRGoVQqFAhlMC+EMgCABUEoAwBYEIQymAGn4jgGAAWAUAYzUP90ToKpLJNxchn2NmBeCGUwC0n+KEmloHN9ONEH5oVQBuFpHggiwRqlikMig9khlMEMVAy/3gcoGIQyCE+dyUhlgAJBKAPkFccYrioBc0MogxlwnCQvUqCGckm2lYNFQSiDGWjuXi89CqUKP7MGc0Mog/ConiyXo0YJUBC4dScIT/WGapS3b9/q2esdBiBmqCmDdFy/cYUBiBxqyiA8Tsbye0KsQ6fmGzasGjn6w6bNwxIS1U/3uHfvzpixQ95p35gGUf+z507xY06YNIr+aSfctWsbTZKcnPzrb4u/mf1VTEw0vVy3fgUNevYsdvqMSVR37tg5fMbMyVFRd/lJNmxc3aVbq0OH/2veovaChXNYnuFn1lAIEMogPJWSKfN5ps/W1nbb35tCQ8t+O3uhk6PT8+fPPhoxoGjR4kt+Wrlwwa+eHl7Tpk+k5DUyhwH9h/Ts0bdYseL/7jvVrWtvhUIxeuzgc+dPjx41cdnSNTSHYcP7PXh4n8a0s7NLTn6xdev6CZ9N7dShO8szlUp9CTYDMCeEMgiP41h+K5Qcx7m5uY8YPi6sZh0bGxuq6trZ248b+7mfr39AQNAn475ISUnesnVd3md48eI5qmtPnDCtTu36Xl7eQ4eMcnP32LBhJf9eqampPXv2C2/emmae93mqVNK8eT9YFLQpgzlwBfiVRdkyFbTdkbcjSpcuR+nMv3R2dg4MCL5x4yrLs4uXzlHtu0b1WlkLxHHVqtY8f+GMdoRyZSsyAMuDUAbhaWqU+T7Mp1YFbfez2Kf+/oG6Qx0cHZNTklmeJSUlZmRkUPuybk8PD0+9bwdgORDKYAYcM/GXb07Ozqlpqbp9UpKTA/z1NDUolAq9c/D2LuLo6Dhj+v90e8plJj1jm1Pf/o4BmBVCGcxAxZSm/aSPmjJ27d5GVV1qgqCXCYkJd+/dbtmyLXXb2drFxT/Xjqm9piKHUqXKpKSk0KlCf78Avs/DRw883D2ZCTS37sfVF2Be2O+DGahP9JkUXu3adXnxImnudzNiYqLv3ImcOesLB3uHNm93pEHly1e6du1yZGQEdZ86ffzQ4f+0U9FZu9jYp4cO/UdJXbNG7dq168+ZM43mEB8ft3nLuiFD39u5cyszgbJAzTIA+YJQBrMwMboC/AOnfDHr9u2Inr3eGTVmEPX5ft5SOt1HHR07dG/erPWgIb2pvXjHji19er3PXj7opG6dhpUrVZs8Zdy+f3bRy5kz5jVuHD51+oSOncM3blodHv525849GYBl43DfWxDcmrlRCbGZPceXYNKyYuYtH3/7LiMCGIDZoE0ZhMcxaf7IAif6oBAglAHyilPRP5zoA/NCKIPwOBtp3rpTqb7/HZr7wLwQyiA8VSZuBg9QQAhlEJ666VWKd1Pj4zNV1QAAEABJREFUODyjD8wOoQzCU0n2el6kMpgdQhnMQKI1ZfW9O/HjETAzhDKYgURryvSRUtPSGIA54apLEFhUVNSNGzelWp98/vx5ly5dHj9+zADMA6EMwtizZ8+MGTOoQ6lUhpQIkUmx7VUml/n5+86dOzczM5NeTp8+/ejRowxAUAhlMMm1a9eSkpLS09P37dvXpk0b6hMcHGxnayvJn++rMpVKhSokJMTPz49eNm3adP369dQRFxd3//59BiAEtClDQVBV0cbGZsqUKRERET///LOdnd2sWbOY1OX4NV8DDaa5BHD48OHh4eEjRoxgAKZBKEP+UJVwwYIFFEAtWrT48MMPAwJwdx7m7u6+ZcsW2j9RN9Wdb9y4MXjwYG9vbwaQf2i+gDyh03fUQEEdFy5caKHB1Pcv1p/IcluZnYME25Tt7GV2dgY/V2hoKP2l04Bly5Y9deoUdR84cIDadhhAfiCU4fWoDkgH5vb29tRNDcdUTTY+vruPLCNNwSQnPVVBH834ONSUQbncqlUrpmlrbtu2bXR0NAPIM4QyGDR16lTKFOooXrz45s2bGzZsmMcJw9/1zUhjz5+lMAl5cCtBpWSNOvvmfZL27dvv37/fxcWFujt06PD7778zgNdBKEM2CQkJv/3224MHD6i7Zs2a27dvpw4+VvIlpJLT9h8fMAn5d/XjsrXyvR7Yy7X3yy+/8M8bpMOOHTt2MAAD8OQRyEJn8KiNeOLEib6+vkOGDOETxBTXTsf9s/ppsWC7wPKuDo5yGaf7JGlO94lR6mZadUnktC+Vqlc3mVB3qIspx17dPl/brX6Z82GmHF+stXNTd9OYMs1b6M5cpenQLEfWTLJmrR3GFMmJiqhriY+j0lsPKFaigiszGbUyz5o1y8bG5ssvv3z69GmRIkUYgA6EMrCTJ0+OHj167ty5derUYYK6fuLZkR3PU5NVivTsAzhNVGpfaTKQcXoHal4qs4bmGMRehiff/1W3kuUMak6TxfrmoJd2VnJb5ujE1WvvXaa6BxOOQqGQy+UbN25cu3btzJkzS5SQ2qOzoMAQylZKqVRSHNA5qFGjRl2/fj0oKMjR0ZFBobt582ZaWlqlSpUWL15ctWrVevXqMbBuaFO2OsePH6e/kZGRUVFR3bt3p+6yZcsikd+U0qVLUyJTR1hY2IoVK6hBIzMz89GjRwysFWrK1iI9Pd3Ozq5Lly6hoaHffPMNA4tERzC0SXbo0IGakiZPnszA+iCUpe/06dM//vjjZ599RnEcGxuLX5qJwqVLl6gGffjw4YMHDw4YMKBYsWIMrAOaLyTr3LlztEkzTUvF8OHD+d+bIZHFgm/ToCbmUqVK7dmzh7rPnj2bmprKQOoQylLD/653165dCxYs4KtX3bp1q169OgMRkslk9PX16dOHaW7l3Lx582vXrjGQNDRfSEdKSsr48eNdXFy+/vpriuYC/OIDLN+TJ098fHyGDRtWtWrVwYMHM5Ac1JRFj1onvvvuO+pITk7u0aMHJTIr0G/wQBQokenvtGnTOI6jk7dxcXF0VMRAQhDKYkX1Yqo0Uce8efP8/f2Zpr2Yv70vSB5914MGDbKzs3Nyctq/f//QoUOpZ3x8PAPxQ/OFKK1bt+77779fuXJlUFAQA6uXkZFha2t74MCBn376aeLEiRUrVmQgWghl0aDWid9++83Z2blfv35XrlypUKECA8iOTgPGxsbSARPttmmHLfjv5qEQoPlCBA4dOsQ0d6iwt7enc/HUjUQGvcqVK8c3YZUtW/b333+nnTd1P336lIF4oKZsueirefHiRZMmTajF8IMPPmAA+cT/jLN37950epDOPTAQA4SyJdqyZcuvv/5KR6AKhYJqxxwnwUcrQWE6ceJE7dq1b9++vX79+j59+vj65uNW/VDI0HxhQf7555/Lly8zTfPxggUL6NSNg4MDEhlMR4lMf0NCQgIDA+n8MNPcnY7q0QwsD2rKbx5/p/P58+dHRUVNmDDBy8uLAZjZqVOnRowYQW0aOBloaRDKb9L9+/fHjx/fsmXLfv368c1/DKAQ3b17Nzg4eOrUqf7+/v3795fL5QzeNDRfvAFHjhzhz7qkpqZOnjyZEpm6kchQ+CiR6e9HH32UlpbG38SZ2tAYvFEI5cJD9eJUjVWrVvFtfKGhoeXKlWMAbxS1mA0bNiwgIIBpQrlLly5MU2Ng8Cag+aKQzJo16+jRo2vWrMHVFGDhUlJSHB0dr1+/Pn369JEjR4aFhTEoRAhlM4qOjl6yZEndunWp1fjatWuoFIO4XLly5fbt223btt23b5+Hh0fNmjUZmB+aL4QXGxvL312e2o6rVq1Kicw0P7ViAKJSoUIFSmTqCAwMpOrF/v37GW57ZH6oKQvsxo0bdNpkwoQJTZs2ZQASwjdrUIMGhcacOXNwatpMEMrCmDt37smTJ1evXh0XF0cHegxAuuhAsEqVKjY2NosXL+7Xrx+urBcWmi+E4evru3TpUupAIoPkNWjQwNXVlWrNPj4+ixYtyszMZCAc1JRNlZ6efurUqfr16zMAAJOhpmyq5OTkyZMnMwCrtG/fPmprZiAchLKp7O3t69WrxwCs0vz582NjYxkIx4aBaahlbfr06QzAKoWHhzs4ODAQDtqUTUUr8MCBA40bN2YAACZD84WpOI4bO3YsA7BKBw8ejIuLYyAchLIAmjZtqlQqGYD1Wbp06f379xkIB23KAvj2228ZgFWihjt3d3cGwkGbsgAOHTpUt25dGxvs4QDAVGi+EMCUKVOSkpIYgPU5fvz4kydPGAgHoSyAt956C9VksE4rV668fv06A+Gg+QIACm716tXVqlXDnWkFhFAWAB3BVa1aFZfQA4Dp0HwhgNmzZ0dHRzMA63P27FlcEicshLIA6tati2oyWKfNmzefO3eOgXDQfAEABbd169bAwMDq1aszEAhCWQBnzpwJDQ11c3NjAACmwYVcBUe1A47jZDKZUqmkDv6X1hUrVly+fDkDkLRmzZolJCQoFAoq+Xwfqt75+/tv27aNgWnQplxwZcqU4Tsol6loyuVyFxeXvn37MgCpq1evHtVCqMzLXqLuVq1aMTAZQrngKH+dnZ11+wQFBbVs2ZIBSF2/fv18fX11+wQEBPTo0YOByRDKBde2bduQkBDtS3t7exRKsBJ0mBgWFqbbp0GDBkWLFmVgMoSySd5//30nJye+myoO7du3ZwDWgQp/YGAg312sWLHu3bszEAJC2SRNmzYNDQ2lDhsbm27dujEAqxEcHKx9iHvt2rXpJQMh5Onqi9tXE5QZcr6bTrXmuIZOxVQc43T7aMfJPUhnJM3AXJPoGZFj2S/bUzED86S+SkPDXr6FZmacbp8cI+RYsNxyfKgurYelPV/l5OhUrXTLWxdeMKPvnmtW6g/H8kRF5xL1Xr5oZNW9Xo5vIeeqzv1er9ZeHtEbuLjKi5dwZOJx63w847I2DYOr10A5eTV+nku4wTnomyr3UO2XYmRkQ9tMtkleV/JZrgLQrE6va2fiFJmKpnXeNVL4md73zcPbsQIVOab7LgWdm7Hsyjlm1niv/4qVqsCydnaOdsbHes11yqu/vf0sRkHbqiKTCeLVZq9iBVzVBZ6wMOf/2njLei9OvSUIKz/Ln9/PWpB1I1N/RLktC6no1LqvH7Nsv02NTIpTym2YIuN1o+bxK7YMefriTCv52SIpL7My94ZsKe/5CpUrpYo5OHKdPvbz8jFYTTEWystnR6a/UL3VqWjxEq4MwARXjj0/vSe2RnO3um9b7rmgxeMjvIrbNe9T3M7OjgGYx3/rHt69kvzB1BKOLnK9IxgM5d++ipTbsY7DSjIAgaz8JsIvxL7doEBmeRZ/GlHxLbdqjXD9ABSG37+KGPptCblcTy7rP9F3+ejz1BdKJDIIq3GX4lE305jl2frTfTtHORIZCk0RP7tVs/XfXU9/KF89keDgggszQGD+oS7UEnvmX4t7etDj+6lFAtFkAYUnuIpT4jP9Jy70J29aKifH843ADORyWfxTJbMwigyZo6MtAygs3sWclQa2A/3Jm5muVCnf4FlKkKyMdKVSaXEHYZkZSgUKPBQmFVMq9A9BdRgAwIIglKFwcUyGKimA4QumEcpQqDiVJUayTM7kOLENhcrgD0QQylCoVEyltLzfwVHrnsLizj6CldIfyjK5DA+JAuvBcdoHaAAUBipvhoqc/lCmU9G4+gLMQcZxcssrWSoVnlUJhYrKm6Eih+YLKFSW2XzByXD6ESyFgeYLGaeyyBMyIHbqCgKzOCols8BdBVgnA80XShzNAQC8AfqvA1IfynFIZRCeZbYpqx9HjkvioFBx+TvRp7nnPpovQHjq0xuWV7LUh4a4JA4KlcHWCP3VAyqgb6r5okOn5n/8uZQVoilffjp23FBmHWjddu3eumXreuwNoXKltLz4y3qYUqGLjIxo2jzswoWzTMz+/W8PfYq4uOfMtK1pw8bV4S3rMAtGn5E+KX1eZk5v4Jjt9u1bPXu9Y2hoj+7vValcnRWiRo2at2jRhlmBtLS0X39bHBZWd/asHxjo4sy4JWzavHbmN1P0DvLw8Oz73sCiRYszqbCercl83sAlcddvXDEytNe7/Vnhat6sFbMOKSnJ9LdO7QbVqtVkbwg1pMksr/VWXX8326Hh9esGC7yXl/eA/kOYhFjP1mQiI+3D+rePAvzAiZodNmxYNXL0h1S9T0hMoD47d/017KP+b7dtSH/Xb1jJt6BQTe2b2V/FxETTaOvWr+AP344dO0TH1AMHvcuyN19cvnzh0/Efte/Q9L1+nRf9+L8XL9SPyz156hhNcunSee1bX712WT2T44cNTWKc9oCLqvA0H5rb5C/GUUf3nm1+XDxPoci6vx7Nf/SYwfRxer/XkSo+sbFPtW9Nf7Vz6/NeR3pfpjkW69Kt1aHD/zVvUXvBwjn8/L+f/02/AV1bvV1/8JA+W7au5ycx/r60Mr+dM436d+wcPn3GJFp1fP9nz2LpJR1zUP8ZMydHRd01/jFpvXXq0oI6pk6bwDdfGFoecudO5JCh79GxJH0vdHA9YuQHc7+bYWQ95INJD9+2FLnLbWZm5k9L5g/4oHvbdo3GT/iYBvFjjhozaNfubbt3b6fxb9y8lqNU5Gi+0LvJLP1lIc0zI+PVDdFXr/mjRau6ycnJhiYxjgrM5i3rflg4l96aisTsb6fSrD7/Yiy97Nu/Cy2qdkwjM1/80/edu7ak0k5bNH12bX/d5gtDRffo0YMzvv68x7ttac5jxg45e+4Uy4/cUWNkq6f3om2E1jaV8B07t2r7Hz68f9Dg3lTyaXOb+Plo7bLR8tMGQl8lzfzAwX+oz75/dtHHbN+x2azZXz5//kw7B1obtE4+HNSrdZsGNPOfl/6g3WbzwsiloYZCmeWXra3ttr83hYaW/Xb2QidHp737dlL4lildbuXyrQM/GE5L/8OiuTQa1Qt69uhbrFjxf2fNZxwAABAASURBVPed6ta1N01FPf9YvpRaLcaO+Vx3hvcfRI37dFhqWuoPC36d9hUV35ujxwyir79G9VquLq78+uIdOvQv9akVVtfQJHn/CPR37nfTmzdvvXvn0UkTpq9dt5xvP6LNacLEkdWr1/pt2fqPR3x669aNb2Z/aXxudnZ2yckvtm5dP+GzqZ06dKc+CxfNPXny6MiPx8+aOb9Nm44UiPyOxMj70sJ/NuHjp7FPvpu7eMRHnzx+EvPZxI+pJ339o8cOPnf+9OhRE5ctXePp4TVseL8HD+8bWR5aP5s2qOf5xeSZ9C5GlodmPn7CCE8v71Ur/qKGjtVr/6DE5xeyAOshB5XSUn88kp/xc5fb+QtmUyHv1LHHyhV/NW7UfMpXn+4/sI/6z/tuSfnylVq2bEsFnjaH3KVCy9Am07RJSwrNEyeOaMc8eOjfenXfcnIyuJW9duFXr/k9KChk144jNBVFFW0mzZu13rPrWNMmLb6dOy0xKdHI8hDaf2/Zuo5KzqJFf/j6+v/x58+538VQ0U1NTZ0x83NqSfts/Fdfz5hHizHp89FUw2B5liNqjGz1lMiTp4z74P3hVMIbNmxKux/6UNT/1OnjX3z5CX0pa1f/PWXyrJiYR/Pmz9LOPPJ2BP2bMe07akelvSbtP1q2fGf5n5tbtXxnwQ/fahdj48bVy1cs69ql1+qV29q167L97820s8zzh1BXTgylrJHrlPMXzFS1dnNzHzF8HP/y7783V6lSfdTIz6jb09NrQL8hs+dM7dPrferOMRXT5AUFdI4Z7t27w9bGltayu7sHvRw3dvK7vdtRFaNJ4/CmTVseOLhv2NDR/JgU0BRncrncyCQszxo3CufHr1q1hp+v/40bV8Obt7508ZyDg0Of3u/LZDLao5QrW4G+Nva6FULlr2fPfrQX4ftMnjyTNkjf4n7UXb1a2M6dW0+cPFK3TgMj73vs+KGrVy/9/ut6Krs0KDAwmPKaSvDDh/fv3bszd86P/MyHDhl1+Mj+DRtWUlCyPDO0PFRkHz+OmfX1fB+fovRv5IjxVNfga0kFWA+ioP5JS37Ke45ySxFD1WFqeWvfrgu9bPN2BzqSo6iidM49oW6poG1eO8jQJlOqVGk/vwAK4gYNGtMgOjS5cuXilC9msTxvZbmVDi3HL2qTxi3mzJ1esWIVimOm2QHQceq9u7epj5GZb9y0moor/+lat2pHRfT+/Xs53sJQ0S1atNjSJasdHR35jbR8uUoU8Rcvncu9roysfN2oMbLVUy2+0VvNWoS/zX9ZL14kUYGn7mW//kj9KU+pm6YaNnTMuE+GXbt+hcozzTw6+uHiRX9SOWeaI/tiRYtTuz/TbCO0/Np6/fkLZ8qWrdCqlfr02DttO1FNJUVz7JJHKsNHjAZrygWoLJctU4HvUCqVly6frxX26hQ/LTH1vHBR/1nmMqXL5+55+fL5cuUq8iuaFC/uS0WTn0OTJi3ocINqbUxzDE4FgvbzxifJuzJlXi2Mi4trkqbWUKlyNdqWJkwaRU0utGemt6BvKC9zK1e24qsXKhXtXekIkY6M6B8VgjidoyG973vr1k2qEPHFWj1O6XKfT5xOxZoKMe3StXFPJala1ZpUSli+GFgeqv9SiSxRohQ/FoUvvSMfygVeD5ZOVZDLjbTllvag6enpugWevg4K3PiEeL0TZisVGsY3GYqVg4f+4Y+OqQpCidawQZP8bmW6tCXK2dmZ/oaEZH3Xjo5O9DcxMcHIzKkkPHgQFRLy6qnKukVXy1DRpW5KRqpyUssPlTpqwWCaqxpYfmijhhne6mlpb0XepEHaMYcMHsnviiKz9+fndu1lI2RwUAk+kYn6k77cEIjuVJUqVT19+jjVvqmRh75of7+A0NAyTAgGrlMuUBmlQzO+gwooNYH9smwR/dMdQbdFJtuE9va5e1IqUUzQ15ZtDprDHCrxtLs+cGAffdNUg6DaHK0g45PknUzfeSh6IzoCondc8vMCarSqWaN2/36D+Tc1TrtOqIh8NnFkRkb6hwM/qlYtjNpbqKH2te9L+3Z7e4fc/emT0hrO8UnpVD7LMyPLQ18Tv3FqOTg48h0FXg+v0Ik+y7tOmSvQrfe15Zbfg+b4Qpmm7Lm7ueuZ0C7nQ1qNbzLhzd/+/Y+fz5w9SdU9aqx7661mNjY2tHfM11amK8cpo9xlz8jyUIst7R50S4i2eOgyVHSpOjVy9MAa1WtPnvR1hQqVaUmofZzlk+4KNLTV0/qhQp57GZKSkujIRrc/7TyYZleRNXOdOEpIiA8ICNK+dNT5pFTRdnJypiNUauShr4NqioM//LhIER+WN5wqn80XVEAVJmw5tJ+hz9myRdtG2Q9J/HwD8j4TL+8ilStXy3Fu2t1NvT+kL5JaMOgIhZq6qIy2CG/z2klMV6d2ffpHM6fd44aNqyZOGrVxg57LFTMV+puwqV5Pu+I53y6iIOP7UGHyKfKaZ9rTt56Skqx+ql32zcbbuwhVl2ZM/59uT7lMzvLMyPK4urqlp6fpjsxftsHTux5s8vyYXe6NXQFvTMFqIVremk1x7JhJ/v6Buv3zfq2b8U2GcoEaMQ4f/o/qpHQigfaLTKCtrADLQ5VraipMS0vV9tQtHlqGiu5/+/dQ4lODMhVglv86cm6Gtnp7e3t6a9o35BifrwWnpqZo+7zQxLG3V5HcM6d2klSdT6oNbqbZk1GrBf2js+Jnzpz47Y8l9F5fZ98kjaDmMkMlztAv+jgTf9FXqlQZOl2gPbalve6jRw/4g5e8zqFk6d17tletUkP7pdKH1+61mjVpSYfedI77ZsT1iROm5WUSU5w7dzotPY3CiPaE1IpUvLgfnVWPjnlkb6feqWoLJe2Enz59oncO8fFx9FebwrRg9K9ESCnj70uNXLTDv37jannNcRO1I3837+sRwz+h1ZuSkkLbPB008WM+fPTAwz0fNWUjy0OtzFQbovfijz3p/OGTJ4+Nr4eA7GFkhInxZyYm3kw5wD/IXlO90hZ4qlHSYT5fBcsj45sMtfZu27YxOLgkxYS22cr0rawAy0PZUKyY7+XLF1i3rDGp+Tj35IaKLtU9aa/PJzLhT4eatJwGtnrac1CbLzX0acf8eekPtD8YPmxM2TLl1cv/Et9dslTp3DOnT3rk6AHtruXosYPaQbt2baN9JLXyUUsO/aN1tf3vTSzPOJXBQmfoF32m3l/2ww8+oh373zu20Oe5ePHc1GkTxowbQmuEaXb7dLLi0KH/jF/F1bVrb5qWTvjSV0tj/rRk/vsDe2hPK9GJCCof1AxfsmSotnnL+CSmoPa1L7/69K9tG2nHfuXqJTrRQalUvJgvnb6gA3/6mLS66ITvrNlTqMDpnUNIcEmqTq5Z+2dCYgIVUGpTo0NRijPj7xsWVpcqX0uWzKdWmpOnjs37ftaTxzHBwSWoelu7dv05c6bRwSDF6+Yt64YMfW+nzhU/r2VkeerVa0SHh3QWnlYj7fNmzvrCxcXF+HpgomfSlXoUvtSMQ2f2qKhTIaegGffpMPqy+KH0DdIpL2p8MN6wYGSTYZrzKPTt0FdMx4gUN3mZxERGZk5nBalpm79AaNXq3+nEY+7JDRXdkiVL0+a/9a8NtL0cP3GE6pjUHPz4cTQrKCNbfYd2XU+ePEqFnM7O0elEWlT+TEmnjj3oOHvDhlVU+GnQoh+/o/1c6dCyuWdOq52KOm0dtIHTmJs3r9UO2vfPzi++/OTIkQPUoEy1Q2r0r1QxH+14Kk6Vv5qy6eiAYsniFStW/krriI4UKlaoMn3ad3xtom6dhpUrVZs8ZVy/voPCm7c2NAc3V7dflq5Zvfr3wUP7UGpQE/sn4yZTm6Z2BDpxTOdzqQUj75MUWPdufei7+WHhnO/+9zUFVrOmrf733RL+mH3y5Jnfz/+mWXgtiqfBg0bS+Vm9+zM6XTZp4vTf/1jSoWMzKqyTJkyLffZ08hfj+g3oOmPad4bel95izuxFM7/54ospnzB1XL418+vv+fedOWMeleyp0yfQJkH7hvDwtzt37snyzMjy0Blzahj56afv32nfmIo7nR7Z8fIY0Mh6EDVNHcSk2nLPHn2parly9W+UMs7OLlTgx47NusSzXdvOdCbwk0+HfzNrgZE5GNlkCB0SUf2OKp66F9gYn8RERmbep/cHfFRRUtNow4aOmfH15zmKvaGi27xZq7t3I2kH9r95M6keMP7TL1ev+WPlqt/o7CIdB7D8M7LV08FcQmL87+qGhRfU4jfowxFt3u5A/Vu2bPvk6eM16/6kKKcNIaxmXTqzonfmtIRU/rduXU8buHqTmTD941ED+U86dszntCFMmjyGaX4ERO0Y3br2YULg9CbI79PuqJRcl1HBDICxAR90p8ND/uooE/0xLaJ8bfdm3fN6PqRwLBoXUaqqe/32lrVUIGGP7qTs+vXBiHmhuQcZekYfwz2zwBw4xlnmrbpx604oVIa3AkPP6GNSupNhu/ZNDA0aP/7Lhg2aMKmgw8BVq37TOyg4pOQP85exN81yn54glfuHU/vvxEmjDA1d/udm7SW9Fss6NliDzWVW8Yy+JUtWGhrk6fGa3z6JS7t2XehEkN5BNvKCf9e//rKWSZx0numgbgs2XOAtP5GZtWywBkuc/g1VfX2/hB48wv+S2Bq4urjSPwb5Jqnn7Ii9wFvPBquXwUvipFVKAYyxzKunwToZuPeF7M08iAHgjSjYzV4AzMHAL/qUqDiAWchkFnqTexR4KEzqaoCBExlWcaIPLIdSqbLAZ/QxHBlC4VJXAwzcLhahDMA4PLwdLIb+UJbLOSVKKVgR6VwSB2KnP5QVCpWUfjwC8DoqnOiDwmSkuKH5AsC8T7MGyM1IcUMoAwBYEP2hbGfLZSpxOAfCk9kwmSwfT2IvHDZ2nNwGDXZQeOTqi0P1D9Lf296FU2Za3JYDEkAn1LyK2zELY2PLpSShwEPhefIg2cZW/yD9oVy1kWtyIsooCCzy4nNquq36lsXdU6ZYsP3j+ykMoLBEXIhz89L/UE39oVyqiqeLp82G7yMZgHCObIstXTUfj60rNO984K9MZwc2P2QA5vfkQXzcY0Wv8SX0DuWM3N9208L7sQ9TqzbxLlc7H0/kBMjtxK6YG6cSG3UpUrGO5d46cumkW3bOLKyFd2AZEdzfEsQo7lnK0S1Pnt5PHzYn1NA4nPGbjm9aFBVzN12RafCnsdREaOC3gq95FKWRCXnqh6aZNoL67V97tlKocUybFX2QbN9DrtFMeq6nyZPrl7fVor4LLMfsHbhytVze6ijMg5bN58+ZkYmxSvpoCsOn/YyvTE25FuYkOf9GhraU/H6neudjcCZ6v9y8feO5N8zXbuy5Z647id71kHPJcyxbjrllH9nYtNknNPZt6oypO8Oc76Wz2HLNjd4cXbgBXxp7jD2XlydBpDxPSUqRG5he/TY5ZsFHDKdZQEOz5zRLmyuNXn2kXMUlZ49SrM/SAAAQAElEQVRXY2afR9ZXqHlvPaXw5cgvO/QXS+1HUM+KNlKZnjfi+zAl+3np0goVKzRoUD/7nF+hYFKq9Cz5qxFYtudv5RhfX59s64nL+kGaKsdnZC/XM8dkKs07GNoIOf7nE7TC+P/4b+flIKZb5nRWoPqRvJoip8q5Fb2anCmYT6DFndkzLv5JenqGwaGcZnVmK3LZVrhmbegv+ep70Kj0llrtd6g7tuZb478RvYuh7s9/a7pfa65ZZQ1Vqe/+qDKwUWWPFY7pW3zNN55jfG7vnt2Pnzzu1au3zoKpR+VHzPqUuSsZWWn3qvzkWGzd1SPTbIK5UjvbalGPo7PUOTNBZ8lfzZBlW2O6m7x25TCdlzm34pcLkPW2nP6vXneGMpnCu7gje508Xafs6OnoiAYMwxLT7ju4liriK7LoAUPcffBV5pVC/lwpj/PxwxoTDH48IoDMzEwbG6xJsEYo/ILD2hQAyiVYLRR+wWFtCgDlEqxWRkaGra0tA+FY3kMgRAihDFYLhV9wWJsCQGUBrBZCWXBYmwJAuQSrhcIvOKxNAaBcgtVC4Rcc1qYAUC7BaqHwCw5rUwBoUwarhcIvOISyAFBZAKuFwi84rE0BoFyC1ULhFxzWpgBQLsFqofALDmtTAFQu0awG1gltyoJDKAsAlQWwWij8gsPaFADKJVgtFH7BYW0KAOUSrBYKv+CwNgWAcglWC23KgkOUmAqJDNYM5V9wWJumQqEEa4byLzisTVOhUII1Q/kXHNamqahNDYUSrBYu0hcc0sRUqCmANUP5FxweB2Uqe3t7X1/fn3/++cmTJwzAajx+/Hjx4sV+fn7Ozs4MhMOpVCoGpklISFi5cuXmzZvLlCnTuXPnJk2aMADp2r9//4YNG27evEmlvVevXghlYSGUhXT48OGNGzeeO3euY8eOnTp1CggIYABSERMTQ8V706ZNlSpV6tKlS4MGDRiYAUJZeHFxcVRrprJLzRoUza1atWIAYsZXjSMiIqhqTEXa29ubgdkglM3o5MmTFM0HDhygckx151KlSjEA8YiOjuarxpUrV0bVuNAglM0uJSWFijXVnanpjdK5ffv2DMCy/ffff1Q1joyM5KvGXl5eDAoLQrnwXLhwgdJ5+/btfItz+fLlGYAl4avGpGrVqlQ1rl+/PoNCh1AubAqFgm9xpjXPpzMu84Q37t9//6Wq8e3btztreHp6MnhDEMpvzLVr1/h0bt26NUVztWrVGEDhevToEV81rl69OlWN69Wrx+BNQyi/edu2baNojouLoxpKhw4dXFxcGICZ/fPPP5TFd+7c4avGHh4eDCwDQtlS0OZBG8mWLVuotkIV5zp16jAAoT18+JC/oKJGjRqUxagaWyCEssXZs2cPbTNRUVF8izNOfIMg9u3bR3F87949/oIKVI0tFkLZQlGNhm9xrly5MqVzo0aNGED+PXjwgK8ah4WFURzXrVuXgWVDKFu6/fv3UzpfvnyZrzj7+voygDygqvGGDRvu37/PV43d3d0ZiAFCWRxiY2P5inNQUBBtY+Hh4QxAH0phvmpcq1atLl264OSE6CCUReb48eO0yR07doyvOIeEhDAAjb1791LZoPYKvmrs5ubGQIQQyqKUlJTEV5w9PT1p82vbti0Da8VXjQlViimOUTUWO4SyuJ09e5aieffu3fw9j8qWLcvAauzZs4eymM4J89cau7q6MhA/hLIUZGRk8Pc8ksvlfDrLZHimjGRR1ZjO4FEc16tXj7K4du3aDCQEoSwpV65c4dO5Xbt2lM6VK1dmIDbDhw9fuHCh3kF0SERZ/OjRIzqDR3GMH39KEkJZmrZs2ULpnJKSwp8PdHBw0B1K5+Vbtmw5Y8YMBhZmzJgxBw8ePHnypG7PqKgoqhrTF1q/fn3KYvr6GEgXQlnKIiIi+POBTZo0oWgOCwujnnRWMCYmxtbWlmpb48aNY2Axpk6dunPnzvT09MDAQPrWqM+uXbuoakzfF31Z9A2iamwNEMpWgTZ12sijo6OpnrVo0SKFQkE9nZyc+vbtO3DgQAYWYMGCBVQdTkpKom7aZXbv3p2+soYNG9JXxu9NwUrgTr5WobUGf+0UnRXkTwMmJyevWLGiSJEi1MTB4I1avnw5RTCfyCQtLc3Hx2fHjh14ULQVwjl6KxIQEEBbvu6FGYmJiVRxPnDgAIM3Z+/evb/++mtCQoK2D31HFNNIZOuE5gvpO7v/6em9cRmpTJHJCvBlUwHhOFYQBZrShLej4szyrWBTFQaVjQ1n78jVeduzYj3cKdCKoPlC4q6eiju2PS6gnGPpau7OrnKFSq47lFNx6v1y9kk4JVPJmCYbVZpxGI3FNGOqB2dLMY5pc/5l/6zxtcM0/bU9tV7OX2cOL+fID1blzkrNMnD6BtFnkGV9oFz7He0Caz+C7nvlWFq9E7JsnytrXH1prp2JnrkZmK0hMo69SEy7cTL+3w3PnNxsS1TED0OsBWrKUrZr+cM7l5J7TQhlIGYrvo4oV8ulSdfiDKwA2pSlLPJ8crOexRiIXN02XleOJzGwDghlyTq8/bHchiteAoe9oleqmpdMzk7/G8vACqBNWbLiH2fK5AykQS6XPX+YwcAKIJQlKzOdy0xjIA0ZqUpFJk7/WAWEMgCABUEoAwBYEIQyAIAFQSgDAFgQhLJkqX+sbKE/IAYAgxDKUoZMBhAdhLJkqVQMP6EHEB2EsmRR8wXHoa4sEZyMk8nwbVoFhLJkaWrKqCpLBA57rAdCGUAMlEylRCxbBYSydHEFvl08ALwxCGXpUnE45AUQHYSyZHEM18RJCL5Oq4H7KUtW1qOYxG/T5rUzv5nCrJxkvk54HdSUwdJdv36FAVgNhLJkcSzfJ/qUSuX38785dPg/O1u75s1bV6pYdcKkURvW7fLy8s7MzPxl2aJjxw89fhxdqVK1Th26163bkJ+qY+fwAf2HxMfH/f7HEkdHx1ph9T4aPs7buwgNevYsdtGP3126fD41NbVWrXp9+wwMDAym/pGRER982HPmjHlzvpvu4eG5dMmq27dvbf1r/ZmzJ6OjH4YEl2zTpmOH9l1pzFFjBp0/f4Y6du/e/tPi5WVKl7t8+QK90bVrl909POvVfatf30HOzs7GP1dSUtK69ctPnDx6584tb68i9es3fn/AUAcHBxr01dTPOI4Lb/72rNlfpqQkV6hQecigkeXLV6JB9+7d+fW3xefOn1apVBUrVunZvW/lytU6d23ZoX23fn0/pBHoI9Nnb9I4fMoXs/g36tq9dZfO777bs5+hhdywcfXKVb+OHjVhypefduzYfcTwcQwgOzRfSJaK5ftE37r1K/7atnHER58sXrzc0dGJUph6ymTqQjJ/wez1G1Z26thj5Yq/GjdqPuWrT/cf2MdPZWtru2bNHzTa5k37fv91w8VL5377/Sfqr1AoRo8dTKE2etTEZUvXeHp4DRve78HD+/wk9PeP5Ut7dH9v7JjPqXvhorknTx4d+fH4WTPnUyLTvuHY8cPUf953SygiW7Zs++++U5TI9x9Ejft0WGpa6g8Lfp321ZzIyJujxwyiHYbxz7VxE0Xhb/ReX8+YN3jwyP/276HE5AfZ2NhcvnJhz96/F//4547th+zt7PmmkvT0dNofyOXyb2YtmPvtjzZym0mfj6ZdS1hY3StXL/LT0i6kWLHi9Hn5l/TRYmOf0ghGFtLOzi45+cXWresnfDaVdmwszzgNBlYAoSxZchv6l7/NeNfubY3eakZVP3c39969Bji9rIGmpaXRoF7v9m/frgsNavN2h+bNWv/x58/aCf39A/v0ft/VxZUqyFRTvnHjKvW8ePEcVTYnTphWp3Z9qmsPHTLKzd1jw4aVjGX91LBWWN1uXXuXL1eRuidPnvntt4tqVK9VvVoY1ZHLlil/4uSR3Eu4d+8OWxtbSrqgoJCQkJLjxk6+GXGdqvbGP1f3bn2oMk6fi2b+VsOmTZu01J15SnLyJ+O+8PP1p4CmzxUVdTc5OZn+Pn/+jKq9tCcoVao01YW/+upbClZawkuXzvG/yjl//nSTxi2SkhL5Pc3Fi2ep1l86tKyRhaQPTsnes2e/8OatAwKCWJ6pNBhYAYSyZCkyWb4eIEQV2zt3Iuk4Xdun0VvN+Q4KWao5UtpqB1WrWpOaIOIT4vmXZcqU1w5ydXV78UL96GWqQlKNmFKM7095RFOdv3BGO2aZ0q+motTZuHF13/5dmjYPo3/Xrl+Je/4s90Jevny+XLmK7u4e/MvixX39/AIuXDzLjKLFOHnq6NBhfVu0qkszX7tu+XOdmQcGhTg5OfHdLi7q58wmJiZQYlLCUpvG8hXLLl06T8cBFOguLi41a9ShyKbGFv4DVq5UjZbn0kV1ZZl2QjVr1M7LQpYrW5HlF22p+Jm1dUCbMmRJSUmhupiT06v2WW2sUGWQ/o4Y+UGOSZ4/i6WKM2P6b7JBU2VkZFAI6vakpNN229nb8x3Ulv3ZxJEZGekfDvyoWrUwqnHnfi/tPCmvc8yTFoMZteTnBX//vZkaLmi/Qg0OS39Z+PeOLdqhfPtMDvb29t//7+ftf2+mRhtqxqFU7d93UIsWbXx8ilKzOLWS0zEBRXP16rWuXrtE6dyq1TsUuz179M3LQlIjBssvJf1DTdkqIJQli1P/oi8f4/MnvihGtX2eP8/KEe8iPvR37JhJ1EyhO0nRosWNzJBii877zZj+P92ecn1P2L5x8xqdE5vz7SK+psk0ueZTpGjuMb28i9DZNjqvqNvT3c2DGUZ7mr+2bejapdc7bTtpZ87ygBofqMmF3uvMmRM7dm79etYXwSElqTWDFpKalWnvUrJkKFWxK1eu/uPi/9FJv/v379E5vYItJIAWQlmyVOpf9OVjfGpRLVq02J07t7R9Dh/Zz3cE+AfZa2q1dAjP96HDf0212snIDEuVKkO1bwpuf78Avs/DRw883D1zj0mJRn+1KUytKPSvREgpPfMsWXr3nu1Vq9TQVm9pTOONs7SbocUo8nLm1A5z5OgB9jrUGk4nAN9u3Z72VfXrN6pTp0HrNg2oGYdCuUaN2j/++D8XZ9eqVWvSmNSCQSNTOzKFODWdF2whX0tzlzgG1gDfs2Spb92Zz1bI+vUaUZqcPHWMAnfd+hXUtMr3p/Dt328wndmjZlMKtf0H9o37dNi872cZnxvVKGvXrj9nzrSYmGiK3c1b1g0Z+t7OnVtzjxkSXJJ2CWvW/pmQmEABt+CHb+kcYHTMI34oVc+vXr105uxJ2hN07dqb2jp+WDSXTpfRubiflsx/f2CPyNsRRhaD2gooLqmqS6fjaDFmz5lKMUof7cWLF0amSkiIn/3t1B8Xz7v/IIreaMXKX+ksX6WKVZl6z1SLlu3o0QP8S1o5dHJv46bVNWvW4actwEK+lkqpUioZWAOEsmSpb92Zz1bIfn0H0cH4p+M/eq9vp7t3b9MhP1PXoNWXr1Fr6Sfjvli5+rd2HZp8KJtNVAAADLNJREFUP/8bP9+AsWM/f+0MZ86Y17hx+NTpEzp2DqfYCg9/u3PnnrlHo3beSROnU5tAh47NJn4+euAHw9u370pB3G+A+lLldm07U5v1J58OvxV5083V7ZelaxwdHAcP7UNnBc+dP/3JuMlUezW+GJMnfe1g79B/QNc+fTvSrmLgwI/oZacu4Y+iHxqapFKlqmNGT9y7bwetCnqjixfPfjd3cUhISaY+GehStmwFqvVrz2HS2VHdlwVbSAAeh+tspGrrT48eRiT3/rxU3iehmt3jx9FUr+Rfrl7zx4oVy/7a+h+DN+3PqRGlqji36ufLQOpQU5YsTsXl9xd9lMKDhvTesHE1Heb/8+/uteuWt9f8rA4ACg1O9EmXXKW+ACM/+vcbFB//fPfubT8vXeDjU6xTxx69ew1gYtCufRNDg8aP/7JhgyZM5HCiz3oglKUt3z83GPnxeCZCK1f+ZWgQte0y8cOJPuuBUJYslTU9QMhV80s8KZPh3hfWAqEsWZz6mJeBRChx7wtrgVCWLnUio24FIDIIZcmyquYLAMlAKAOIgPr3mWhTtg4IZcniZCoON3uUCvXvM9GmbB0QytKVzxsSAYAlQChLFupWAGKEUAYAsCAIZcmiNmWZLdqUJYK+Sk6Ob9MqIJQly9GVcQy/zJUMlYMLA2uAn3xJVt23PdPTGUiAQqFQZrBGHYszsAIIZclycXd0LyLf/EMkA5Hb8sMdL185A+uAm9xL3Nrvo+KfprUbEuTskv8nKMOblvQsffvP93yCHDoMCWBgHRDK0rdmzu2n0QobG06ZqVKqcp4s4jiWowiofzimynaJs6ZH1t/XTq5DfZt9lc4cWPZ5Mp2eOUbQzFale++OHG8kkzHdW1nyQ7P+ahZWpW9CzfKosi2Dvkn0vot2PpxM/RP2HD1l1H6vyv1Bsj7Cq2k1PVVZ61h3bahUWYuT1Z/emuNUikzmE2TbfVQwA6uBULYWp/Y+fZGg/r5fPyrH/+ok55gq/fc34gyPqTtI9bq7I+WMKRVT5eVqA2puPXToUOPGjXXfS6UOST2fVN9C8O+bbZKs1My5FFlLaPyT6A41MKam98thqperO8ckSpXK1cumZjMvBlYGoQzilpSU1LZt2/379zMAScAlcSBumZmZNjYoxiAdKM0gbghlkBiUZhA3hDJIDEoziBtCGSQGpRnEDaEMEoPSDOKGUAaJQWkGccvIyLC1tWUAUoFQBnFDTRkkBqUZxA2hDBKD0gzihlAGiUFpBnFDKIPEoDSDuOFEH0gMQhnEDTVlkBiUZhA3hDJIDEoziBtCGSQGpRnEDW3KIDEIZRA31JRBYlCaQdwQyiAxKM0gbghlkBiUZhA3hDJIDEoziBtCGSQGpRnEDVdfgMQglEHc7O3tnZycGIBUIJRB3FJSUpRKJQOQCoQyiBs1KFOzMgOQChkDEDOEMkgMasogbghlkBiEMogbQhkkBqEM4oZQBolBKIO4IZRBYhDKIG4IZZAYhDKIG0IZJAahDOKGUAaJQSiDuCGUQWIQyiBuCGWQGIQyiJutrW1GRgYDkAqEMogbasogMQhlEDeEMkgMQhnEDaEMEoNQBnFDKIPEcCqVigGITZ8+fZ49e8ZxHJ3li4+P9/Hxoe60tLTdu3czADHD/ZRBlFq0aJGQkBATE0PRrFAooqOjHz165OLiwgBEDqEMotSjRw9/f3/dPnTMV7NmTQYgcghlECUHB4du3brZ29tr+/j5+VFSMwCRQyiDWHXt2jUoKEj7snr16qGhoQxA5BDKIGJ9+/Z1cnKiDjrR1717dwYgfghlELG33347ODiYOipUqFCpUiUGIH64JA4KQ+SlxEtH4h9HpSkymCJTxdT/cRydnGMcnaLj1H+ZppPvo+lU91JxHF9EOc0YfE/GyZhKqelQqf9Pf2TUS8a9mqnOX37+WRNyjJ/by24mkzGl8tVycjL1HGVy5uRq41nMtnpTt8DSrgygECGUwbzWz496fC9NqWCcDZPbyh1d7OR2ck5GYfgyQrXpq4ncrDjOFa/US6mSyTh+oCZnVTSR7GVQM1VWqqtj/OWrrP6vcl9ngEqnpxb1VCqU6WmZijRlRmqmUqGigPYt4dBpWAADKBQIZTCXDQvuP7qdamMv8/R3LVbKi4nToxux8Y+SFOlK/1DHjsP8GYCZIZRBePHPk5fPeGhjIwuoUdTZ1ZGJX2Jcyv2zMVSRHjQrRC6XMwCzQSiDwCLOJe78PcYryM2vnDeTlvuXnsQ9TOr8sb9fCSnsacAyIZRBSA9upWxa+KBSixJMopRK5ZW9d9/9NNDb154BmAFCGQRz/dTzvatiK4ZLNpG1Lu+53XGYn3+oEwMQGq5TBsHsWRFbuoFVXKUQFFZs06KHDMAMEMogjB/HRzh529k52jIr4Orp5OBm+9OECAYgNIQyCOC/tTHKTFayphVdMRZaJyAjlR37+wkDEBRCGQRw5USid7AbszIe/s6n98UzAEEhlMFUx7Y/VSpZ8dIWegFc0ovn4ybXOXdxLxNaQMWiKiU7fzCWAQgHoQymunwswcHVKpqSc7N1lJ/eG8cAhINQBlOlJCmLBLszq+Qd5J6cgItKQUh4mjWYJPJyIv318DXXrdQSEmP/2jHvTtSF9PTUsqXrhjd+v6iP+l6dh4+t27N/2dD3f/xj9YSYx5G+xUIb1X+3Vo13+KnOXti9c99PKSkJFcq91bhBb2Y2tDeKvv4s7nG6R1E7BiAE1JTBJLcvvch1qzXBKBSKxcuG3bpzpku7z8Z+tNLF2Wv+kvefxt6nQXIb25SUxM3b53TvOPHbqceqVGq2dvP053HRNOhRTMTK9V+EVW/z2agNYdXabtk+l5kTJ2NXjycwAIEglMEkCbGZcltzpfLte+ceP73zbtevypWp5+bq3a71x85OHgePruaHKhQZLZoODA6szHEcha9KpXrw6Ab1P3J8g4d78RZNPnBycgstWbNOWEdmTjIb2fOnaQxAIGi+AJNkpKlkcnPt2u/cPS+X25YuGca/pPAtVaJG5J2z2hGC/CvyHU6O6gvyUlLVbSlPn0UVL1ZSO06gfwVmTpyMS09GszIIBqEMJpHJmfnunpKSmkTV4XGT6+j2dHH21HZznJ5KenJyQhHvQO1LOzvz3tFNfWd9GY44QTAIZTCJg6OMKc2Vyq4u6h9uv987W6Ow7HUJSK0WGRmp2pdpaS+YOSkVSmcXszWrg/VBKINJvPzs791IYebh71smPT3Fw6NYEa+s+xzFPnugW1PWy9PD98q1g0qlko/vK9cPMXNSKlVFgxwYgEBw2AUmqVDLRalgZlK6VK1ypeut2zzjeVx00ou4w8fXf7+4/4kzfxmfqmrF8KQXzzdvn0un/iIiTx85vp6Zk0rBqjX2ZAACQU0ZTOJR1EEuZzG3npnpKXzv9/nu6MmNy9d+fjfqok+R4BpVW79Vr4fxScqWrvNOqxFHT2z85Iu6Hu7Fe3f7auHSwdrnqwrr4ZWnciv9MSOYC25yD6ZaPeduwnNVmYaBzPpcO3DPu5hNt1HW+NnBTNB8AaZq2LFIRmoms0qZqYqWfYsyAOGg+QJMFRDq7OAku33qUYkwX70jvHgRN3NeF72DHO1dUtKS9A4q7lPyo0E/M+F8PqO5oUEKRaZcrmdbKFok5OPBvxiaKuL4A2d3ubsXHtYHQkLzBQjgYWTKxh8MPi9VoVDEJ8ToHZSenmpnp//SBZnMxsNdyEros+cGH+CUnpFmZ2uf32W4tPt2vylBrh646wUICTVlEIBfSceiAfY3D0eVbqCndVUul3t5+rE3TdhluHbwjm9JWyQyCA5tyiCM7mMClQpF1MXHzArcPRcjZ6zLiGAGIDQ0X4CQFo2LcC3qFFi5GJOuu2cfJcelDp0dygDMAKEMAqNcdipiF1JVmg9RvX3mQXpixuBZpRiAeSCUQXiLx0fIbORlGgYxabn6322OsSHfoI4MZoRQBrNYNy8q5l6ak5d9yZpv/hSf6SJPPEiOSy8WYtdtpNT2NGBpEMpgLjF3U7Yve5ScqLR1tHEr7uwbapbfYZvVoxtP46NfZKYqnVxlHT/y8yqKGw+B2SGUwbwe3k7Zv+HJ8+h0pYJxcsZRkZMxmfo+yHpud8lxrwqkesz83rCCZpujPHNZN71QaWb32klowZRKpUqpUv9TqRfYu7hdeC+fIn7mvSkzgBZCGQpJ8ou0CwcSHt9LT0vNVGRyeu8tx8mYSpnVLZdzCsXrC6duqOpOnqOPobnlmERuw8lkzN5JVizIoUZzD1tbOQMoXAhlAAALgl/0AQBYEIQyAIAFQSgDAFgQhDIAgAVBKAMAWBCEMgCABfk/AAAA///OKJn1AAAABklEQVQDAI2/HYh7XNurAAAAAElFTkSuQmCC",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'router': {'domain': 'insurance', 'messages': [HumanMessage(content='Am I covered for COVID-19 treatment?', additional_kwargs={}, response_metadata={}, id='978d375e-1eeb-46fd-a8fd-6868dd8777c8'), AIMessage(content='insurance', additional_kwargs={}, response_metadata={'model': 'llama3.1:latest', 'created_at': '2025-10-14T09:49:45.037583659Z', 'done': True, 'done_reason': 'stop', 'total_duration': 95815921, 'load_duration': 47379830, 'prompt_eval_count': 86, 'prompt_eval_duration': 5710521, 'eval_count': 2, 'eval_duration': 41597741, 'model_name': 'llama3.1:latest'}, id='run--5db463db-00e8-45c8-a95e-f2cade8d0435-0', usage_metadata={'input_tokens': 86, 'output_tokens': 2, 'total_tokens': 88})]}}\n",
      "{'retrieve_insurance_faqs': {'documents': []}}\n",
      "{'generate_answer': {'answer': \"I'd be happy to help you with your question.\\n\\nTo confirm if you're covered for COVID-19 treatment, can you please provide me with the following documents or information:\\n\\n1. **Policy details**: Your insurance policy number, type of plan (e.g., individual, group), and coverage start date.\\n2. **Pre-existing condition waiver**: If you have a pre-existing medical condition that may be related to COVID-19, please let me know if it's been waived by your insurance provider.\\n3. **Doctor's note or diagnosis**: If you've already visited a doctor for COVID-19 symptoms, provide the doctor's note or diagnosis confirming the illness.\\n\\nOnce I receive this information, I can help you understand your coverage and any specific requirements or limitations related to COVID-19 treatment.\", 'messages': AIMessage(content=\"I'd be happy to help you with your question.\\n\\nTo confirm if you're covered for COVID-19 treatment, can you please provide me with the following documents or information:\\n\\n1. **Policy details**: Your insurance policy number, type of plan (e.g., individual, group), and coverage start date.\\n2. **Pre-existing condition waiver**: If you have a pre-existing medical condition that may be related to COVID-19, please let me know if it's been waived by your insurance provider.\\n3. **Doctor's note or diagnosis**: If you've already visited a doctor for COVID-19 symptoms, provide the doctor's note or diagnosis confirming the illness.\\n\\nOnce I receive this information, I can help you understand your coverage and any specific requirements or limitations related to COVID-19 treatment.\", additional_kwargs={}, response_metadata={'model': 'llama3.1:latest', 'created_at': '2025-10-14T09:49:47.79112565Z', 'done': True, 'done_reason': 'stop', 'total_duration': 2673921001, 'load_duration': 44575807, 'prompt_eval_count': 61, 'prompt_eval_duration': 4942974, 'eval_count': 161, 'eval_duration': 2623432893, 'model_name': 'llama3.1:latest'}, id='run--3df74312-92e1-4695-9fa1-075624ac81e1-0', usage_metadata={'input_tokens': 61, 'output_tokens': 161, 'total_tokens': 222})}}\n"
     ]
    }
   ],
   "source": [
    "#P126: Arcitecture#3: Router\n",
    "\n",
    "from langchain_ollama import OllamaEmbeddings,ChatOllama\n",
    "from typing import Annotated, TypedDict,Literal\n",
    "from langgraph.graph.message import add_messages\n",
    "from langchain.docstore.document import Document\n",
    "from langchain_core.vectorstores.in_memory import InMemoryVectorStore\n",
    "from langchain_core.messages import SystemMessage, HumanMessage\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "\n",
    "embedding_model = OllamaEmbeddings(model=\"llama3.1:latest\")\n",
    "model_low_temp = ChatOllama(model=\"llama3.1:latest\", temperature=0.1)\n",
    "model_high_temp = ChatOllama(model=\"llama3.1:latest\", temperature=0.7)\n",
    "\n",
    "############ State prepration ################\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "    user_query: str\n",
    "    domain: Literal[\"records\", \"insurance\"]\n",
    "    documents: list[Document]\n",
    "    answer: str\n",
    "class Input(TypedDict):\n",
    "    user_query: str\n",
    "class Output(TypedDict):\n",
    "    documents: list[Document]\n",
    "\n",
    "############ Vectore store prepration ################\n",
    "medical_records_store = InMemoryVectorStore.from_documents([],embedding_model)\n",
    "medical_records_retriever = medical_records_store.as_retriever()\n",
    "\n",
    "insurance_faqs_store = InMemoryVectorStore.from_documents([],embedding_model)\n",
    "insurance_faqs_retriever = insurance_faqs_store.as_retriever()\n",
    "\n",
    "############ Router part ################\n",
    "router_prompt = SystemMessage(\n",
    "    \"\"\"You need to decide which domain to route the user query to. You have two domains to choose from:\n",
    "- records: contains medical records of the patient, such as diagnosis, treatment, and prescriptions.\n",
    "- insurance: contains frequently asked questions about insurance policies, claims, and coverage.\n",
    "\n",
    "Output only the domain name.\"\"\")\n",
    "def router_node(state: State) -> State:\n",
    "    user_message = HumanMessage(state[\"user_query\"])\n",
    "    messages = [router_prompt, *state[\"messages\"], user_message]\n",
    "    res = model_low_temp.invoke(messages)\n",
    "    return {\n",
    "        \"domain\": res.content,\n",
    "        # update conversation history\n",
    "        \"messages\": [user_message, res],\n",
    "    }\n",
    "############ pick part ################\n",
    "def pick_retriever(\n",
    "    state: State,\n",
    ") -> Literal[\"retrieve_medical_records\", \"retrieve_insurance_faqs\"]:\n",
    "    if state[\"domain\"] == \"records\":\n",
    "        return \"retrieve_medical_records\"\n",
    "    else:\n",
    "        return \"retrieve_insurance_faqs\"\n",
    "    \n",
    "def retrieve_medical_records(state: State) -> State:\n",
    "    documents = medical_records_retriever.invoke(state[\"user_query\"])\n",
    "    return {\n",
    "        \"documents\": documents,\n",
    "    }\n",
    "\n",
    "\n",
    "def retrieve_insurance_faqs(state: State) -> State:\n",
    "    documents = insurance_faqs_retriever.invoke(state[\"user_query\"])\n",
    "    return {\n",
    "        \"documents\": documents,\n",
    "    }\n",
    "############ retrieve part ################    \n",
    "medical_records_prompt = SystemMessage(\n",
    "    \"You are a helpful medical chatbot, who answers questions based on the patient's medical records, such as diagnosis, treatment, and prescriptions.\"\n",
    ")\n",
    "\n",
    "insurance_faqs_prompt = SystemMessage(\n",
    "    \"You are a helpful medical insurance chatbot, who answers frequently asked questions about insurance policies, claims, and coverage.\"\n",
    ")\n",
    "\n",
    "def generate_answer(state: State) -> State:\n",
    "    if state[\"domain\"] == \"records\":\n",
    "        prompt = medical_records_prompt\n",
    "    else:\n",
    "        prompt = insurance_faqs_prompt\n",
    "    messages = [\n",
    "        prompt,\n",
    "        *state[\"messages\"],\n",
    "        HumanMessage(f\"Documents: {state['documents']}\"),\n",
    "    ]\n",
    "    res = model_high_temp.invoke(messages)\n",
    "    return {\n",
    "        \"answer\": res.content,\n",
    "        # update conversation history\n",
    "        \"messages\": res,\n",
    "    }\n",
    "############ langgraph part ################\n",
    "builder = StateGraph(State, input=Input, output=Output)\n",
    "builder.add_node(\"router\", router_node)\n",
    "builder.add_node(\"retrieve_medical_records\", retrieve_medical_records)\n",
    "builder.add_node(\"retrieve_insurance_faqs\", retrieve_insurance_faqs)\n",
    "builder.add_node(\"generate_answer\", generate_answer)\n",
    "builder.add_edge(START, \"router\")\n",
    "builder.add_conditional_edges(\"router\", pick_retriever)\n",
    "builder.add_edge(\"retrieve_medical_records\", \"generate_answer\")\n",
    "builder.add_edge(\"retrieve_insurance_faqs\", \"generate_answer\")\n",
    "builder.add_edge(\"generate_answer\", END)\n",
    "\n",
    "graph = builder.compile()\n",
    "\n",
    "# Example usage\n",
    "input = {\"user_query\": \"Am I covered for COVID-19 treatment?\"}\n",
    "for chunk in graph.stream(input):\n",
    "    print(chunk)\n",
    "\n",
    "graph = builder.compile()\n",
    "\n",
    "from IPython.display import Image,display\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))\n",
    "\n",
    "# Example usage\n",
    "input = {\"user_query\": \"Am I covered for COVID-19 treatment?\"}\n",
    "for chunk in graph.stream(input):\n",
    "    print(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "971e8432",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LangChain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
