{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6a958e91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(splitted_text)\n",
    "#splitted_text[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8b220854",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import TextLoader\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_postgres import PGVector\n",
    "\n",
    "# Load the document, split it with chunks\n",
    "text = TextLoader(\"./test.txt\").load()\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=150,chunk_overlap=10)\n",
    "splitted_text = splitter.split_documents(text)\n",
    "\n",
    "# Embed each chunk and insert it into the vector store\n",
    "embedding_model = OllamaEmbeddings(model =\"llama3.1\")\n",
    "connection = \"postgresql+psycopg://langchain:langchain@localhost:6024/langchain\"\n",
    "db = PGVector.from_documents(splitted_text, embedding=embedding_model, connection=connection)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "edb48332",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='c4ca181a-ae8c-4408-94d5-d7b95de37b5f', metadata={'source': './test.txt'}, page_content='than that with the double-sided tape while providing other benefits.')]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a retriever\n",
    "retriever = db.as_retriever(search_kwargs={\"k\": 1}, search_type=\"mmr\")\n",
    "\n",
    "# Fetch relevant documents\n",
    "query_user = retriever.invoke(\"what is the material weighs?\")\n",
    "query_user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "b03d5ff0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='76.50%', additional_kwargs={}, response_metadata={'model': 'llama3.1', 'created_at': '2025-08-27T10:41:51.121697548Z', 'done': True, 'done_reason': 'stop', 'total_duration': 43107632741, 'load_duration': 48364827, 'prompt_eval_count': 295, 'prompt_eval_duration': 41844492861, 'eval_count': 5, 'eval_duration': 1214123684, 'model_name': 'llama3.1'}, id='run--8a38235a-c35e-4c65-bbfd-0a433dbaa03b-0', usage_metadata={'input_tokens': 295, 'output_tokens': 5, 'total_tokens': 300})"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "retriever = db.as_retriever()\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\"\"\"Answer the question based on only the following context:\n",
    "                                          {context}\n",
    "                                          Question: {question}\n",
    "                                          \"\"\")\n",
    "llm = ChatOllama(model=\"llama3.1\", temperature=0)\n",
    "\n",
    "chain = prompt | llm\n",
    "\n",
    "#Fetch relevant documents\n",
    "docs = retriever.get_relevant_documents(\"what is the average intersession word accuracy?\")\n",
    "\n",
    "#Run\n",
    "chain.invoke({\"context\": docs, \"question\": \"what is the average intersession word accuracy\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "4aa7ed4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='76.50% and 68.18%.', additional_kwargs={}, response_metadata={'model': 'llama3.1', 'created_at': '2025-08-27T13:22:59.28521524Z', 'done': True, 'done_reason': 'stop', 'total_duration': 47126228057, 'load_duration': 48121590, 'prompt_eval_count': 309, 'prompt_eval_duration': 44248532861, 'eval_count': 11, 'eval_duration': 2828484865, 'model_name': 'llama3.1'}, id='run--8334bd70-1d50-4c47-a738-c8b8528482d4-0', usage_metadata={'input_tokens': 309, 'output_tokens': 11, 'total_tokens': 320})"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain_core.runnables import chain\n",
    "\n",
    "retriever = db.as_retriever()\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\"\"\"Answer the question based on only the following context:\n",
    "                                          {context}\n",
    "                                          Question: {question}\n",
    "                                          \"\"\")\n",
    "llm = ChatOllama(model=\"llama3.1\", temperature=0)\n",
    "\n",
    "@chain\n",
    "def qa(input):\n",
    "    #fetch relevant docs\n",
    "    docs = retriever.get_relevant_documents(input)\n",
    "    # format prompt\n",
    "    formatted = prompt.invoke({\"context\": docs, \"question\": input})\n",
    "    #generate answer\n",
    "    answer = llm.invoke(formatted)\n",
    "    return answer\n",
    "#run\n",
    "qa.invoke(input=\"what is the average intersession word accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "959adda1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LangChain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
