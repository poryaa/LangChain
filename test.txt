Silent speech interfaces allow speech communication to take place in the absence of the acoustic speech signal. Radar-based sensing with radio antennas on the speakersâ€™ face can be used as a non-invasive modality to measure speech articulation in such applications. One of the major challenges with this approach is the variability between different sessions, mainly due to the repositioning of the antennas on the face of the speaker. In order to reduce the impact of this influencing factor, we developed a wearable headset that can be 3D-printed with flexible materials and weighs only about 69 g. For evaluation, a radar-based word recognition experiment was performed, where five speakers recorded a speech corpus in multiple sessions, alternatively with the headset and with double-sided tape to place the antennas on the face. By using a bidirectional long short-term memory network for classification, an average intersession word accuracy of 76.50% and 68.18% was obtained using the headset and the tape, respectively. This indicates that the antenna (re-) positioning accuracy with the headset is not worse than that with the double-sided tape while providing other benefits.